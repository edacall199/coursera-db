{
  "quizSrc": [
    {
      "term": "When performing logistic regression on sentiment analysis, you represented each tweet as a vector of ones and zeros. However your model did not work well. Your training cost was reasonable, but your testing cost was just not acceptable. What could be a possible reason?",
      "definition": "The vector representations are sparse and therefore it is much harder for your model to learn anything that could generalize well to the test set."
    },
    {
      "term": "Which of the following are examples of text preprocessing?",
      "definition": "Stemming, or the process of reducing a word to its word stem.  |  Lowercasing, which is the process of removing changing all capital letter to lower case.  |  Removing stopwords, punctuation, handles and URLs"
    },
    {
      "term": "The sigmoid function is defined as h(x^(i) ,θ) = 1 / (1+e^(−θ^Tx^(i))) . Which of the following is true.",
      "definition": "Large positive values of θ^Tx^(i) will make h(x^(i), θ) closer to 1 and large negative values of θ^Tx^(i) will make h(x^(i), θ) close to 0."
    },
    {
      "term": "The cost function for logistic regression is defined as J(θ) = −1/m *​ ∑^{i=1}_m [y^(i)logh(x^(i), θ)+(1−y^(i))log(1−h(x^(i), θ))]. Which of the following is true about the cost function above. Mark all the correct ones.",
      "definition": "When y^(i) = 1, as h(x^(i), θ) goes close to 0, the cost function approaches ∞.  |  When y^(i) = 0, as h(x^(i), θ) goes close to 0, the cost function approaches 0."
    },
    {
      "term": "For what value of θ^Tx in the sigmoid function does h(x^(i), θ)=0.5.\n\nEnter answer here",
      "definition": "0"
    },
    {
      "term": "Select all that apply. When performing logistic regression for sentiment analysis using the method taught in this week's lecture, you have to:",
      "definition": "Performing data processing.  |  Create a dictionary that maps the word and the class that word is found in to the number of times that word is found in the class.  |  For each tweet, you have to create a positive feature with the sum of positive counts of each word in that tweet. You also have to create a negative feature with the sum of negative counts of each word in that tweet."
    },
    {
      "term": "When training logistic regression, you have to perform the following operations in the desired order.",
      "definition": "Initialize parameters, classify/predict, get gradient, update, get loss, repeat"
    },
    {
      "term": "Assuming we got the classification correct, where y^(i) = 1 for some specific example i. This means that h(x^(i), θ) > 0.5. Which of the following has to hold:",
      "definition": "Our prediction, h(x^(i), θ) for this specific training example is greater than (1−h(x^(i), θ))."
    },
    {
      "term": "What is the purpose of gradient descent? Select all that apply.",
      "definition": "Gradient descent allows us to learn the parameters θ in logistic regression as to minimize the loss function J.  |  Gradient descent, grad_theta allows us to update the parameters θ by computing θ = θ − α ∗ grad_theta"
    },
    {
      "term": "What is a good metric that allows you to decide when to stop training/trying to get a good model? Select all that apply.",
      "definition": "When your accuracy is good enough on the test set.  |  When you plot the cost versus (# of iterations) and you see that your the loss is converging (i.e. no longer changes as much)."
    },
    {
      "term": "Assume that there are 2 happy people and 2 unhappy people in a room. Concretely, persons A and B are happy and persons B and C are unhappy. If you were to randomly pick a person from the room, what is the probability that the person is happy.",
      "definition": "1/2"
    },
    {
      "term": "Assume that there are 2 happy people and 2 unhappy people in a room. Concretely, persons A and B are happy and persons B and C are unhappy. If a friend showed you the part of the room where the two happy people are, what is the probability that you choose person B?",
      "definition": "1/2"
    },
    {
      "term": "From the equations presented below, express the probability of a tweet being positive given that it contains the word happy in terms of the probability of a tweet containing the word happy given that it is positive P( Positive ∣ \"happy\" ) = P( Positive ∩ \"happy\" ) / P( \"happy\" ) P( \"happy\" ∣ Positive ) = P( \"happy\" ∩ Positive ) / P( Positive )",
      "definition": "P( Positive ∣ happy ) = P( happy ∣ Positive ) × P( Positive ) / P( happy)"
    },
    {
      "term": "Bayes rule is defined as",
      "definition": "P(X∣Y) = P(Y∣X) × P(X) / P(Y)"
    },
    {
      "term": "Suppose that in your dataset, 25% of the positive tweets contain the word 'happy'. You also know that a total of 13% of the tweets in your dataset contain the word 'happy', and that 40% of the total number of tweets are positive. You observe the tweet: ''happy to learn NLP'. What is the probability that this tweet is positive?\n\nEnter answer here",
      "definition": "0.77"
    },
    {
      "term": "The log likelihood for a certain word w_i is defined as: log( P(w_i ∣ pos) / P(w_i ∣ neg) ).",
      "definition": "Positive numbers imply that the word is positive.  |  Negative numbers imply that the word is negative."
    },
    {
      "term": "The log likelihood mentioned in lecture, which is the log of the ratio between two probabilities is bounded between",
      "definition": "−∞ and ∞"
    },
    {
      "term": "When implementing naive Bayes, in which order should the following steps be implemented. Preprocess the tweets: process_tweet(tweet) ➞ Compute freq(w, class) Get P(w | pos), P(w | neg) Get λ(w) Compute logprior = log(P(pos) / P(neg)) Preprocess the tweets: process_tweet(tweet) ➞ Compute freq(w, class) Get λ(w) Get P(w | pos), P(w | neg) Compute logprior = log(P(pos) / P(neg)) Compute freq(w, class) Preprocess the tweets: process_tweet(tweet) ➞ Get P(w | pos), P(w | neg) Get λ(w) Compute logprior = log(P(pos) / P(neg)) Compute freq(w, class) Preprocess the tweets: process_tweet(tweet) ➞ Compute logprior = log(P(pos) / P(neg) Get P(w | pos), P(w | neg) Get λ(w)",
      "definition": "Get or annotate a dataset with positive and negative tweets"
    },
    {
      "term": "To predict using naive bayes, which of the following are required.",
      "definition": "X_val, Y_val, λ, logprior"
    },
    {
      "term": "Which of the following is NOT an application of naive Bayes?",
      "definition": "Numerical predictions"
    },
    {
      "term": "G​iven a corpus A, encoded as (1, 2, 3) and corpus B encoded as (4, 7, 2), What is the euclidean distance between the two documents?",
      "definition": "5.91608"
    },
    {
      "term": "G​iven the previous problem, a user now came up with a corpus C defined as (3, 1, 4) and you want to recommend a document that is similar to it. Would you recommend document A or document B?",
      "definition": "Document A​"
    },
    {
      "term": "W​hich of the following is true about euclidean distance?",
      "definition": "W​hen comparing similarity between two corpuses, it does not work well when the documents are of different sizes.  |  I​t is the norm of the difference between two vectors."
    },
    {
      "term": "W​hat is the range of a cosine similarity score, namely s, in the case of information retrieval where the vectors are positive?",
      "definition": "0 ≤ s ≤ 1"
    },
    {
      "term": "T​he cosine similarity score of corpus A = (1, 0, −1) and corpus B = (2, 8, 1) is equal to ?",
      "definition": "0.08512565307587486"
    },
    {
      "term": "W​e will define the following vectors, USA = (5, 6), Washington = (10, 5), Turkey = (3, 1), Ankara = (9, 1), Russian = (5, 5), and Japan = (4, 3). Using only the following vectors, Ankara is the capital of what country?",
      "definition": "T​urkey"
    },
    {
      "term": "P​lease select all that apply. PCA is",
      "definition": "u​sed to reduce the dimension of your data.  |  v​isualize word vectors"
    },
    {
      "term": "P​lease select all that apply. Which is correct about PCA?",
      "definition": "Y​ou can think of an eigenvector as an uncorrelated feature for your data.  |  T​he eigenvalues tell you the amount of information retained by each feature.  |  C​omputing the covariance matrix is critical when performing PCA"
    },
    {
      "term": "I​n which order do you perform the following operations when computing PCA?",
      "definition": "m​ean normalize, get Σ the covariance matrix, perform SVD, then dot product the data, namely X, with a subset of the columns of U to get the reconstruction of your data."
    },
    {
      "term": "V​ector space models allow us to",
      "definition": "T​o represent words and documents as vectors.  |  b​uild useful applications including and not limited to, information extraction, machine translation, and chatbots.  |  c​reate representations that capture similar meaning."
    },
    {
      "term": "A​ssume that your objective is to minimize the transformation of X as similar to Y as possible, what would you optimize to get R? (XR≈Y)",
      "definition": "M​inimize the distance between XR and Y"
    },
    {
      "term": "W​hen solving for R, which of the following is true?",
      "definition": "Initialize R, create a forloop, inside the forloop: (compute the gradient, update the loss)"
    },
    {
      "term": "T​he Frobenius norm of A = (1, 3; 4, 5) is\n\nEnter answer here",
      "definition": "7.14"
    },
    {
      "term": "A​ssume X∈R^m×n, R∈R^n×n, Y∈R^m×n which of the following is the gradient of ∥XR−Y∥_F^2?",
      "definition": "2/m × X^T × (XR-Y)"
    },
    {
      "term": "I​magine that you are visiting a city in the US. If you search for friends that are living in the US, would you be able to determine the 2 closest of ALL your friends around the world?",
      "definition": "N​o"
    },
    {
      "term": "W​hat is the purpose of using a function to hash vectors into values?",
      "definition": "T​o speed up the time it takes when comparing similar vectors.  |  T​o not have to spend time comparing vectors with other vectors that are completely different."
    },
    {
      "term": "Given the following vectors, determine the true statements. V_1: (1, 1) V_2: (2, 2) V_3: (−1, −1)",
      "definition": "P × V_1^T and P × V_2^T have the same sign."
    },
    {
      "term": "W​e define H to be the number of planes and h_i to be 1 or 0 depending on the sign of the dot product with plane i. Which of the following is the equation used to calculate the hash for several planes.",
      "definition": "∑_i^H 2^i × h_i"
    },
    {
      "term": "H​ow can you speed up the look up for similar documents.",
      "definition": "A​pproximate Nearest Neighbors  |  L​ocality sensitive hashing"
    },
    {
      "term": "H​ash tables are useful because",
      "definition": "a​llow us to divide vector space to regions.  |  s​peed up look up  |  c​an always be reproduced"
    },
    {
      "term": "The Transition matrix A defined in lecture allows you to:",
      "definition": "Compute the probability of going from a part of speech tag to another part of speech tag."
    },
    {
      "term": "The Emission matrix B defined in lecture allows you to:",
      "definition": "Compute the probability of going from a part of speech tag to a word."
    },
    {
      "term": "The column sum of the emission matrix has to be equal to 1.",
      "definition": "False."
    },
    {
      "term": "The row sum of the transition matrix has to be 1.",
      "definition": "True"
    },
    {
      "term": "Why is smoothing usually applied? Select all that apply.",
      "definition": "Applying smoothing, for the majority of cases, allows us to decrease the probabilities in the transition and emission matrices and this allows us to have non zero probabilities.  |  Applying smoothing, for the minority of cases, allows us to increase the probabilities in the transition and emission matrices and this allows us to have non zero probabilities."
    },
    {
      "term": "Given the following D matrix, what would be the sequence of tags for the words on the right?",
      "definition": "t_2, t_3, t_1, t_3, t_1"
    },
    {
      "term": "Previously, we have been multiplying the raw probabilities, but in reality we take the log of those probabilities. Why might that be the case?",
      "definition": "We take the log probabilities because probabilities are bounded between 0 and 1 and as a result, the numbers could be too small and will go towards 0."
    },
    {
      "term": "Which of the following are useful for applications for parts of speech tagging?",
      "definition": "Named Entity Recognition  |  Coreference Resolution  |  Speech recognition"
    },
    {
      "term": "Corpus: \"In every place of great resort the monster was the fashion. They sang of it in the cafes, ridiculed it in the papers, and represented it on the stage. \" (Jules Verne, Twenty Thousand Leagues under the Sea) In the context of our corpus, what is the probability of word \"papers\" following the phrase \"it in the\".",
      "definition": "P(papers|it in the) = 1/2"
    },
    {
      "term": "Given these conditional probabilities P(Mary)=0.1; P(likes)=0.2; P(cats)=0.3 . P(Mary|likes) =0.2; P(likes|Mary) =0.3; P(cats|likes)=0.1; P(likes|cats)=0.4 Approximate the probability of the following sentence with bigrams: \"Mary likes cats\"",
      "definition": "P(Mary likes cats) = 0.003"
    },
    {
      "term": "Given these conditional probabilities P(Mary)=0.1; P(likes)=0.2; P(cats)=0.3 P(Mary|<s>)=0.2; P(</s>|cats)=0.6 P(likes|Mary) =0.3; P(cats|likes)=0.1 Approximate the probability of the following sentence with bigrams: \"<s> Mary likes cats </s>\"",
      "definition": "P(<s> Mary likes cats </s>) = 0.0036"
    },
    {
      "term": "Given the logarithm of these conditional probabilities: log(P(Mary|<s>))=-2; log(P(</s>|cats))=-1 log(P(likes|Mary)) =-10; log(P(cats|likes))=-100 Approximate the log probability of the following sentence with bigrams : \"<s> Mary likes cats </s>\"",
      "definition": "log(P(<s> Mary likes cats </s>)) = -113"
    },
    {
      "term": "Given the logarithm of these conditional probabilities: log(P(Mary|<s>))=-2; log(P(</s>|cats))=-1 log(P(likes|Mary)) =-10; log(P(cats|likes))=-100 Assuming our test set is W=\"<s> Mary likes cats </s>\", what is the model's perplexity.",
      "definition": "log PP(W) = (-1/4)*(-113)"
    },
    {
      "term": "Given the training corpus and minimum word frequency=2, how would the vocabulary for corpus preprocessed with <UNK> look like? \"<s> I am happy I am learning </s> <s> I am happy I can study </s>\"",
      "definition": "V = (I,am,happy)"
    },
    {
      "term": "Corpus: \"I am happy I am learning\" In the context of our corpus, what is the estimated probability of word \"can\" following the word \"I\" using the bigram model and add-k-smoothing where k=3.",
      "definition": "P(can|I) = 3/(2+3*4)"
    },
    {
      "term": "Which of the following are applications of n-gram language models?",
      "definition": "Speech recognitions  |  Auto-complete  |  Auto-correct  |  Augmentative communication"
    },
    {
      "term": "The higher the perplexity score the more our corpus will make sense.",
      "definition": "False"
    },
    {
      "term": "The perplexity score increases as we increase the number of <UNK> tokens.",
      "definition": "True."
    },
    {
      "term": "Which one of the following word representations is most likely to correspond to a word embedding representation in a general-purpose vocabulary? In other words, which one is most likely to capture meaning and important information about the words? caravan -> 3 caravan -> (-0.1 0.9) caravan -> (0 0 1 0) caravan -> (-1 -0.9)",
      "definition": "car -> (0.1 1)"
    },
    {
      "term": "Which one of the following statements is correct?",
      "definition": "The meaning of the words, as carried by the word embeddings, depends on the embedding approach."
    },
    {
      "term": "Which one of the following statements is false?",
      "definition": "The continuous bag-of-words model learns to predict context words given a center word."
    },
    {
      "term": "Consider the corpus \"A robot may not injure a human being or, through inaction, allow a human being to come to harm.\" and assume you are preparing data to train a CBOW model. Ignoring punctuation, for a context half-size of 3, what are the context words of the center word \"inaction\"?",
      "definition": "\"being or through allow a human\""
    },
    {
      "term": "You are designing a neural network for a CBOW model that will be trained on a corpus with a vocabulary of 8000 words. If you want it to learn 400-dimensional word embedding vectors, what should be the sizes of the input, hidden, and output layers?",
      "definition": "8000 (input layer), 400 (hidden layer), 8000 (output layer)"
    },
    {
      "term": "If you are designing a neural network for a CBOW model that will be trained on a corpus of 8000 words, and if you want it to learn 400-dimensional word embedding vectors, what should be the size of W1, the weighting matrix between the input layer and hidden layer, if it is fed training examples in batches of 16 examples represented by a 8000 row by 16 column matrix? Hint: if X is the input matrix, H the matrix for the hidden layer, and B1 the bias matrix, then H = ReLU(W1X + B1).",
      "definition": "400 rows by 8000 columns"
    },
    {
      "term": "Given the input vector x below, a trained continuous bag-of-words model outputs the vector ŷ below. What is the word predicted by the model?",
      "definition": "Therefore"
    },
    {
      "term": "The following weighting matrix W_1 has been learned after training a CBOW model. You are also given word-to-row mapping for the input column vectors. ​What is the word embedding vector for \"ring\"?",
      "definition": "[4.56; -2.94; 2.61; -1.16]"
    },
    {
      "term": "Select all that are correct.",
      "definition": "You can perform intrinsic evaluation by using a clustering algorithm to group similar word embedding vectors, and determining if the clusters capture related words.  |  Extrinsic evaluation evaluates actual usefulness of embeddings, is time consuming and is more difficult to trouble shoot.  |  To evaluate word embeddings with extrinsic evaluation, you use the word embeddings to perform an external task, which is typically the real-world task that you initially needed the word embeddings for. Then, use the performance metric of this task as a proxy for the quality of the word embeddings."
    },
    {
      "term": "How many layers does the following neural network have?",
      "definition": "3"
    },
    {
      "term": "Let us analyze the following class: What would be the output above?",
      "definition": "14"
    },
    {
      "term": "The ReLU layer, is an activation layer that typically follows a dense fully connected layer, and transforms all values between 0 and 1 before sending them on to the next layer.",
      "definition": "False"
    },
    {
      "term": "The ReLU layer is an activation layer that typically follows a dense fully connected layer, and transforms any negative values to 0 before sending them on to the next layer.",
      "definition": "True"
    },
    {
      "term": "For the embedding layer in your model, you'd have to learn a matrix of weights of what size?",
      "definition": "Equal to your vocabulary times the dimension of the embedding"
    },
    {
      "term": "What would be the probability of a five word sequence using a penta-gram?",
      "definition": "P(w5,w4,w3,w2,w1) = P(w1)×P(w2∣w1)×P(w3∣w1,w2)×P(w4∣w1,w2,w3)×P(w5∣w1,w2,w3,w4)"
    },
    {
      "term": "The number of parameters in an RNN is the same regardless of the input's length.",
      "definition": "True."
    },
    {
      "term": "Select all the examples that correspond to a \"many to one\" architecture.",
      "definition": "An RNN which inputs a sentence and determines the sentiment.  |  An RNN which inputs a conversation and determines the topic."
    },
    {
      "term": "What should be the size of matrix Wh, if h<t> had size 4x1 and x<t> 10x1? h<t> = g(Wh[h<t−1>,x<t>]+bh)",
      "definition": "4x14"
    },
    {
      "term": "In the next equation, why is there a division by the number of time steps but not one for the number of classification categories?",
      "definition": "Because there is just one value in every vector y<t> different from zero."
    },
    {
      "term": "What problem, related to vanilla RNNs, do GRUs tackle?",
      "definition": "Loss of relevant information for long sequences of words."
    },
    {
      "term": "Bidirectional RNNs are acyclic graphs, which means that the computations in one direction are independent from the ones in the other direction.",
      "definition": "True"
    },
    {
      "term": "Compared to Traditional Language models which of the following problems does an RNN help us with?",
      "definition": "Helps us solve memory issues.  |  Helps us solve RAM issues."
    },
    {
      "term": "What type of RNN structure would you use when implementing machine translation?",
      "definition": "Many to Many"
    },
    {
      "term": "In the scan() function the variable cur_value corresponds to the hidden state in an RNN.",
      "definition": "True"
    },
    {
      "term": "Identify the correct order of the gates that information flows through in an LSTM unit.",
      "definition": "Forget gate, input gate, output gate."
    },
    {
      "term": "Which are some applications of LSTMs?",
      "definition": "Music composition  |  Image captioning  |  Next character prediction  |  Chatbots  |  Speech recognition"
    },
    {
      "term": "The tanh layer ensures the values in your network stay numerically stable, by squeezing all values between -1 and 1. This prevents any of the values from the current inputs from becoming so large that they make the other values insignificant.",
      "definition": "True"
    },
    {
      "term": "What type of architecture is a named entity recognition using?",
      "definition": "Many to many"
    },
    {
      "term": "Extract the named entities from the following sentence: Younes, a Moroccan artificial intelligence engineer, travelled to France for a conference.",
      "definition": "Younes, Moroccan, France."
    },
    {
      "term": "In a vectorized representation of your data, equal sequence length allows more efficient batch processing.",
      "definition": "True."
    },
    {
      "term": "Which built-in Python method would you use to iterate over your test set during the evaluation step? Assuming you are using a data generator.",
      "definition": "next()"
    },
    {
      "term": "Why is it important to mask padded tokens when computing the loss?",
      "definition": "Padded tokens are not part of the data and are just used to help us keep the same sequence length for more efficient batch processing. We should not include their loss."
    },
    {
      "term": "In which of the following orders should we train an Named Entity Recognition with an LSTM? Put them in a batch => 64, 128, 256, 512 ... Run the output through a dense layer Feed it into an LSTM unit Predict using a log softmax over K classes Put them in a batch => 64, 128, 256, 512 ... Run the output through a dense layer Predict using a log softmax over K classes Feed it into an LSTM unit Put them in a batch => 64, 128, 256, 512 ... Feed it into an LSTM unit Run the output through a dense layer Predict using a log softmax over K classes",
      "definition": "Create a tensor for each input and its corresponding number"
    },
    {
      "term": "LSTMS solve vanishing/exploding gradient problems when compared to basic RNNs.",
      "definition": "True"
    },
    {
      "term": "Classification allows you to identify similarity between two things while siamese networks allow you to categorize things.",
      "definition": "False"
    },
    {
      "term": "Do the two subnetworks in a siamese network share the same parameters?",
      "definition": "Y​es"
    },
    {
      "term": "When training a siamese network to identify duplicates, which pairs of questions from the following questions do you expect to have the highest cosine similarity ? Is learning NLP useful for me to get a job? (ANCHOR) What should I learn to get a job? (POSITIVE) Where is the job? (NEGATIVE)",
      "definition": "Anchor, Positive"
    },
    {
      "term": "In the triplet loss function below, will decreasing the hyperparameter alpha from 0.5 to 0.2 require more, or less, optimization during training ? diff = s(A,N) − s(A,P) L(A,P,N) = max(diff+α, 0)",
      "definition": "Less"
    },
    {
      "term": "The orange square below corresponds to the similarity score of question duplicates?",
      "definition": "False"
    },
    {
      "term": "What is the closest negative in this set of numbers assuming a duplicate pair similarity of 0.6? [-0.9,-0.4,0.4, 0.8]",
      "definition": "0.4"
    },
    {
      "term": "In one shot learning, is any retraining required when new classes are added? For example, a new bank customer's signature.",
      "definition": "N​o"
    },
    {
      "term": "The sigmoid function is defined as $h(x^{(i)}, \\theta) = \\frac{1}{1+e^{-\\theta^T x^{(i)}}}$. Which of the following is true. x^{(i)},\\theta)$ close to -1. x^{(i)},\\theta)$ close to 0. x^{(i)},\\theta)$ close to 0. x^{(i)},\\theta)$ close to -1.",
      "definition": "Large positive values of $\\theta^Tx^{(i)}$ will make $h( x^{(i)}, \\theta)$ closer to 1 and large negative values of $\\theta^Tx^{(i)}$ will make $h("
    },
    {
      "term": "The cost function for logistic regression is defined as $J(\\theta)=-\\frac{1}{m} \\sum_{i=1}^{m}\\left[y^{(i)} \\log h\\left(x^{(i)}, \\theta\\right)+\\left(1-y^{(i)}\\right) \\log \\left(1-h\\left(x^{(i)}, \\theta\\right)\\right)\\right]$. Which of the following is true about the cost function above. Mark all the correct ones.",
      "definition": "When $y^{(i)} = 1$, as $h(x^{(i)},\\theta)$ goes close to 0, the cost function approaches $\\infty$.  |  When $y^{(i)} = 0$, as $h(x^{(i)},\\theta)$ goes close to 0, the cost function approaches $0$."
    },
    {
      "term": "0",
      "definition": "For what value of $\\theta^Tx$ in the sigmoid function does $h(x^{(i)},\\theta) = 0.5$."
    },
    {
      "term": "Assuming we got the classification correct, where $y^{(i)} = 1$ for some specific example i. This means that $h(x^{(i)}, \\theta) > 0.5$. Which of the following has to hold:",
      "definition": "Our prediction, $h(x^{(i)}, \\theta) > 0.5$ for this specific training example is greater than $(1 - h(x^{(i)}, \\theta))$."
    },
    {
      "term": "Assume that there are 2 happy people and 2 unhappy people in a room. Concretely, persons A and B are happy and persons C and D are unhappy. If you were to randomly pick a person from the room, what is the probability that the person is happy.",
      "definition": "1/2"
    },
    {
      "term": "Assume that there are 2 happy people and 2 unhappy people in a room. Concretely, persons A and B are happy and persons C and D are unhappy. If a friend showed you the part of the room where the two happy people are, what is the probability that you choose person B?",
      "definition": "1/2"
    },
    {
      "term": "From the equations presented below, express the probability of a tweet being positive given that it contains the word happy in terms of the probability of a tweet containing the word happy given that it is positive $P(\\text { Positive } \\mid \\text { \"happy\" })=\\frac{P(\\text { Positive } \\cap \\text { \"happy\" })}{P(\\text { \"happy\" })} $ $P(\\text { \"happy\" } \\mid \\text { Positive })=\\frac{P(\\text { \"happy\" } \\cap \\text { Positive })}{P(\\text { Positive })} $ Positive }) \\times \\frac{P(\\text { Positive })}{P(\\text { \"happy\"})}$ Positive }) \\times \\frac{P(\\text { \"happy\" })}{P(\\text {Positive})}$ Positive }) \\times \\frac{P(\\text { Positive })}{P(\\text { \"happy\"})}$ Positive }) \\times \\frac{P(\\text {\"happy\"})}{P(\\text {Positive})}$",
      "definition": "$P(\\text { Positive } \\mid \\text { \"happy\" })=P(\\text {\"happy\" } \\mid \\text {"
    },
    {
      "term": "0.77",
      "definition": "Suppose that in your dataset, 25% of the positive tweets contain the word 'happy'. You also know that a total of 13% of the tweets in your dataset contain the word 'happy', and that 40% of the total number of tweets are positive. You observe the tweet: ''happy to learn NLP'. What is the probability that this tweet is positive?"
    },
    {
      "term": "The log likelihood for a certain word $w_i$​ is defined as: $\\log (\\frac{P(w_i | pos)}{P(w_i | neg)})$.",
      "definition": "Positive numbers imply that the word is positive.  |  Negative numbers imply that the word is negative."
    },
    {
      "term": "To test naive bayes model, which of the following are required?",
      "definition": "$X_{\\text val}, Y_{\\text val}, \\lambda, logprior$"
    },
    {
      "term": "Given a corpus A, encoded as $\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}$ and corpus B encoded as $\\begin{pmatrix} 4 \\\\ 7 \\\\ 2 \\end{pmatrix}$​, What is the Euclidean distance between the two documents?",
      "definition": "5.91608"
    },
    {
      "term": "Given the previous problem, a user now came up with a corpus C defined as $\\begin{pmatrix} 3 \\\\ 1 \\\\ 4 \\end{pmatrix}$​ and you want to recommend a document that is similar to it. Would you recommend document A or document B?",
      "definition": "Document A"
    },
    {
      "term": "Which of the following is true about euclidean distance?",
      "definition": "When comparing similarity between two corpuses, it does not work well when the documents are of different sizes.  |  It is the norm of the difference between two vectors."
    },
    {
      "term": "The cosine similarity score of corpus A = $\\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix}$​ and corpus B = $\\begin{pmatrix} 2 \\\\ 8 \\\\ 1 \\end{pmatrix}​$ is equal to?",
      "definition": "0.08512565307587486"
    },
    {
      "term": "What is the range of a cosine similarity score, namely s, in the case of information retrieval where the vectors are positive?",
      "definition": "$0 \\leq s \\leq 1$"
    },
    {
      "term": "We will define the following vectors, USA = $\\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}$, Washington = $\\begin{pmatrix} 10 \\\\ 5 \\end{pmatrix}$, Turkey = $\\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}$, Ankara = $\\begin{pmatrix} 9 \\\\ 1 \\end{pmatrix}$, Russia = $\\begin{pmatrix} 5 \\\\ 5 \\end{pmatrix}$, and Japan = $\\begin{pmatrix} 4 \\\\ 3 \\end{pmatrix}$. Using only the following vectors, Ankara is the capital of what country? Please consider the cosine similarity score in your calculations.",
      "definition": "Turkey"
    },
    {
      "term": "Please select all that apply. PCA is",
      "definition": "used to reduce the dimension of your data;  |  visualize word vectors;"
    },
    {
      "term": "Please select all that apply. Which is correct about PCA?",
      "definition": "You can think of an eigenvector as an uncorrelated feature for your data.  |  The eigenvalues tell you the amount of information retained by each feature.  |  Computing the covariance matrix is critical when performing PCA"
    },
    {
      "term": "In which order do you perform the following operations when computing PCA?",
      "definition": "mean normalize, get $\\Sigma$ the covariance matrix, perform SVD, then dot product the data, namely X, with a subset of the columns of U to get the reconstruction of your data."
    },
    {
      "term": "Vector space models allow us to",
      "definition": "To represent words and documents as vectors.  |  build useful applications including and not limited to, information extraction, machine translation, and chatbots.  |  create representations that capture similar meaning."
    },
    {
      "term": "Assume that your objective is to minimize the transformation of X as similar to Y as possible, what would you optimize to get R? ($XR \\approx Y$)",
      "definition": "Minimize the distance between XR and Y"
    },
    {
      "term": "When solving for RRR, which of the following is true?",
      "definition": "Initialize R, create a forloop, inside the forloop: (compute the gradient, update the loss)"
    },
    {
      "term": "7.14",
      "definition": "The Frobenius norm of A = $\\begin{pmatrix} 1 & 3 \\\\ 4 & 5 \\end{pmatrix}$ is\n(Answer should be in 2 decimal places)"
    },
    {
      "term": "Assume $X \\in R^{m \\times n}, R \\in R^{n \\times n}, Y \\in R^{m \\times n}$. Which of the following is the gradient of $\\|XR - Y\\|_F^2$​?",
      "definition": "$\\frac{2}{m}X^T (XR-Y)$"
    },
    {
      "term": "Imagine that you are visiting a city in the US. If you search for friends that are living in the US, would you be able to determine the 2 closest of ALL your friends around the world?",
      "definition": "No"
    },
    {
      "term": "What is the purpose of using a function to hash vectors into values?",
      "definition": "To speed up the time it takes when comparing similar vectors.  |  To not have to spend time comparing vectors with other vectors that are completely different."
    },
    {
      "term": "Given the following vectors, determine the true statements. $P: \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$ $V_1: \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$ $V_2: \\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix}$ $V_3: \\begin{bmatrix} - 1 \\\\ - 1 \\end{bmatrix}$",
      "definition": "$P V_1^T$​ and $P V_2^T$​ have the same sign."
    },
    {
      "term": "We define H to be the number of planes and $h_i$​ to be 1 or 0 depending on the sign of the dot product with plane i. Which of the following is the equation used to calculate the hash for several planes.",
      "definition": "$\\sum_{i}^H 2^i h_i$"
    },
    {
      "term": "How can you speed up the look up for similar documents.",
      "definition": "Approximate Nearest Neighbors  |  Locality sensitive hashing"
    },
    {
      "term": "Hash tables are useful because",
      "definition": "allow us to divide vector space to regions.  |  speed up look up  |  can always be reproduced"
    },
    {
      "term": "4",
      "definition": "The minimum edit distance between the words deep and creepy is:"
    },
    {
      "term": "Which of the following is a NOT VALID example of an edit string operation?",
      "definition": "SWITCH a letter 'Lusca' --> 'Lucas'"
    },
    {
      "term": "Autocorrect is only appliable when dealing with misspelled words.",
      "definition": "False"
    },
    {
      "term": "Given the corpus: \"I am happy because I am doing quizzes.\" Based on this tiny corpus, consider the following sentence: \"I sm very good at solving quizzes.\" Which of the following is true?",
      "definition": "There is a unique correction for the misspelled word \"sm\"."
    },
    {
      "term": "About the probabilistic model defined in the lecture, select all that apply.",
      "definition": "Replacing a character costs more than deleting a character.  |  If $C(w)$ is the number of times a word appear in a corpus and $V$ is the corpus size, then the probability of the word $w$ in the corpus is $P(w) = \\frac{C(w)}{V}$​.  |  The sentence \"Happy birthday deer friends\" would not have any word corrected in the model defined in the lecture."
    },
    {
      "term": "5",
      "definition": "Suppose we build a distance matrix D for the following case:\nSource: Pie --> Target: Bye\nWhat is the value for D[3,2]?"
    },
    {
      "term": "About the Minimum edit distance algorithm, select all that apply. Let $D$ be the distance matrix, for two words of same size. The matrix size is $n$.",
      "definition": "$D[0,i] > D[0,j]$ if $i > j$.  |  The algorithm avoids usage of brute force by implementing a dynamic programming approach."
    },
    {
      "term": "About the minimum edit distance, which of the following statement is not true?",
      "definition": "It is used to check if a word is misspelled."
    },
    {
      "term": "The minimum edit distance calculation is more computationally intensive if we have a big corpus.",
      "definition": "False"
    },
    {
      "term": "0.17",
      "definition": "Given the corpus \"Autocorrect is a powerful tool and it is used on our computer.\"\nThe value for $P(\\text{is})$ is:\nThe answer should have two decimal places (rounding up, if necessary). For example: 0.88888 should be answered as 0.89."
    },
    {
      "term": "The following weighting matrix W_1 has been learned after training a CBOW model. You are also given word-to-row mapping for the input column vectors. What is the word embedding vector for \"ring\"?",
      "definition": "[4.56; -2.94; 2.61; -1.16]"
    },
    {
      "term": "What should be the size of matrix $W_h$, if $h^{<t>}$ had size 4x1 and $x^{<t>}$ 10x1? $h^{<t>}=g\\left(W_{h}\\left[h^{<t-1>}, x^{<t>}\\right]+b_{h}\\right)$",
      "definition": "4x14"
    },
    {
      "term": "In the next equation, why is there a division by the number of time steps but not one for the number of classification categories? $J=-\\frac{1}{T} \\sum_{t=1}^{T} \\sum_{j=1}^{K} y_{j}^{<t>} \\log \\hat{y}_{j}^{<t>} $",
      "definition": "Because there is just one value in every vector $y^{<t>}$ different from zero."
    },
    {
      "term": "What are the two subfields of Natural Language Processing?\nA. Context and Expectations\nB. Recognition and Synthesis\nC. Semantics of Pragmatics\nD. Generation and Understanding",
      "definition": "D. Generation and Understanding\n3 phương án trắc nghiệm"
    },
    {
      "term": "Given a stream of text, Named Entity Recognition determines which pronoun maps to which noun.\nA. True\nB. False",
      "definition": "B. False\n1 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following smoothing techniques assigns too much probability to unseen events?\nA. Add-1 smoothing\nB. Add-k smoothing\nC. Witten-Bell smoothing\nD. Good-Turing smoothing",
      "definition": "A. Add-1 smoothing"
    },
    {
      "term": "Given a sound clip of a person or people speaking, determine the textual representation of the speech.\nA. Text-to-speech\nB. Speech-to-text\nC. All of the mentioned\nD. None of the others.",
      "definition": "B. Speech-to-text\n3 phương án trắc nghiệm"
    },
    {
      "term": "Words may have multiple meanings. This leads to what type of ambiguity in NLP?\nA. Syntactic ambiguity\nB. Anaphoric ambiguity\nC. Semantic ambiguity\nD. Lexical ambiguity",
      "definition": "D. Lexical ambiguity"
    },
    {
      "term": "Which of the following is not an error correction and detection code?\nA. Block code\nB. Convolutional codes\nC. Passive codes\nD. Turbo codes",
      "definition": "C. Passive codes"
    },
    {
      "term": "Which is NOT a conjunction?\nA. but\nB. and\nC. or\nD. that",
      "definition": "D. that"
    },
    {
      "term": "Given a sequence of observations and a HMM model, which of the following fundamental problems of HMM finds the most likely sequence of states that produced the observations in an efficient way?\nA. Evaluation problem\nB. Likelihood estimation problem\nC. Decoding problem\nD. Learning problem",
      "definition": "C. Decoding problem"
    },
    {
      "term": "__________ concerns how the immediately preceding sentences affect the interpretation of the next sentence\nA. Pragmatics\nB. Syntax\nC. Discourse\nD. Semantics",
      "definition": "C. Discourse\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which Among The Following Is Important Component Of Natural Language Processig?\nA. Representation\nB. Description\nC. Exposion\nD. Narration",
      "definition": "A. Representation"
    },
    {
      "term": "_________ transfers linear sequences of words into structures\nA. Semantic Analysis\nB. Tokens\nC. Lexical Analysis\nD. Discourse",
      "definition": "A. Semantic Analysis\n3 phương án trắc nghiệm"
    },
    {
      "term": "What is Natural Language Processing good for?\nA. Summarize blocks of text\nB. Automatically generate keyword tags\nC. Identify the type of entity extracted\nD. All of the others",
      "definition": "D. All of the others"
    },
    {
      "term": "The words 'there' and 'their causes which of the following type of ambiguity?\nA. Syntactic\nB. Semantic\nC. Phonological\nD. Pragmatic",
      "definition": "C. Phonological\n3 phương án trắc nghiệm"
    },
    {
      "term": "What is the main challenge/s of NLP?\nA. Handling Ambiguity of Sentences\nB. Handling Tokenization\nC. Handling POS-Tagging\nD. All of the mentioned",
      "definition": "A. Handling Ambiguity of Sentences\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following includes major tasks of NLP?\nA. Automatic Summarization\nB. Discourse Analysis\nC. Machine Translation\nD. All of the others",
      "definition": "D. All of the others"
    },
    {
      "term": "________ extracts all the documents containing the key words\nA. Information Extraction\nB. Information Retrieval\nC. Inflection\nD. Inflation",
      "definition": "B. Information Retrieval\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following is not a primitive operation of a regular expression?\nA. Concatenation\nB. Closure\nC. Union\nD. Projection",
      "definition": "D. Projection"
    },
    {
      "term": "__________ is a phrase whose head is a noun or a pronoun, optionally accompanied by a set of modifier\nA. Pronoun Phrase\nB. Adverb Phrase\nC. Noun Phrase\nD. Proposition Phrase",
      "definition": "C. Noun Phrase\n3 phương án trắc nghiệm"
    },
    {
      "term": "Operators and Quantifiers are mostly responsible for ___________\nA. Scope Ambiguity\nB. Pragmatic Ambiguity\nC. Semantic Ambiguity\nD. None of These",
      "definition": "A. Scope Ambiguity\n3 phương án trắc nghiệm"
    },
    {
      "term": "What are the input and output of an NLP system?\nA. Speech and noise\nB. Speech and Written Text\nC. Noise and Written Text\nD. Noise and value",
      "definition": "B. Speech and Written Text"
    },
    {
      "term": "What scope ambiguity involves?\nA. Operators and quantifiers\nB. Parameters and arguments\nC. Tokens\nD. None of Above",
      "definition": "A. Operators and quantifiers"
    },
    {
      "term": "Where the additional variables does are added in HMM?\nA. Temporal model\nB. Reality model\nC. Probability model\nD. In all three models, temporal, reality and probability model",
      "definition": "A. Temporal model"
    },
    {
      "term": "Which data is used to use supervised approach for Machine translation\nA. Plain text\nB. Labelled text\nC. Dictionary\nD. Vectors",
      "definition": "C. Dictionary"
    },
    {
      "term": "_________ is the type of morphology that changes the word category and affects the meaning.\nA. Inflectional\nB. Derivational\nC. Cliticization\nD. All of the others",
      "definition": "B. Derivational\n3 phương án trắc nghiệm"
    },
    {
      "term": "Speech Segmentation is a subtask of Speech Recognition.\nA. TRUE\nB. FALSE",
      "definition": "A. TRUE"
    },
    {
      "term": "How many uni-grams phrases can be generated from the following sentence, after performing following text cleaning steps: Stop word Removal and Replacing punctuations by a single space i. \"Delhi is the capital of b Mumbai is the financial capital of India.\"\nA. 8\nB. 7\nC. 6\nD. 5",
      "definition": "B. 7\n3 phương án trắc nghiệm"
    },
    {
      "term": "Software designed for taking input data(text) and give structural representation of the input after checking the correct syntax or grammar is\nA. Compiler\nB. Parser\nC. Painter\nD. Easydraw",
      "definition": "A. Compiler"
    },
    {
      "term": "Lexicon, orthographic rules and spelling variations are the components of _________\nA. FST\nB. FSA\nC. Two-level morphology\nD. Stemmer Algorithm",
      "definition": "A. FST\n3 phương án trắc nghiệm"
    },
    {
      "term": "In the English language inflectional morphemes can be\nA. Prefixes, Suffixes and Infixes\nB. Suffixes only\nC. Infixes Only",
      "definition": "B. Suffixes only"
    },
    {
      "term": "There are 7 boys in the class and 3 play in the band. Thereare 8 girls in the class and 2 play in the band. What is theprobability of selecting a boy band member?\nA. 1/5\nB. 2/5\nC 3/5\nD. 4/5",
      "definition": "C 3/5\n3 phương án trắc nghiệm"
    },
    {
      "term": "Dissimilarity between words expressed using cosine similarity will have values significantly higher than 0.5\nA. True\nB. False",
      "definition": "A. True"
    },
    {
      "term": "Which one of the following is not a pre-processing technique in NLP?\nA. Stemming and Lemmatization\nB. converting to lowercase\nC. removing punctuations\nD. removal of stop words\nE. Sentiment analysis",
      "definition": "E. Sentiment analysis"
    },
    {
      "term": "Markov chains can have more than one invariant distribution.\nA. True\nB. False",
      "definition": "A. True"
    },
    {
      "term": "Which of the following statement is (are) true for Word2Vec model?\nA. The architecture of word2vec consists of only two layers - continuous bag of words and skip-gram model\nB. Continuous bag of word (CBOW) is a Recurrent Neural Network model\nC. Both CBOW and Skip-gram are shallow neural network models\nD. All of the others",
      "definition": "C. Both CBOW and Skip-gram are shallow neural network models"
    },
    {
      "term": "The word bank can be (river bank or financial institution) it denotes\nA. Antonymy\nB. Polysemy\nC. Homonyms\nD. Synonymy",
      "definition": "B. Polysemy"
    },
    {
      "term": "Connectionist Approach is based on\nA. The interconnection of networks having simple processing units with knowledge stored in weights to identify connections between units.\nB. It performs extensive analysis of linguistic phenomena through explicit representation of facts about language and well-understood knowledge representation schemas and associated algorithms.\nC. It harnesses various mathematical techniques and often uses large text corpora to develop approximately generalized models of linguistic phenomena based on actual examples.\nD. None of Above",
      "definition": "A. The interconnection of networks having simple processing units with knowledge stored in weights to identify connections between units.\n3 phương án trắc nghiệm"
    },
    {
      "term": "Morphemes that cannot stand alone and are typically attached to another to become a meaningful word is called,\nA. Free morphemes\nB. Bound morphemes\nC. Derived morphemes\nD. Lexical morphemes",
      "definition": "B. Bound morphemes"
    },
    {
      "term": "What is Machine Translation?\nA. Converts one human language to another\nB. Converts human language to machine language\nC. Converts any human language to English\nD. Converts Machine language to human language",
      "definition": "A. Converts one human language to another"
    },
    {
      "term": "The more hidden layers a neural network has, the better it can predict desired outputs for new inputs that it was not trained with.\nA. True\nB. False",
      "definition": "B. False"
    },
    {
      "term": "Which of the following is used to mapping sentence plan into sentence structure?\nA. Text planning\nB. Sentence planning\nC. Text Realization\nD. All of the others",
      "definition": "C. Text Realization"
    },
    {
      "term": "The most widely used stemmer algorithm is\nA. Viterbi Algorithm\nB. Porter Algorithm\nC. Decision Algorithm\nD. Stemmer Algorithm",
      "definition": "B. Porter Algorithm"
    },
    {
      "term": "You created a document term matrix on the input data of 20K documents for a Machine learning model. Which of the following can be used to reduce the dimensions of data?\n1. Keyword Normalization\n2. Latent Semantic Indexing\n3. Latent Dirichlet Allocation\nA. only 1\nB. 2, 3\nC. 1,3\nD. 1, 2, 3",
      "definition": "D. 1, 2, 3\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following models can be used for the purpose of document similarity?\nA. Training a word 2 vector model on the corpus that learns context present in the document\nB. Training a bag of words model that learns occurrence of words in the document\nC. Creating a document-term matrix and using cosine similarity for each document\nD. All of the others",
      "definition": "D. All of the others"
    },
    {
      "term": "What is morphology?\nA. The study of the rules governing the sounds that form words\nB. The study of the rules governing sentence formation\nC. The study of the rules governing word formation\nD. The study of the rules governing sounds",
      "definition": "C. The study of the rules governing word formation"
    },
    {
      "term": "In a corpus of N documents, one randomly chosen document contains a total of T terms and the term \"hello\" appears K times. What is the correct value for the product of TF (term frequency) and IDF (inverse-document-frequency), if the term \"hello\" appears in approximately one-third of the total documents? A. KT * Log(3)\nB. T * Log(3)/K\nC. K * Log(3)/T\nD. Log(3)/KT",
      "definition": "C. K * Log(3)/T\n3 phương án trắc nghiệm"
    },
    {
      "term": "What does 'discourse' refer to in the study of language?\nA. the vocabulary of a text\nB. the structure, organisation and layout of a text\nC. the meaning behind the vocabulary of a text\nD. the mode of a text",
      "definition": "B. the structure, organisation and layout of a text"
    },
    {
      "term": "Given a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\")\nA. Anaphora Resolution\nB. Coreference Resolution\nC. Noun Resolution\nD. Pronoun Resolution",
      "definition": "B. Coreference Resolution\n3 phương án trắc nghiệm"
    },
    {
      "term": "Elements of Semantic analysis\nA. Hyponymy\nB. Homonymy\nC. Polysemy\nD. Hyponymy, Homonymy, Polysemy",
      "definition": "D. Hyponymy, Homonymy, Polysemy"
    },
    {
      "term": "Parsing determines Parse Trees (Grammatical Analysis) for a given sentence.\nA. TRUE\nB. FALSE",
      "definition": "A. TRUE"
    },
    {
      "term": "What Pragmatic Analysis does?\nA. This component transfers linear sequences of words into structures.\nB. This only abstracts the dictionary meaning or the real meaning from the given context.\nC. This component transfers linear sequences of words into structures. It shows how the words are associated with each other.\nD. It deals with the overall communicative and social content and its effect on interpretation. It means abstracting or deriving the meaningful use of language in situations.",
      "definition": "D. It deals with the overall communicative and social content and its effect on interpretation. It means abstracting or deriving the meaningful use of language in situations.\n3 phương án trắc nghiệm"
    },
    {
      "term": "In NLP, The algorithm decreases the weight for commonly used words and increases the weight for words that are not used very much in a collection of documents\nA. Term Frequency (TF)\nB. Inverse Document Frequency (IDF)\nC. Word2Vec\nD. Latent Dirichlet Allocation (LDA)",
      "definition": "B. Inverse Document Frequency (IDF)\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following is not true input for the NLP?\nA. Image\nB. Text\nC. Types input\nD. Speech",
      "definition": "A. Image\n3 phương án trắc nghiệm"
    },
    {
      "term": "Different learning methods does not include?\nA. Memorization\nB. Analogy\nC. Deduction\nD. Introduction",
      "definition": "D. Introduction"
    },
    {
      "term": "To whether \"duck\" is a verb or a noun can be solved by _________\nA. Part-of-speech tagging.\nB. Lexical analysis\nC. Semantic analysis\nD. Pragmatic analysis",
      "definition": "A. Part-of-speech tagging.\n3 phương án trắc nghiệm"
    },
    {
      "term": "Morphological analysis is also known as\nA. Sentiment Analysis\nB. Pragmatic Analysis.\nC. CNN\nD. Lexical Analysis",
      "definition": "D. Lexical Analysis\n3 phương án trắc nghiệm"
    },
    {
      "term": "P(rolling an even number or a prime number) on a die\nA. 5/6\nB. 1/6\nC. 1/3\nD. 2/3",
      "definition": "A. 5/6\n3 phương án trắc nghiệm"
    },
    {
      "term": "In linguistic morphology ___________ is the process for reducing inflected words to their root form.\nA. Rooting\nB. Stemming\nC. Text-Proofing\nD. Both Rooting & Stemming",
      "definition": "B. Stemming\n3 phương án trắc nghiệm"
    },
    {
      "term": "The process of converting data to something a computer can understand is referred to as __________\nA. Post processing\nB. Pre processing\nC. Pre defined\nD. Post defined",
      "definition": "B. Pre processing\n3 phương án trắc nghiệm"
    },
    {
      "term": "In NLP, the process of removing words like \"and\", \"is\", \"a\", \"an\", \"the\" from a sentence is called as\nA. Stemming\nB. Lemmatization\nC. Stop word\nD. All of the others",
      "definition": "C. Stop word\n3 phương án trắc nghiệm"
    },
    {
      "term": "Given a transactional dataset containing bakery products purchased by 1,000 customers, which of the following methods is most appropriate to find 'how many times a chocolate cup cake is bought when brownie and strawberry muffin are bought together.\nA. Neural Network\nB. Decision Tree\nC. K-means Clustering\nD. Association Rule Mining/Market Basket Analysis",
      "definition": "D. Association Rule Mining/Market Basket Analysis\n3 phương án trắc nghiệm"
    },
    {
      "term": "What is Morphical and Lexical Analysis?\nA. It depicts analyzing, identifying and description of the structure of words. It includes dividing a text into paragraphs, words and the sentences.\nB. This component transfers linear sequences of words into structures.\nC. This only abstracts the dictionary meaning or the real meaning from the given context.\nD. All of the others",
      "definition": "A. It depicts analyzing, identifying and description of the structure of words. It includes dividing a text into paragraphs, words and the sentences.\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which sentence describes inflectional morphology?\nA. Adding a morpheme to produce a new word but the same lexeme.\nB. Adding a morpheme to produce a new word and different lexeme.\nC. Adding a morpheme to produce the same word but different lexeme.\nD. Adding a morpheme to produce the same sentence but different lexeme.",
      "definition": "A. Adding a morpheme to produce a new word but the same lexeme."
    },
    {
      "term": "\"It is the inverse probability of the test data which is normalized by the number of words.\" This is the definition of\nA. Language Model\nB. N-gram\nC. Perplexity\nD. Laplace smoothing",
      "definition": "C. Perplexity\n3 phương án trắc nghiệm"
    },
    {
      "term": "Who discovered \"Turing Test\"?\nA. Alan Turing\nB. Venessa Turing\nC. Leibniz\nD. Descartes",
      "definition": "A. Alan Turing\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following techniques can be used for keyword normalization in NLP, the process of converting a keyword into its base form?\nA. Lemmatization\nB. Soundex\nC. Cosine Similarity\nD. N-grams",
      "definition": "A. Lemmatization"
    },
    {
      "term": "The Hidden Markov Model directly models the dependency of each hidden state on all previous hidden states.\nA. True\nB. False",
      "definition": "B. False\n1 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following is NOT a good example of cohesive device?\nA. Discourse markers\nB. Pronouns\nC. Prepositions\nD. Demonstratives",
      "definition": "C. Prepositions"
    },
    {
      "term": "A frequently used statistical model inNLP\nA. Stochestic\nB. Hybrid\nC. HMM\nD. Lengustic",
      "definition": "C. HMM"
    },
    {
      "term": "Syntactic analysis or parsing may be defined as the process of _________ the __________ of symbols in Natural language conforming to the rules of formal grammar.\nA. Analyzing & Strings\nB. Defining & Groups\nC. Reducing & Arrays\nD. Reviewing & Letters",
      "definition": "A. Analyzing & Strings\n3 phương án trắc nghiệm"
    },
    {
      "term": "Dog is hyponym of\nA. Forest\nB. Human\nC. Animal\nD. Automobile",
      "definition": "C. Animal"
    },
    {
      "term": "The Area Of Ai That Investigates Methods Of Facilitating Communication Between People And Computers Is:\nA. Natural Language Processing\nB. Symbolic Processing\nC. Decision Support\nD. Robotics",
      "definition": "A. Natural Language Processing\n3 phương án trắc nghiệm"
    },
    {
      "term": "One of the main challenge/s of NLP is ________\nA. Handling Tokenization\nB. Handling Ambiguity of Sentences\nC. Handling POS-Tagging\nD. All of the others",
      "definition": "B. Handling Ambiguity of Sentences\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the text parsing techniques can be used for noun phrase detection, verb phrase detection, subject detection, and object detection in NLP.\nA. Part of speech tagging\nB. Skip Gram and N-Gram extraction\nC. Continuous Bag of Words\nD. Dependency Parsing and Constituency Parsing",
      "definition": "D. Dependency Parsing and Constituency Parsing"
    },
    {
      "term": "The collection of documents, required for text analysis is known as\nA. Dictionary\nB. Lexicon\nC. Corpus\nD. Stemming",
      "definition": "C. Corpus\n3 phương án trắc nghiệm"
    },
    {
      "term": "Corpus Based Approach is also called ________\nA. Statistical Approach\nB. Rule Based Approach\nC. CNN\nD. K- nearest",
      "definition": "A. Statistical Approach\n3 phương án trắc nghiệm"
    },
    {
      "term": "The words \"bank/data bank/blood bank\" is an example of\nA. Homophony\nB. Synonymy\nC. Polysemy\nD. Hyponymy",
      "definition": "C. Polysemy\n3 phương án trắc nghiệm"
    },
    {
      "term": "What refers to a situation where the context of a phrase gives it multiple interpretations?\nA. Lexical Ambiguity\nB. Scope Ambiguity\nC. Semantic Ambiguity\nD. Pragmatic Ambiguity",
      "definition": "D. Pragmatic Ambiguity\n3 phương án trắc nghiệm"
    },
    {
      "term": "What are the possible values of the variable?\nA. Variables\nB. Literals\nC. Discrete variable\nD. Possible states of the world",
      "definition": "D. Possible states of the world"
    },
    {
      "term": "Choose form the following areas where NLP can be useful.\nA. Automatic Text Summarization\nB. Automatic Question-Answering Systems\nC. Information Retrieval\nD. All of the others",
      "definition": "D. All of the others"
    },
    {
      "term": "Symbolic Approach is also called ________\nA. Convolutional Neural Networks.\nB. Rule based Approach.\nC. Corpus based.\nD. Hybrid.",
      "definition": "B. Rule based Approach\n3 phương án trắc nghiệm"
    },
    {
      "term": "\"He lifted the beetle with red cap.\" contain which type of ambiguity?\nA. Lexical ambiguity\nB. Syntax Level ambiguity\nC. Referential ambiguity\nD. All of the mentioned",
      "definition": "B. Syntax Level ambiguity"
    },
    {
      "term": "Which is not type of Sentiment Analysis?\nA. Emotion Detection\nB. Aspect based\nC. Word based\nD. Bilingual",
      "definition": "C. Word based\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following techniques can be used to compute the distance between two word vectors in NLP? (select 2)\nA. Lemmatization\nB. Euclidean distance\nC. Cosine Similarity\nD. N-grams",
      "definition": "B. Euclidean distance\nC. Cosine Similarity\n3 phương án trắc nghiệm"
    },
    {
      "term": "Dictionary-based sentiment analysis is a computational approach relies on a pre-defined list (or dictionary) of sentiment-laden words.\nA. probability model.\nB. a pre-defined list of sentiment-laden words.\nC. CRF\nD. HMM",
      "definition": "B. a pre-defined list of sentiment-laden words.\n3 phương án trắc nghiệm"
    },
    {
      "term": "Examples of NLP?\nA. Digital assistance, chatbots, Text summarization, text retrieval, sentiment analysis, translation etc.\nB. Clustering and differentiating patterns.\nC. Deep Learning, Machine Learning, Al etc.\nD. None of Above",
      "definition": "A. Digital assistance, chatbots, Text summarization, text retrieval, sentiment analysis, translation etc.\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following component of NLP?\nA. Pragmatic analysis\nB. Entity extraction\nC. Syntactic analysis\nD. All of the others",
      "definition": "D. All of the others\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following is/are the input(s) to k-means algorithm? (select 3)\nA. Number of clusters\nB. Class labels\nC. Distance metric\nD. Number of centroids",
      "definition": "A. Number of clusters\nC. Distance metric\nD. Number of centroids"
    },
    {
      "term": "Function morphemes are also called __________\nA. open-class morphemes.\nB. sub-class morphemes\nC. super-class morphemes\nD. closed-class morphemes",
      "definition": "D. closed-class morphemes\n3 phương án trắc nghiệm"
    },
    {
      "term": "Natural Language Processing (NLP) is the field of\nA. Artificial Intelligence\nB. Computer Science\nC. Linguistics\nD. All of the others",
      "definition": "D. All of the others"
    },
    {
      "term": "_________ depicts analyzing, identifying and description of the structure of words.\nA. Tokens\nB. Semantic Analysis\nC. Symbolic Analysis\nD. Morphical And Lexical Analysis",
      "definition": "D. Morphical And Lexical Analysis\n3 phương án trắc nghiệm"
    },
    {
      "term": "What is outcome thinking?\nA. Knowing what you want rather than what you don't want.\nB. Know about others\nC. Know about the society None\nD. language",
      "definition": "A. Knowing what you want rather than what you don't want.\n3 phương án trắc nghiệm"
    },
    {
      "term": "How to use WordNet to measure semantic relatedness between words:\nA. Measure the shortest path between two words on WordNet\nB. Count the number of shared parent nodes\nC. Measure the difference between their depths in WordNet\nD. Measure the difference between the size of child nodes they have",
      "definition": "A. Measure the shortest path between two words on WordNet\n3 phương án trắc nghiệm"
    },
    {
      "term": "_________ is an advanced version of FSA (finite state automata) and is used to represent the lexicon computationally.\nA. FST\nB. FSA\nC. DAWG\nD. Stemmer Algorithm",
      "definition": "A. FST\n3 phương án trắc nghiệm"
    },
    {
      "term": "It is not word embedding library\nA. Word2vec\nB. Glove\nC. Fasttext\nD. TextBlog",
      "definition": "D. TextBlog\n3 phương án trắc nghiệm"
    },
    {
      "term": "two or more words with the same form and related meanings by extension (foot of a person, of a bed, of a mountain); based on similarity\nA. Metonymy\nB. hyponymy\nC. polysemy\nD. hyponym",
      "definition": "C. polysemy\n3 phương án trắc nghiệm"
    },
    {
      "term": "What Creates Problems In Machine Translation?\nA. Different Level Of Ambiguities\nB. Processing Power\nC. Memory\nD. Diversity",
      "definition": "A. Different Level Of Ambiguities\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following is an advantage of normalizing a word? (select 2) (Choose 2 answers)\nA. It helps in reducing the randomness in the word\nB. It increases the false negatives\nC. It reduces the dimensionality of the input\nD. All of the others",
      "definition": "A. It helps in reducing the randomness in the word\nC. It reduces the dimensionality of the input\n2 phương án trắc nghiệm"
    },
    {
      "term": "Morphotactics is a model of\nA. Spelling modifications that may occur during affixation\nB. How and which morphemes can be affixed to a stem\nC. All affixes in the English language\nD. N-grams of affixes and stems",
      "definition": "B. How and which morphemes can be affixed to a stem\n3 phương án trắc nghiệm"
    },
    {
      "term": "What is FSA (Finite State Automata)?\nA. Finite state automaton is a model of behavior composed of state, transitions and actions.\nB. This consists of rules which map the two representations to each other. Each rule is described through a finite-state transducer\nC. It takes raw corpus as input and produces a segmentation of the word forms observed in the text.\nD. None of the others",
      "definition": "A. Finite state automaton is a model of behavior composed of state, transitions and actions.\n3 phương án trắc nghiệm"
    },
    {
      "term": "What is corpus?\nA. A corpus is collection of Parameters and arguments\nB. A corpus is a large and structured set of machine-readable texts that have been produced in a natural communicative setting\nC. It refers to a situation where the context of a phrase gives it multiple interpretation\nD. All of the others",
      "definition": "B. A corpus is a large and structured set of machine-readable texts that have been produced in a natural communicative setting\n3 phương án trắc nghiệm"
    },
    {
      "term": "_ morphology is a type of word formation that creates new lexemes\nA. Derivational morphology\nB. Compound morphology\nC. Inflectional morphology\nD. Complex morphology",
      "definition": "A. Derivational morphology"
    },
    {
      "term": "When the meaning of the words themselves can be misinterpreted then ___ ambiguity occurs.",
      "definition": "Semantic Ambiguity"
    },
    {
      "term": "It is not word embedding library",
      "definition": "TextBlog"
    },
    {
      "term": "What is corpus?",
      "definition": "A corpus is a large and structured set of machine-readable texts that have been produced in a natural communicative setting"
    },
    {
      "term": "In NLP, The process of removing words like \"and\", \"is\", \"a\", \"an\", \"the\" from a sentence is called as",
      "definition": "Stop word"
    },
    {
      "term": "What is the number of trigrams in a normalized sentence of length n words?",
      "definition": "n-2"
    },
    {
      "term": "What is FSA (Finite State Automata)?",
      "definition": "Finite state automaton is a model of behavior composed of state, transitions and actions."
    },
    {
      "term": "In NLP, The process of converting a sentence or paragraph into tokens is referred to as Stemming",
      "definition": "False"
    },
    {
      "term": "What are the approaches of NLP?",
      "definition": "Morphological and Lexical Analysis, Syntactic Analysis, Semantic Analysis, Discourse Integration, Pragmatic Analysis"
    },
    {
      "term": "___ Is The Type Of Morphology That Changes The Word Category And Affects The Meaning.",
      "definition": "Derivational"
    },
    {
      "term": "When we encounter two or more words with the same form and related meanings, we have what is known as ___",
      "definition": "Polysemy"
    },
    {
      "term": "P(rolling an even number or a prime number) on a die",
      "definition": "5/6"
    },
    {
      "term": "P(rolling an odd number or a # >4) on a die А. 5/6",
      "definition": "2/3"
    },
    {
      "term": "Syntactic analysis or parsing may be defined as the process of ___ the ___ of symbols in Natural language conforming to the rules of formal grammar.",
      "definition": "Analyzing & Strings"
    },
    {
      "term": "The branches of linguistics that focus on the meaning of a language",
      "definition": "Semantics & pragmatics"
    },
    {
      "term": "This involves analysis of the words in a sentence by following the grammatical structure of the sentence",
      "definition": "Syntax Analysis"
    },
    {
      "term": "What Can Be Called As \"The Knowledge Of What Has Been Said Earlier\"",
      "definition": "Co-Textual Context"
    },
    {
      "term": "Discrete representation, aka integerized words",
      "definition": "pre-cursor to words as vectors"
    },
    {
      "term": "___ ambiguity refers to a situation where the context of a phrase gives it multiple interpretation",
      "definition": "Pragmatic"
    },
    {
      "term": "How to use WordNet to measure semantic relatedness between words:",
      "definition": "Measure the shortest path between two words on WordNet"
    },
    {
      "term": "Suppose you have the following training data for Naive Bayes: Really tasty dish [LABEL = POS] What is the unsmoothed Maximum Likelihood Estimate (MLE) of P(POS) for this data?",
      "definition": "2/3"
    },
    {
      "term": "Which application use to determine people in context?",
      "definition": "Named entity recognition"
    },
    {
      "term": "The Area Of Ai That Investigates Methods Of Facilitating Communication Between People And Computers Is:",
      "definition": "Natural Language Processing"
    },
    {
      "term": "___ used for stripping of affixes. It uses a set of rules containing a list of stems and replacement rules.",
      "definition": "Stemmer"
    },
    {
      "term": "Morphotactics is a model of",
      "definition": "How and which morphemes can be affixed to a stem"
    },
    {
      "term": "Which of the following component of NLP?",
      "definition": "All of the others"
    },
    {
      "term": "What are the two subfields of Natural Language Processing?",
      "definition": "Generation and Understanding"
    },
    {
      "term": "What is the main challenge/s of NLP?",
      "definition": "All of the mentioned"
    },
    {
      "term": "An example of unstructured data is ___.",
      "definition": "customer reviews"
    },
    {
      "term": "What are the components of Morphological Analyzer acc., to Shrivastava et. al 2005?",
      "definition": "The recognition engine, identifying suffixes, and finding a stem within the input word algorithms"
    },
    {
      "term": "Dictionary-based sentiment analysis is a computational approach relies on a pre-defined list (or dictionary) of sentiment-laden words.",
      "definition": "a pre-defined list of sentiment-laden words."
    },
    {
      "term": "two or more words with the same form and related meanings by extension (foot of a person, of a bed, of a mountain); based on similarity",
      "definition": "polysemy"
    },
    {
      "term": "Who discovered \"Turing Test\"?",
      "definition": "Alan Turing"
    },
    {
      "term": "What pragmatic ambiguity refers?",
      "definition": "It refers to a situation where the context of a phrase gives it multiple interpretation"
    },
    {
      "term": "NLP stands for Natural Language Processing.",
      "definition": "True"
    },
    {
      "term": "Which of the following technique is used to remove semantic ambiguity?",
      "definition": "Word Sense Disambiguation"
    },
    {
      "term": "Which of the following is an advantage of normalizing a word? (select 2)",
      "definition": "It helps in reducing the randomness in the word   It reduces the dimensionality of the input"
    },
    {
      "term": "What is outcome thinking?",
      "definition": "Knowing what you want rather than what you don't want."
    },
    {
      "term": "___ is also known as shallow parsing.",
      "definition": "Chunking"
    },
    {
      "term": "Parts-of-Speech tagging Does not determine ___",
      "definition": "all part-of-speech for a specific stem from input"
    },
    {
      "term": "The process of converting data to something a computer can understand is referred to as ___",
      "definition": "Pre processing"
    },
    {
      "term": "\"He doesn't know\" is an example of ___ type of deixis",
      "definition": "Personal"
    },
    {
      "term": "IR (information Retrieval) and IE (Information Extraction) are the two same thing",
      "definition": "FALSE"
    },
    {
      "term": "How many trigrams phrases can be generated from the following sentence, after performing stop word removal?\nGoogle is one of the most widely used search engine in Vietnam.\nA. 2\nB. 3\nC. 4\nD. 5",
      "definition": "A. 2 (theo đáp án của SGK nước ngoà)"
    },
    {
      "term": "What Creates Problems In Machine Translation?",
      "definition": "Different Level Of Ambiguities"
    },
    {
      "term": "The collection of documents, required for text analysis is known as ___",
      "definition": "Corpus"
    },
    {
      "term": "Which of the following is not a problem when using Maximum Likelihood Estimation to obtain parameters in a language model?",
      "definition": "Smoothing"
    },
    {
      "term": "___ is an advanced version of FSA (finite state automata) and is used to represent the lexicon computationally.",
      "definition": "FST"
    },
    {
      "term": "Which is not type of Sentiment Analysis?",
      "definition": "Bilingual"
    },
    {
      "term": "This type of automata maps between two sets of symbols.",
      "definition": "FST"
    },
    {
      "term": "___ is a phrase whose head is a noun or a pronoun, optionally accompanied by a set of modifiers.",
      "definition": "Noun Phrase"
    },
    {
      "term": "_______is the type of morphology that changes the word category and affects the meaning.\nA. Inflectional\nB. Derivational\nC. Cliticization\nD. All of the others",
      "definition": "B. Derivational"
    },
    {
      "term": "OCR (Optical Character Recognition) uses NLP.\nA. TRUE\nB. FALSE",
      "definition": "A. TRUE"
    },
    {
      "term": "_ concerns how the immediately preceding sentences affect the interpretation of the next sentence\nA. Pragmatics\nB. Syntax\nC. Discourse\nD. Semantics",
      "definition": "C. Discourse"
    },
    {
      "term": "Given a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects\n('entities\")\nA. Anaphora Resolution\nB. Coreference Resolution\nC. Noun Resolution\nD. Pronoun Resolution",
      "definition": "B. Coreference Resolution"
    },
    {
      "term": "Lexicon, orthographic rules and spelling variations are the components of____\nA. FST\nB. FSA\nC. Two-level morphology\nD. Stemmer Algorithm",
      "definition": "A. FST"
    },
    {
      "term": "You created a document term matrix on the input data of 20K documents for a Machine learning model. Which\nof the following can be used to reduce the dimensions of data?\n1. Keyword Normalization\n2. Latent Semantic Indexing\n3. Latent Dirichlet Allocation\nA. only 1\nB. 2,3\nC. 1, 3\nD. 1, 2, 3",
      "definition": "D. 1, 2, 3"
    },
    {
      "term": "____transfers linear sequences of words into structures\nA. Semantic Analysis\nB. Tokens\nC. Lexical Analysis\nD. Discourse",
      "definition": "A. Semantic Analysis"
    },
    {
      "term": "Given a sound clip of a person or people speaking, determine the textual representation of the speech.\nA. Text-to-speech\nB. Speech-to-text\nC. All of the mentioned\nD. None of the others",
      "definition": "B. Speech-to-text"
    },
    {
      "term": "There are 7 boys in the class and 3 play in the band. Thereare 8 girls in the class and 2 play in the band. What is theprobability of selecting a boy band member?\nA. 1/5\nB. 2/5\nC. 3/5\nD. 4/5\nCON",
      "definition": "A. 1/5"
    },
    {
      "term": "Given a stream of text, Named Entity Recognition determines which pronoun maps to which noun.\nA. TRUE\nB. FALSE",
      "definition": "B. FALSE"
    },
    {
      "term": "How many uni-grams phrases can be generated from the following sentence, after performing following text cleaning steps: Stop word Removal and Replacing punctuations by a single space i. \"Delhi is the capital of but\nMumbai is the financial capital of India.\"\nA. 8\nB. 7\nC. 6\nD. 5",
      "definition": "C. 6"
    },
    {
      "term": "In a corpus of N documents, one randomly chosen document contains a total of T terms and the term \"hello\"\nappears K times.\nWhat is the correct value for the product of TF (term frequency) and IDF (inverse-document-frequency), if the\nterm \"hello\" appears in approximately one-third of the total documents?\nA. KT * Log(3)\nB. T * Log(3) / K\nC. K * Log(3) / T\nD. Log(3) / KT",
      "definition": "C. K * Log(3) / T"
    },
    {
      "term": "Operators and Quantifiers are mostly responsible for\nA. Scope Ambiguity\nB. Pragmatic Ambiguity\nC. Semantic Ambiguity\nD. None of These",
      "definition": "A. Scope Ambiguity"
    },
    {
      "term": "___extracts all the documents containing the key words\nA. Information Extraction\nB. Information Retrieval\nC. Inflection\nD. Inflation",
      "definition": "B. Information Retrieval"
    },
    {
      "term": "Connectionist Approach is based on\nA. The interconnection of networks having simple processing units with knowledge stored in weights to identify connections between units.\nB. It performs extensive analysis of linguistic phenomena through explicit representation of facts about language and well-understood knowledge representation schemas and associated algorithms.\nC. It harnesses various mathematical techniques and often uses large text corpora to deveiop approximately\ngeneralized models of linguistic phenomena based on actual examples.\nD. None of Above",
      "definition": "A. The interconnection of networks having simple processing units with knowledge stored in weights to identify connections between units."
    },
    {
      "term": "Natural language processing is divided into the two subfields of\nA. symbolic and numeric\nB. algorithmic and heuristic\nC. time and motion\nD. understanding and generation",
      "definition": "D. understanding and generation"
    },
    {
      "term": "What is 'indefinite noun phrases' in reference phonomena?\nA. Introduces entities that are new to the hearer into the discourse context\nB. Introduces entities that are previous or old to the hearer into the discourse context\nC. Entities that accept the irregular pharses\nD. Entities that accept the regular pharses",
      "definition": "A. Introduces entities that are new to the hearer into the discourse context"
    },
    {
      "term": "It focuses about the proper ordering of words which can affect its meaning.\nA. Syntax Analysis\nB. Semantic Analysis\nC. Lexical Analysis\nD. Pragmatic Analysis",
      "definition": "A. Syntax Analysis"
    },
    {
      "term": "Which of the following NLP tasks use sequential labeling technique?\nA. POS tagging\nB. Named Entity Recognition\nC. Speech recognition\nD. All of the others",
      "definition": "D. All of the others"
    },
    {
      "term": "Connectionist Approach is widely known as___\nA. Statistical\nB. Symbolical\nC. Neural Network\nD. All of the others",
      "definition": "C. Neural Network"
    },
    {
      "term": "Which of the following is not true input for the NLP?\nA. Image\nB. Text\nC. Types input cent\nD. Speech",
      "definition": "A. Image"
    },
    {
      "term": "Which of the following is not an algorithm for decoding convolution codes?\nA. Viterbi algorithm\nB. Stack algorithm\nC. Fano's sequential coding\nD. Ant colony optimization",
      "definition": "D. Ant colony optimization"
    },
    {
      "term": "Typing buckled when you meant bucked is a type of which Spelling error\nA. Non-word Errors\nB. Real Word Errors\nC. Cognitive Errors\nD. Short forms/Slang/Lingo",
      "definition": "B. Real Word Errors"
    },
    {
      "term": "\"The car hit the pole while it was moving.\" what type of ambiguity exists in above sentence?\nA. Semantic\nB. Syntactic\nC. Lexical\nD. Pragmatic",
      "definition": "A. Semantic"
    },
    {
      "term": "-Cluster analysis: category of unsupervised learningtechniquies that allow us to discover hidden structures in\ndatawhere we do not know right answer up front\nGoal: find natural groupings in data such that items in thesame cluster are more similar to each other than\nthose indifferent clusters\n-K-Means is most popular clustering\nA. How multi-layer perceptron (MLP) functions (steps)\nB. Concept-based Approach (what, how, weaknesses)\nC. K-Means Clustering (define clustering and goal)\nD. Dictionary-based/Keyword Spotting (what, how, weaknesses)",
      "definition": "C. K-Means Clustering (define clustering and goal)"
    },
    {
      "term": "___deals with the overall communicative and social content and its effect on interpretation.\nA. Tokens\nB. Pragmatic Analysis\nC. Symbolic Analysis\nD. Morphical And Lexical Analysis",
      "definition": "B. Pragmatic AnalysisWord embeddings capture multiple dimensions of data and are represented as vectors"
    },
    {
      "term": "Word embeddings capture multiple dimensions of data and are represented as vectors\nA. True\nB. False",
      "definition": "A. True"
    },
    {
      "term": "___also converts a word to its root form.\nA. Rooting\nB. Dreaming\nC. Steaming\nD. Lemmatization",
      "definition": "D. Lemmatization"
    },
    {
      "term": "Function morphemes are also called___\nA. open-class morphemes\nB. sub-class morphemes\nC.super-class morphemes\nD. closed-class morphemes",
      "definition": "D. closed-class morphemes"
    },
    {
      "term": "What are the components of NLP?\nA. Morphological and Lexical Analysis\nB. Syntactic Analysis and Semantic Analysis\nC. Discourse Integration, Pragmatic Analysis\nD. All of the others",
      "definition": "D. All of the others"
    },
    {
      "term": "The reference to an entity that has been previously introduced into the sentence is called as\nA. discourse\nB. anaphora\nC. co refer\nD. referent",
      "definition": "B. anaphora"
    },
    {
      "term": "In the sentence, \"They bought a blue house\", the underlined part (a blue house) is an example of\nA. Noun phrase\nB. Verb phrase\nC. Prepositional phrase\nD. Adverbial phrase",
      "definition": "A. Noun phrase"
    },
    {
      "term": "A Bidirectional Feedback Loop Links Computer Modelling With:\nA. Artificial Science\nB. Heuristic Processing\nC. Human Intelligence\nD. Cognitive Science",
      "definition": "D. Cognitive Science"
    },
    {
      "term": "Statistical Approach is also called\nA. Corpus Based Approach\nB. Rule Based Approach\nC. CNN\nD. K- nearest",
      "definition": "A. Corpus Based Approach"
    },
    {
      "term": "How to implement NLP?\nA. Machine Learning & Statistical Inference.\nB. Machine Learning & Al\nC. Deep Learning\nD. Python & R",
      "definition": "A. Machine Learning & Statistical Inference."
    },
    {
      "term": "What is the right order for a text classification model components?\n1. Text cleaning\n2. Text annotation\n3. Gradient descent\n4. Model tuning\n5. Text to predictors\nA. 12345\nB. 13425\nC. 12534\nD. 13452",
      "definition": "C. 12534"
    },
    {
      "term": "Finite State Transducer is an advanced version of______and is used to represent the lexicon computationally.\nA. FST\nB. FSA\nC. DAWG\nD.Stemmer Algorithm",
      "definition": "B. FSA"
    },
    {
      "term": "is the process of extracting phrases from unstructured text and more structure to it.\nA. Rooting\nB. Chunking\nC. Steaming\nD. Lemmatization",
      "definition": "B. Chunking"
    },
    {
      "term": "Generating natural, conversational language that explains complex concepts in a way that is easy to consume.\nA. Intuitive\nB. Relevant\nC. Timely\nD. Space",
      "definition": "B. Relevant"
    },
    {
      "term": "What is Syntax Analysis?\nA. This only abstracts the dictionary meaning or the real meaning from the given context.\nB.This component transfers linear sequences of words into structures. It shows how the words are associated with each other.\nC. It deals with the overall communicative and social content and its effect on interpretation. It means abstracting or deriving the meaningful use of language in situations.\nD. It focuses about the proper ordering of words which can affect its meaning. This involves analysis of the words in a sentence by following the grammatical structure of the sentence. The words are transformed into\nthe structure to show how the words are related to each other.",
      "definition": "D. It focuses about the proper ordering of words which can affect its meaning. This involves analysis of the words in a sentence by following the grammatical structure of the sentence. The words are transformed into"
    },
    {
      "term": "The study of the sound patterns in natural language and the rules that govern them is:\nA. Phonetics\nB. Morphology\nC. Phonology\nD. Syntax",
      "definition": "C. Phonology"
    },
    {
      "term": "Consider the language L = (a^nb^nc^m| m, n >=0}. Which of the following strings are in L?\nA. abbe\nB. ab\nC. aabc\nD. abbec",
      "definition": "B. ab"
    },
    {
      "term": "\"He was running quickly into the stadium\". What type of phrase is this?\nA. Noun phrase\nB. Verb phrase\nC. Prepositional phrase\nD. Adjectival phrase",
      "definition": "B. Verb phrase"
    },
    {
      "term": "Which of the following techniques can be used for the purpose of keyword normalization, the proces converting a keyword into its meaningful base form?\nA. Lemmatization\nB. Levenshtein distance\nC. Morphing\nD. Stemming\nRUOMER",
      "definition": "A. Lemmatization"
    },
    {
      "term": "Corpus Based Approach is also called\nA. Statistical Approach\nB. Rule Based Approach\nC. CNN\nD. K- nearest",
      "definition": "A. Statistical Approach"
    },
    {
      "term": "Which is a finite state machine with two tapes: an input tape and an output tape\nA. Finite State Transducers (FSTs)\nB. Finite State Translators (FSTs)\nC. Finite Automata\nD. Deterministic Finite Automaton",
      "definition": "A. Finite State Transducers (FSTs)"
    },
    {
      "term": "NLP is concerned with the interactions between computers and human (natural) languages.\nA. True\nB. False",
      "definition": "A. True"
    },
    {
      "term": "What are the possible features of a text corpus in NLP?\nA. Count of the word in a document\nB. Vector notation of the word\nC. Part of Speech Tag\nD. Basic Dependency Grammar\nE. All of the others",
      "definition": "E. All of the others"
    },
    {
      "term": "What will be the perplexity value if you calculate the perplexity of an unsmoothed language model or corpus with unseen words?\nA. Zero\nB. Infinity\nC. Any Non-Zero Value\nD. Inefficient",
      "definition": "B. Infinity"
    },
    {
      "term": "Computer vs computational is an example of___morphology.\nA. Inflectional\nB. Derivational\nC. Cliticization\nD. All of the others",
      "definition": "B. Derivational"
    },
    {
      "term": "The Hidden Markov Model directly models the dependency of each hidden state on all previous hidden states\nA. True\nB. False",
      "definition": "B. False"
    },
    {
      "term": "In linguistic morphology__ is the process for reducing inflected wor\nA. Rooting\nB. Stemming\nC. Text-Proofing\nD. Both Rooting & Stemming",
      "definition": "B. Stemming"
    },
    {
      "term": "To whether \"duck\" is a verb or a noun can be solved by___\nA. Part-of-speech tagging.\nB. Lexical analysis\nC. Semantic analysis\nD. Pragmatic analysis",
      "definition": "A. Part-of-speech tagging."
    },
    {
      "term": "What refers to a situation where the context of a phrase gives it multiple interpretation\nA. Lexical Ambiguity\nB. Scope Ambiguity\nC. Semantic Ambiguity\nD. Pragmatic Ambiguity",
      "definition": "D. Pragmatic Ambiguity"
    },
    {
      "term": "Which of the following techniques can be used for keyword normalization in NLP, the proces\nkeyword into its base form?\nA. Lemmatization\nB. Soundex\nC. Cosine Similarity\nD. N-grams",
      "definition": "A. Lemmatization"
    },
    {
      "term": "Symbolic Approach is also called\nA. Convolutional Neural Networks.\nB. Rule based Approach.\nC. Corpus based.\nD. Hybrid",
      "definition": "B. Rule based Approach."
    },
    {
      "term": "Examples of NLP?\nA. Digital assistance, chatbots, Text summarization, text retrieval, sentiment analysis...\nB. Clustering and differentiating patterns.\nC. Deep Learning, Machine Learning, Al etc.\nD. None of Above",
      "definition": "A. Digital assistance, chatbots, Text summarization, text retrieval, sentiment analysis..."
    },
    {
      "term": "In NLP, the process of removing words like \"and\", \"is\", \"a\", \"an\", \"the\" from a sentence is called\nA. Stemming\nB. Lemmatization\nC. Stop word\nD. All of the others",
      "definition": "C. Stop word"
    },
    {
      "term": "Which of the following techniques can be used to compute the distance between two word..\n(select 2)\nA. Lemmatization\nB. Euclidean distance\nC. Cosine Similarity\nD. N-grams",
      "definition": "B. Euclidean distance\nC. Cosine Similarity"
    },
    {
      "term": "The Area Of Ai That Investigates Methods Of Facilitating Communication Between People.\nA. Natural Language Processing\nB. Symbolic Processing\nC. Decision Support\nD. Robotics",
      "definition": "A. Natural Language Processing"
    },
    {
      "term": "____depicts analyzing, identifying and description of the structure of words.\nA. Tokens\nB. Semantic Analysis\nC. Symbolic Analysis\nD. Morphical And Lexical Analysis",
      "definition": "D. Morphical And Lexical Analysis"
    },
    {
      "term": "Which of the following component of LP?\nA. Pragmatic analysis\nB. Entity extraction\nC. Syntactic analysis\nD. All of the others",
      "definition": "D. All of the others"
    },
    {
      "term": "What is Morphical and Lexical Analysis?\nA. It depicts analyzing, identifying and description of the structure of words. It includes dividing paragraphs, words and the sentences.\nB. This component transfers linear sequences of words into structures.\nC. This only abstracts the dictionary meaning or the real meaning from the given context.\nD. All of the others",
      "definition": "A. It depicts analyzing, identifying and description of the structure of words. It includes dividing paragraphs, words and the sentences."
    },
    {
      "term": "What Pragmatic Analysis does?\nA. This component transfers linear sequences of words into structures.\nB. This only abstracts the dictionary meaning or the real meaning from the given context.\nC. This component transfers linear sequences of words into structures. It shows how the v\nassociated with each other.\nD. It deals with the overall communicative and social content and its effect on interpretatio abstracting or deriving the meaningful use of language in situations",
      "definition": "D. It deals with the overall communicative and social content and its effect on interpretatio abstracting or deriving the meaningful use of language in situations"
    },
    {
      "term": "Morphological analysis is also known as__\nA. Sentiment Analysis\nB. Pragmatic Analysis\nC. CNN\nD. Lexical Analysis",
      "definition": "D. Lexical Analysis"
    },
    {
      "term": "The words \"bank/data bank/blood bank\" is an example of___\nA. Homophony\nB. Synonymy\nC. Polysemy\nD. Hyponymy",
      "definition": "C. Polysemy"
    },
    {
      "term": "How does the Statistical Approach work?\nA. It uses statistical methods to resolve some of the difficulties in symbolic approach. It does this by harnessing various mathematical techniques and often using large text corpora to develop approximately\ngeneralized models of linguistic phenomena based on actual examples.\nB. It performs extensive analysis of linguistic phenomena through explicit representation of facts about language and well-understood knowledge representation schemas and associated algorithms.\nC. It harnesses various mathematical techniques and often uses large text corpora to develop approximately generalized models of linguistic phenomena based on actual examples.\nD. All of the others",
      "definition": "A. It uses statistical methods to resolve some of the difficulties in symbolic approach. It does this by harnessing various mathematical techniques and often using large text corpora to develop approximately"
    },
    {
      "term": "What will be the perplexity value if you calculate the perplexity of an unsmoothed language model on a test corpus with unseen words?\nA. Zero\nB. Infinity\nC. Any Non-Zero Value\nD. Inefficient",
      "definition": "B. Infinity"
    },
    {
      "term": "Which of the following techniques can be used for the purpose of keyword normalization, the process of converting a keyword into its meaningful base form?\nA. Lemmatization\nB. Levenshtein distance\nC. Morphing\nD. Stemming",
      "definition": "A. Lemmatization"
    },
    {
      "term": "_____deals with the overall communicative and social content and its effect on interpretation.\nA. Tokens\nB. Pragmatic Analysis\nC. Symbolic Analysis\nD. Morphical And Lexical Analysis",
      "definition": "B. Pragmatic Analysis"
    },
    {
      "term": "Which of the following is not true input for the LP?\nA. Image\nB. Text\nC. Types input\nD. Speech",
      "definition": "A. Image"
    },
    {
      "term": "What type of architecture is a named entity recognition using?\nA. Many to many\nB. Many to one\nC. One to many",
      "definition": "A. Many to many"
    },
    {
      "term": "eg. 'do', 'eat', 'go' are examples of which type of verb\nA. Regular verb\nB. Irregular verb\nC. Complex verb\nD. Normal verb",
      "definition": "B. Irregular verb"
    },
    {
      "term": "Input layer ved sim unped per rature), one or more hiddenlayers and a output layer (w. one output per target\nA. What needs to be chosen?\nB. Feedforeword network\nC. Neural network\nD. Recurrent network",
      "definition": "C. Neural network"
    },
    {
      "term": "In add-k smoothing method, for a small k value, what would be perplexity?\nA. High perplexity\nB. Zero perplexity\nC. Low perplexity\nD. Perplexity is not disturbed",
      "definition": "A. High perplexity"
    },
    {
      "term": "Syntactical analysis is done at___level\nA. Sentence\nB. Word\nC. Lexicon\nD. Symbol",
      "definition": "A. Sentence"
    },
    {
      "term": "For HMM Model, with N hidden states, V observable states, what is the dimension of State Transition Probability Matrix\nA. N×V\nB. N×1\nC. N*N\nD. 1 For HMM Model, with N hidden states, V observable states, what is the dimension of Emission Probability *N",
      "definition": "C. N*N"
    },
    {
      "term": "The english words through and threw are examples of_\nA. Automymy\nB. Polysemy\nC. Synonymy\nD. Homophony",
      "definition": "D. Homophony"
    },
    {
      "term": "The words 'there' and their causes which of the following type of ambiguity?\nA. Syntactic\nB. Semantic\nC. Phonological\nD. Pragmatic",
      "definition": "C. Phonological"
    },
    {
      "term": "Which of the following is not correct with respect to levels of semantic analysis?\nA. Word level\nB. Character level\nC. Sentence level\nD. Utterance level",
      "definition": "B. Character level"
    },
    {
      "term": "WordNet is the___database\nA. Symbol\nB. Word\nC. Lexical|\nD. Annotation",
      "definition": "C. Lexical|"
    },
    {
      "term": "Rule-based POS taggers doesnt possess which of the following properties\nA. The rules in Rule-based POS tagging are built auto\nB. These taggers are knowledge-driven taggers\nC. These taggers are consist of many hand written rules\nD. The information is coded in the form of rules.",
      "definition": "A. The rules in Rule-based POS tagging are built auto"
    },
    {
      "term": "Two words with very closely related meanings\nA. Antonyms\nB. Homonyms\nC. Synonyms\nD. Hyponymy",
      "definition": "C. Synonyms"
    },
    {
      "term": "SVD, PCA\nA. What does a co-occurence matrix look like?\nB. Types of Prediction embeddings\nC. What are some examples of co-occurence matrix technologies?\nD. Word2vec is not a single algorithm but a combination of two techniques",
      "definition": "D. Word2vec is not a single algorithm but a combination of two techniques"
    },
    {
      "term": "Which one of the following is morpheme of the word \"unbelievable\"?\nA. un\nB. unbe\nC. evable\nD. able",
      "definition": "A. un"
    },
    {
      "term": "Video summarization extracts the most important frames from the\n__content\nA. Video\nB. Image\nC. Sound\nD. Doccument",
      "definition": "A. Video"
    },
    {
      "term": "Every word is a row, every word is a column, the number isthe number of times the two words occur in the same context\nA. CountVector could also be a\nB. What are some examples of co-occurence matrix technologies?\nC. Two types of word embeddings\nD. What does a co-occurence matrix look like?",
      "definition": "B. What are some examples of co-occurence matrix technologies?"
    },
    {
      "term": "What is corpus?\nA. A corpus is collection of Parameters and arguments\nB. Corpus is a large collection of written text belonging to a particular language\nC. It refers to a situation where the context of a phrase gives it multiple interpretation\nD. All of the others.",
      "definition": "B. Corpus is a large collection of written text belonging to a particular language"
    },
    {
      "term": "Which of the following instances the regular expression Ib(one|two|three)lb* can recognize?\nA. \"one\"\nB. \"onetwo\"\nC. 'TWO\"\nD. \"Onetwothree\"",
      "definition": "A. \"one\""
    },
    {
      "term": "a_____often called a pattern, specifies a set of strings required for a particular purpose. A simple way specify a finite set of strings is to list its elements or members.\nA. Regular Expression\nB. Non regular Expression\nC. Finite Automata\nD. None of the others",
      "definition": "A. Regular Expression"
    },
    {
      "term": "____are created by removing the suffixes or prefixes used with a word. This process is called as\nA. Stems, Stemming\nB. Lemma, Lemmatization\nC. Corpus\nD. Suffix stripping",
      "definition": "A. Stems, Stemming"
    },
    {
      "term": "The words are transformed into the structure to show how the words are related to each other. This process is called as_____\nA. Syntax Analysis\nB. Semantic Analysis\nC. Lexical Analysis\nD. Pragmatic Analysis",
      "definition": "A. Syntax Analysis"
    },
    {
      "term": "Which of the following is an advantage of normalizing a word?\nA. It quarantees word to be inconsistent\nB. It helps in reducing the randomness in the word\nC. It increases the false negatives\nD. It increases the dimensionality of the input",
      "definition": "B. It helps in reducing the randomness in the word"
    },
    {
      "term": "Which of the following measurements are used to evaluate the quality of entity recognition?Which of the following measurements are used to evaluate the quality of entity recognition?\nA. Precision\nB. Recall\nC. F-measure\nD. All of the others",
      "definition": "D. All of the others"
    },
    {
      "term": "When training a language model, if we use an overty narrow corpus, the probabilities\nA. Don't reflect the task\nB. Reflect all possible wordings\nC. Reflect intuition\nD. Don't generalize",
      "definition": "D. Don't generalize"
    },
    {
      "term": "Which of the following is not a learning approach for QA system\nA. Unsupervised approach\nB. Supervised approach\nC. Knowledge based approach\nD. Sense disambiguation approach",
      "definition": "D. Sense disambiguation approach"
    },
    {
      "term": "One of the main challenge/s of NLP is\nA. Handling Tokenization\nB. Handling Ambiguity of Sentences\nC. Handling POS-Tagging\nD. All of the others",
      "definition": "D. All of the others"
    },
    {
      "term": "History of Natural Language Processing does not include\nA. Automata Theory\nB. Compression Algorithms\nC. CFG by Chomsky\nD. Predicate and First Order Logic",
      "definition": "B. Compression Algorithms"
    },
    {
      "term": "Regular expressions are combination of simple units as given in options, select incorrect unit.\nA. Character or string\nB. Concatenation\nC. Kleen star\nD. Conjunction",
      "definition": "D. Conjunction"
    },
    {
      "term": "Which of the below are NLP use cases?\nA. Detecting objects from an image\nB. Facial Recognition\nC. Speech Biometric\nD. Text Summarization",
      "definition": "D. Text Summarization"
    },
    {
      "term": "Suppose we want to calculate a probability for the sequence of observations {'Dry','Rain'}. If the following are the possible hidden state sequences, then P('Dry' 'Rain') = ---------. {'Low', 'Low'}, {'Low', 'High'}, {'High', 'Low'}, and {'High', 'High'}",
      "definition": "P('Dry' 'Rain', 'Low' 'Low') + P('Dry' 'Rain', 'Low' 'High') + P('Dry' 'Rain', 'High' 'Low') + P('Dry' 'Rain', 'HIgh' 'High')"
    },
    {
      "term": "Which of the following techniques can be used for the purpose of keyword normalization, the process of converting a keyword into its base form? Lemmatization Levenshtein Stemming Soundex",
      "definition": "1 and 3"
    },
    {
      "term": "N-grams are defined as the combination of N keywords together. How many bi-grams can be generated from a given sentence: \"Analytics Vidhya is a great source to learn data science\"",
      "definition": "9"
    },
    {
      "term": "How many trigrams phrases can be generated from the following sentence, after performing following text cleaning steps: Stopword Removal Replacing punctuations by a single space \"#Analytics-vidhya is a great source to learn @data_science.\"",
      "definition": "5"
    },
    {
      "term": "Which of the following regular expression can be used to identify date(s) present in the text object: \"The next meetup on data science will be held on 2017-09-21, previously it happened on 31/03, 2016\"",
      "definition": "None of the above"
    },
    {
      "term": "Which of the following models can perform tweet classification with regards to context mentioned above?",
      "definition": "None of the above"
    },
    {
      "term": "You have created a document term matrix of the data, treating every tweet as one document. Which of the following is correct, in regards to document term matrix? Removal of stopwords from the data will affect the dimensionality of data Normalization of words in the data will reduce the dimensionality of data Converting all the words in lowercase will not affect the dimensionality of the data",
      "definition": "1 and 2"
    },
    {
      "term": "Which of the following features can be used for accuracy improvement of a classification model?",
      "definition": "All of these"
    },
    {
      "term": "What percentage of the total statements are correct with regards to Topic Modeling? It is a supervised learning technique LDA (Linear Discriminant Analysis) can be used to perform topic modeling Selection of number of topics in a model does not depend on the size of data Number of topic terms are directly proportional to size of the data",
      "definition": "0"
    },
    {
      "term": "In Latent Dirichlet Allocation model for text classification purposes, what does alpha and beta hyperparameter represent-",
      "definition": "Alpha: density of topics generated within documents, beta: density of terms generated within topics"
    },
    {
      "term": "Solve the equation according to the sentence \"I am planning to visit New Delhi to attend Analytics Vidhya Delhi Hackathon\". A = (# of words with Noun as the part of speech tag)B = (# of words with Verb as the part of speech tag)C = (# of words with frequency count greater than one) What are the correct values of A, B, and C?",
      "definition": "7, 4, 2"
    },
    {
      "term": "In a corpus of N documents, one document is randomly picked. The document contains a total of T terms and the term \"data\" appears K times. What is the correct value for the product of TF (term frequency) and IDF (inverse-document-frequency), if the term \"data\" appears in approximately one-third of the total documents?",
      "definition": "K * Log(3) / T"
    },
    {
      "term": "Which of the following technique is not a part of flexible text matching?",
      "definition": "Keyword Hashing"
    },
    {
      "term": "True or False: Word2Vec model is a machine learning model used to create vector notations of text objects. Word2vec contains multiple deep neural networks",
      "definition": "FALSE"
    },
    {
      "term": "Which of the following statement is(are) true for Word2Vec model?",
      "definition": "Both CBOW and Skip-gram are shallow neural network models"
    },
    {
      "term": "What is the right order for a text classification model components Text cleaning Text annotation Gradient descent Model tuning Text to predictors",
      "definition": "12534"
    },
    {
      "term": "Polysemy is defined as the coexistence of multiple meanings for a word or phrase in a text object. Which of the following models is likely the best choice to correct this problem?",
      "definition": "Convolutional Neural Networks"
    },
    {
      "term": "Which of the following models can be used for the purpose of document similarity?",
      "definition": "All of the above"
    },
    {
      "term": "While creating a machine learning model on text data, you created a document term matrix of the input data of 100K documents. Which of the following remedies can be used to reduce the dimensions of data - Latent Dirichlet Allocation Latent Semantic Indexing Keyword Normalization",
      "definition": "1, 2, 3"
    },
    {
      "term": "Google Search's feature - \"Did you mean\", is a mixture of different techniques. Which of the following techniques are likely to be ingredients? Collaborative Filtering model to detect similar user behaviors (queries) Model that checks for Levenshtein distance among the dictionary terms Translation of sentences into multiple languages",
      "definition": "1, 2, 3"
    },
    {
      "term": "While working with text data obtained from news sentences, which are structured in nature, which of the grammar-based text parsing techniques can be used for noun phrase detection, verb phrase detection, subject detection and object detection.",
      "definition": "Dependency Parsing and Constituency Parsing"
    },
    {
      "term": "Social Media platforms are the most intuitive form of text data. You are given a corpus of complete social media data of tweets. How can you create a model that suggests the hashtags?",
      "definition": "All of these"
    },
    {
      "term": "While working with context extraction from a text data, you encountered two different sentences: The tank is full of soldiers. The tank is full of nitrogen. Which of the following measures can be used to remove the problem of word sense disambiguation in the sentences?",
      "definition": "Compare the dictionary definition of an ambiguous word with the terms contained in its neighborhood"
    },
    {
      "term": "Collaborative Filtering and Content Based Models are the two popular recommendation engines, what role does NLP play in building such algorithms.",
      "definition": "All of these"
    },
    {
      "term": "Retrieval based models and Generative models are the two popular techniques used for building chatbots. Which of the following is an example of retrieval model and generative model respectively.",
      "definition": "Rule-based learning and Sequence to Sequence model"
    },
    {
      "term": "What is the major difference between CRF (Conditional Random Field) and HMM (Hidden Markov Model)?",
      "definition": "CRF is Discriminative whereas HMM is Generative model"
    },
    {
      "term": "What is the field of Natural Language Processing (NLP)?",
      "definition": "All of the mentioned"
    },
    {
      "term": "NLP is concerned with the interactions between computers and human (natural) languages.",
      "definition": "True"
    },
    {
      "term": "Modern NLP algorithms are based on machine learning, especially statistical machine learning.",
      "definition": "True"
    },
    {
      "term": "Choose form the following areas where NLP can be useful.",
      "definition": "All of the mentioned"
    },
    {
      "term": "Which of the following includes major tasks of NLP?",
      "definition": "All of the mentioned"
    },
    {
      "term": "What is Coreference Resolution?",
      "definition": "Given a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\")"
    },
    {
      "term": "What is Machine Translation?",
      "definition": "Converts one human language to another"
    },
    {
      "term": "The more general task of coreference resolution also includes identifying so-called \"bridging relationships\" involving referring expressions.",
      "definition": "True"
    },
    {
      "term": "What is Morphological Segmentation?",
      "definition": "Separate words into individual morphemes and identify the class of the morphemes"
    },
    {
      "term": "Given a stream of text, Named Entity Recognition determines which pronoun maps to which noun.",
      "definition": "False"
    },
    {
      "term": "Natural Language generation is the main task of Natural language processing.",
      "definition": "True"
    },
    {
      "term": "OCR (Optical Character Recognition) uses NLP.",
      "definition": "True"
    },
    {
      "term": "Parts-of-Speech tagging determines ___________",
      "definition": "all of the mentioned"
    },
    {
      "term": "Parsing determines Parse Trees (Grammatical Analysis) for a given sentence.",
      "definition": "True"
    },
    {
      "term": "IR (information Retrieval) and IE (Information Extraction) are the two same thing.",
      "definition": "False"
    },
    {
      "term": "Many words have more than one meaning; we have to select the meaning which makes the most sense in context. This can be resolved by ____________",
      "definition": "Word Sense Disambiguation"
    },
    {
      "term": "Given a sound clip of a person or people speaking, determine the textual representation of the speech.",
      "definition": "Speech-to-text"
    },
    {
      "term": "Speech Segmentation is a subtask of Speech Recognition.",
      "definition": "True"
    },
    {
      "term": "In linguistic morphology _____________ is the process for reducing inflected words to their root form.",
      "definition": "Stemming"
    },
    {
      "term": "Which of the following techniques can be used for keyword normalization in NLP, the process of converting a keyword into its base form?",
      "definition": "Lemmatization"
    },
    {
      "term": "Which of the following techniques can be used to compute the distance between two word vectors in NLP?",
      "definition": "b) and c)"
    },
    {
      "term": "What are the possible features of a text corpus in NLP?",
      "definition": "All of the above"
    },
    {
      "term": "You created a document term matrix on the input data of 20K documents for a Machine learning model. Which of the following can be used to reduce the dimensions of data? Keyword Normalization Latent Semantic Indexing Latent Dirichlet Allocation",
      "definition": "1, 2, 3"
    },
    {
      "term": "Which of the text parsing techniques can be used for noun phrase detection, verb phrase detection, subject detection, and object detection in NLP.",
      "definition": "Dependency Parsing and Constituency Parsing"
    },
    {
      "term": "Dissimilarity between words expressed using cosine similarity will have values significantly higher than 0.5",
      "definition": "TRUE"
    },
    {
      "term": "Which of the below are NLP use cases?",
      "definition": "Text Summarization"
    },
    {
      "term": "In NLP, The algorithm decreases the weight for commonly used words and increases the weight for words that are not used very much in a collection of documents",
      "definition": "Inverse Document Frequency (IDF)"
    },
    {
      "term": "In NLP, Tokens are converted into numbers before giving to any Neural Network",
      "definition": "True"
    },
    {
      "term": "Identify the odd one out",
      "definition": "BERT"
    },
    {
      "term": "TF-IDF helps you to establish?",
      "definition": "most important word in the document"
    },
    {
      "term": "In NLP, The process of identifying people, an organization from a given sentence, paragraph is called",
      "definition": "Named entity recognition"
    },
    {
      "term": "Which one of the following is not a pre-processing technique in NLP",
      "definition": "Sentiment analysis"
    },
    {
      "term": "In text mining, converting text into tokens and then converting them into an integer or floating-point vectors can be done using",
      "definition": "CountVectorizer"
    },
    {
      "term": "In NLP, Words represented as vectors are called as Neural Word Embeddings",
      "definition": "True"
    },
    {
      "term": "In NLP, Context modeling is supported with which one of the following word embeddings",
      "definition": "BERT"
    },
    {
      "term": "In NLP, Bidirectional context is supported by which of the following embedding",
      "definition": "BERT"
    },
    {
      "term": "Which one of the following Word embeddings can be custom trained for a specific subject in NLP",
      "definition": "BERT"
    },
    {
      "term": "Word embeddings capture multiple dimensions of data and are represented as vectors",
      "definition": "True"
    },
    {
      "term": "In NLP, Word embedding vectors help establish distance between two tokens",
      "definition": "True"
    },
    {
      "term": "Language Biases are introduced due to historical data used during training of word embeddings, which one amongst the below is not an example of bias",
      "definition": "New Delhi is to India, Beijing is to China"
    },
    {
      "term": "Which of the following will be a better choice to address NLP use cases such as semantic similarity, reading comprehension, and common sense reasoning",
      "definition": "Open AI's GPT"
    },
    {
      "term": "Transformer architecture was first introduced with?",
      "definition": "Open AI's GPT"
    },
    {
      "term": "Which of the following architecture can be trained faster and needs less amount of training data",
      "definition": "Transformer architecture"
    },
    {
      "term": "Same word can have multiple word embeddings possible with ____________?",
      "definition": "ELMo"
    },
    {
      "term": "For a given token, its input representation is the sum of embedding from the token, segment and position embedding",
      "definition": "BERT"
    },
    {
      "term": "Trains two independent LSTM language model left to right and right to left and shallowly concatenates them",
      "definition": "ELMo"
    },
    {
      "term": "Uses unidirectional language model for producing word embedding",
      "definition": "GPT"
    },
    {
      "term": "In this architecture, the relationship between all words in a sentence is modelled irrespective of their position. Which architecture is this?",
      "definition": "BERT"
    },
    {
      "term": "Transformer model pays attention to the most important word in Sentence",
      "definition": "True"
    },
    {
      "term": "Which NLP model gives the best accuracy amongst the following?",
      "definition": "XLNET"
    },
    {
      "term": "Permutation Language models is a feature of",
      "definition": "XLNET"
    },
    {
      "term": "Transformer XL uses relative positional embedding",
      "definition": "True"
    },
    {
      "term": "Which algorithm is used for solving temporal probabilistic reasoning?",
      "definition": "Hidden markov model"
    },
    {
      "term": "How does the state of the process is described in HMM?",
      "definition": "Single discrete random variable"
    },
    {
      "term": "What are the possible values of the variable?",
      "definition": "Possible states of the world"
    },
    {
      "term": "Where does the additional variables are added in HMM?",
      "definition": "Temporal model"
    },
    {
      "term": "Which allows for a simple and matrix implementation of all the basic algorithm?",
      "definition": "Restricted structure of HMM"
    },
    {
      "term": "Where does the Hidden Markov Model is used?",
      "definition": "Speech recognition"
    },
    {
      "term": "Which variable can give the concrete form to the representation of the transition model?",
      "definition": "Both Single & Discrete state variable"
    },
    {
      "term": "Which algorithm works by first running the standard forward pass to compute?",
      "definition": "Modified smoothing"
    },
    {
      "term": "Which reveals an improvement in online smoothing?",
      "definition": "Matrix formulation"
    },
    {
      "term": "Which suggests the existence of an efficient recursive algorithm for online smoothing?",
      "definition": "Constant space"
    },
    {
      "term": "Given a sentence S=\"w1 w2 w3 ... wn\", to compute the likelihood of S using a bigram model. How would you compute the likelihood of S?",
      "definition": "Calculate the conditional probability of each word in the sentence given the preceding word and multiply the resulting numbers"
    },
    {
      "term": "In the sentence, \"They bought a blue house\", the underlined part is an example of _____.",
      "definition": "Noun phrase"
    },
    {
      "term": "Consider the following Context-Free Grammar G; S → A B (1) S → A S C (2) B → A C D (3) A → a (4) C → c (5) D → d (6) Which of the following strings belong to the language defined by the above grammar?",
      "definition": "b and c"
    },
    {
      "term": "Let us assume that CorpA is a corpus of English with approximately 560 million tokens. Following are the counts of unigrams and bigrams from the corpus; snow | purple | snow 30250 | 12321 |0 Find the probability of P(snow|purple) using maximum likelihood estimation without smoothing.",
      "definition": "0"
    },
    {
      "term": "4-grams are better than trigrams for part-of-speech tagging.",
      "definition": "FALSE"
    },
    {
      "term": "What will be the perplexity value if you calculate the perplexity of an unsmoothed language model on a test corpus with unseen words?",
      "definition": "Infinity"
    },
    {
      "term": "Which of the following NLP tasks use sequential labeling technique?",
      "definition": "All of the above"
    },
    {
      "term": "In POS tagging problem, what is the output of Viterbi algorithm?",
      "definition": "Probability of the best tag sequence given a word sequence"
    },
    {
      "term": "What type of ambiguity exists in the word sequence \"Time flies\"?",
      "definition": "Semantic"
    },
    {
      "term": "Let G = (V, T, S, P) be a context-free grammar such that Variables V = {S, R}, Terminal symbols T = {0, 1} Productions P = {S → R1R1R1R, R → 0R | 1R | e} Which of the following languages are supported by this grammar?",
      "definition": "L = {w | w contains at least three 1's}"
    },
    {
      "term": "Given a sequence of observations and a HMM model, which of the following fundamental problems of HMM finds the most likely sequence of states that produced the observations in an efficient way?",
      "definition": "Decoding problem"
    },
    {
      "term": "Zipf's law states that",
      "definition": "The frequency of a word type is inversely proportional to its rank by frequency."
    },
    {
      "term": "Which of the following is not a problem when using Maximum Likelihood Estimation to obtain the parameters in a language model?",
      "definition": "Smoothing"
    },
    {
      "term": "The words \"window\" and \"room\" are in a lexical semantic relation",
      "definition": "meronym - holonym"
    },
    {
      "term": "In an HMM, observation likelihoods measure",
      "definition": "The likelihood of a word given a POS tag"
    },
    {
      "term": "In a HMM, the possible state transitions are from state JJ to states NN, VB, JJ and RB. Following are the known state transitions probabilities; P(NN|JJ) = 1/4. P(VB|JJ) = 1/6, and P(JJ|JJ) = 1/3. What is the transition probability value of P(RB|JJ)?",
      "definition": "1/4"
    },
    {
      "term": "Which of the following best describes the probability of observation sequence {'Dry','Rain'} given a hidden state 'Low' for the observation 'Dry'?",
      "definition": "P('Dry' 'Rain', 'Low' 'Low') + P('Dry' 'Rain', 'Low' 'High')"
    },
    {
      "term": "_________ is the type of morphology that changes the word category and affects the meaning.",
      "definition": "Derivational"
    },
    {
      "term": "computer vs computational is an example of ______ morphology.",
      "definition": "Derivational"
    },
    {
      "term": "N-grams are defined as the combination of N keywords together. How many bi-grams can be generated from the given sentence: Gandhiji is the father of our nation",
      "definition": "6"
    },
    {
      "term": "Which of the following techniques can be used for the purpose of keyword normalization, the process of converting a keyword into its meaningful base form?",
      "definition": "Lemmatization"
    },
    {
      "term": "Which of the following areas where NLP can be useful?",
      "definition": "All of the above"
    },
    {
      "term": "Which of the following is the recognized statement by the Maximum Matching algorithm (Greedy - forward pass only) for string thetabledownthere?",
      "definition": "theta bled own there"
    },
    {
      "term": "You have collected a data of about 10,000 rows of tweet text and no other information. You want to create a tweet classification model that categorizes each of the tweets in three buckets - positive, negative and neutral. Which of the following models can perform tweet classification with regards to context mentioned above?",
      "definition": "None of the above"
    },
    {
      "term": "How many trigrams phrases can be generated from the following sentence, after performing stop word removal? Google is one of the most widely used search engine in India.",
      "definition": "2"
    },
    {
      "term": "One of the major challenges that causes almost all stages of Natural Language Processing a hard one is about handling,",
      "definition": "Ambiguity of sentences"
    },
    {
      "term": "Morphemes that cannot stand alone and are typically attached to another to become a meaningful word is called,",
      "definition": "Bound morphemes"
    },
    {
      "term": "In an HMM, tag transition probabilities measure",
      "definition": "The likelihood of a POS tag given the preceding tag"
    },
    {
      "term": "Consider the language L = {anbncm | m, n >=0}. Which of the following strings are in L?",
      "definition": "ab"
    },
    {
      "term": "Which of the following instances the regular expression \"\\b(one|two|three)\\b\" can recognize?",
      "definition": "\"one\""
    },
    {
      "term": "Which of the following can be used to implement orthographic rules?",
      "definition": "Finite State Transducer (FST)"
    },
    {
      "term": "The words 'there' and 'their' causes which of the following type of ambiguity?",
      "definition": "Phonological"
    },
    {
      "term": "Which of the following is an advantage of Porter stemmer over a full morphological parser?",
      "definition": "The stemmer does not require a detailed lexicon to implement"
    },
    {
      "term": "Given a set of unigram and bigram probabilities, what is the probability of the following sequence '<s> do Sam I like' according to the bigram language model?[Refer here: Language modeling in NLP] P(do|<s>) = 2/11, P(do|Sam) = 1/11, P(Sam|<s>) = 4/11, P(Sam|do) = 1/8, P(I|Sam) = 4/11, P(Sam|I) = 2/9, P(I|do) = 2/8, P(I|like) = 2/7, P(like|I) = 3/11, P(do) = 3/8, P(Sam) = 2/11, P(I) = 4/11, P(like) = 5/11",
      "definition": "2/11 1/8 4/11 * 3/11"
    },
    {
      "term": "Which of the following is TRUE about CRF (Conditional Random Field) and HMM (Hidden Markov Model)?",
      "definition": "CRF is discriminative model and HMM is generative model"
    },
    {
      "term": "Knowledge of the relationship of meaning to the goals and intentions of the speaker is ________",
      "definition": "Pragmatics"
    },
    {
      "term": "Which of the following NLP problems can be solved with Hidden Markov Model (HMM)?",
      "definition": "All of the above"
    },
    {
      "term": "Consider the following simple bigram language model, where the vocabulary consists of the single word x, and the parameters of the model are; q(a|*) = 1.0; q(a|a) = 0.4; q(END|a) = 0.6 Which of the following are the probabilities of the string '* a a' with and without END?",
      "definition": "0.4, 0.24"
    },
    {
      "term": "Which of the following measurements are used to evaluate the quality of entity recognition?",
      "definition": "All of the above"
    },
    {
      "term": "The study of the sound patterns in natural language and the rules that govern them is:",
      "definition": "Phonology"
    },
    {
      "term": "The lexical semantic relation between the words \"room\" and \"house\" with room as the first word and the house as the second is",
      "definition": "meronym - holonym"
    },
    {
      "term": "Which of the following is an NLP task that involves determining all referring expressions that point to the same real-world entity?",
      "definition": "Coreference resolution"
    },
    {
      "term": "Which of the following models can be estimated by maximum likelihood estimator?",
      "definition": "b and d"
    },
    {
      "term": "Suppose a language model assigns the following conditional n-gram probabilities to a 3-word test set: 1/4, 1/2, 1/4. Then P(test-set) = 1/4 1/2 1/4 = 0.03125. What is the perplexity?",
      "definition": "3.175"
    },
    {
      "term": "Assume a corpus with 350 tokens in it. We have 20 word types in that corpus (V = 20). The frequency (unigram count) of word types \"short\" and \"fork\" are 25 and 15 respectively. Which of the following is the probability of \"short\" (PMLE(\"short\"))?",
      "definition": "25/350"
    },
    {
      "term": "Assume a corpus with 350 tokens in it. We have 20 word types in that corpus (V = 20). The frequency (unigram count) of word types \"short\" and \"fork\" are 25 and 15 respectively. If we are using the Laplace smoothing, which of the following is PLaplace(\"fork\")?",
      "definition": "16/370"
    },
    {
      "term": "When training a language model, if we use an overly narrow corpus, the probabilities",
      "definition": "Don't generalize"
    },
    {
      "term": "The difference(s) between generative models and discriminative models include(s)",
      "definition": "c and d"
    },
    {
      "term": "Assume that there are 10000 documents in a collection. Out of these, 50 documents contain the terms \"difficult task\". If \"difficult task\" appears 3 times in a particular document, what is the TFIDF value of the terms for that document?",
      "definition": "15.87"
    },
    {
      "term": "Let us suppose that you have the following two 4-dimensional word vectors for two words w1 and w2 respectively: w1 = (0.2, 0.1, 0.3, 0.4) and w2 = (0.3, 0, 0.2, 0.5) What is the cosine similarity between w1 and w2?",
      "definition": "0.948"
    },
    {
      "term": "\"He was running quickly into the stadium\". What type of phrase is this?",
      "definition": "Verb phrase"
    },
    {
      "term": "If your training loss increases with number of epochs, which of the following could be a possible issue with the learning process?",
      "definition": "Step size is too large"
    },
    {
      "term": "Dense word vectors learned through word2vec or GloVe have many advantages over using sparse one-hot word vectors. Which of the following is a NOT advantage dense vectors have over sparse vectors?",
      "definition": "Models using dense word vectors generalize better to unseen words than those using sparse vectors."
    },
    {
      "term": "Which of the following is/are the input(s) to k-means algorithm?",
      "definition": "a and c and d"
    },
    {
      "term": "Which of the following best describes grammar induction?",
      "definition": "Unsupervised learning problem"
    },
    {
      "term": "Zipf's law tells us:",
      "definition": "in a given corpus, if the most frequent word's frequency is 1, then the second frequent word's frequency is around 0.5;"
    },
    {
      "term": "Which of the following is NOT a good example of cohesive device?",
      "definition": "Prepositions"
    },
    {
      "term": "In the sentence, \"I want a cute teddy for my birthday\", the underlined part is an example of _____.",
      "definition": "None of choices"
    },
    {
      "term": "Which of the following is an advantage of GLoVE?",
      "definition": "c and d"
    },
    {
      "term": "In a language, it is usual to have a word with more than one meaning even within its semantic class (polysemy). Which of the following tasks would help us in choose the right meaning as per the context in which the word is used?",
      "definition": "Word Sense Disambiguation"
    },
    {
      "term": "Which of the following is an advantage of normalizing a word?",
      "definition": "a and c"
    },
    {
      "term": "Which of the following techniques is most appropriate to the process of word normalization?",
      "definition": "Lemmatization"
    },
    {
      "term": "Words may have multiple meanings. This leads to what type of ambiguity in NLP?",
      "definition": "Lexical ambiguity"
    },
    {
      "term": "\"I went to the school, and they told me come on next day\". What type of ambiguity present in the given sentence?",
      "definition": "Anaphoric ambiguity"
    },
    {
      "term": "Let us assume that we use the words 'study' 'computer' and 'abroad'. It these are only informative words to classify that a mail is spam or not. Which of the following represent the maximum-likelihood estimate using add-one smoothing for P(study|spam)? Use the following table to answer the question;",
      "definition": "1/8"
    },
    {
      "term": "What is the probability P ('computer in abroad' | spam) as per the data in the table given in question 1?",
      "definition": "1/36"
    },
    {
      "term": "What is the unsmoothed maximum likelihood estimate of P(Spam) for the data given in question 1?",
      "definition": "b and d"
    },
    {
      "term": "Which of the following increases the weight of rarely occurring terms in the document set?",
      "definition": "Inverse document frequency"
    },
    {
      "term": "The act of converting a text document into a set of individual words is referred as ______ .",
      "definition": "Tokenization"
    },
    {
      "term": "Using TF-IDF (Term Frequency - Inverse Document Frequency) values for features in a uni-gram bag-of-words model should have an effect most similar to which of the following?",
      "definition": "Removing stop words"
    },
    {
      "term": "Suppose you have the following training data for Naïve Bayes: I liked the dish [LABEL = POS] I disliked the dish because it contains sugar [LABEL = NEG] Really tasty dish [LABEL = POS] What is the unsmoothed Maximum Likelihood Estimate (MLE) of P(POS) for this data?",
      "definition": "2/3"
    },
    {
      "term": "Use the data given in question (2) to answer this question. What is the unsmoothed Maximum Likelihood Estimate (MLE) of P(dish |POS)?",
      "definition": "2/7"
    },
    {
      "term": "Which of the following smoothing techniques is most complex?",
      "definition": "Good-Turing smoothing"
    },
    {
      "term": "Which of the following smoothing techniques assigns too much probability to unseen events?",
      "definition": "Add-1 smoothing"
    },
    {
      "term": "In add-k smoothing method, for a small k value, what would be perplexity?",
      "definition": "High perplexity"
    },
    {
      "term": "Which of the following is the main advantage of neural transition-based dependency parsers over non-neural transition-based dependency parsers?",
      "definition": "It relies on dense feature representations"
    },
    {
      "term": "Which of the following equations is used to find the unigram probabilities using Add-1 smoothing?",
      "definition": "(Count (wi)+1)/(N+1)"
    },
    {
      "term": "Let Xi denote state i in a Markov chain. It is nesscary true that Xi+1 and Xi-1 are uncorrlated",
      "definition": "False"
    },
    {
      "term": "Which one of the following are keyword Normalization techniques in NLP",
      "definition": "A and D"
    },
    {
      "term": "NLTK stands for _____.",
      "definition": "Natural Language Toolkit."
    },
    {
      "term": "NLP is a subfield of _______.",
      "definition": "Artificial Intelligence"
    },
    {
      "term": "What is Sentiment Analysis?",
      "definition": "recognizing the sentiment among several online posts and comments using NLP."
    },
    {
      "term": "Examples of NLP?",
      "definition": "Digital assistance, chatbots, Text summarization, text retrieval, sentiment analysis, translation etc."
    },
    {
      "term": "Likely, which languages can be used to work with NLP?",
      "definition": "Python & R language."
    },
    {
      "term": "When the first patents for \"translating machines\" were applied?",
      "definition": "Mid 1930"
    },
    {
      "term": "NLP breaks down language into shorter, more basic pieces, called _____.",
      "definition": "Tokens"
    },
    {
      "term": "What are the components of NLP?",
      "definition": "Morphological and Lexical Analysis, Syntactic Analysis, Semantic Analysis, Discourse Integration, Pragmatic Analysis"
    },
    {
      "term": "What is Morphical and Lexical Analysis?",
      "definition": "It depicts analyzing, identifying and description of the structure of words. It includes dividing a text into paragraphs, words and the sentences."
    },
    {
      "term": "Better similarity representation than 1-hot can be extended to n-grams",
      "definition": "What are the advantages of Bag of Word?"
    },
    {
      "term": "Which of these properties do the K-means algorithm and K-gaussian EM algorithm have in common?",
      "definition": "They optimize a lower bound on the complete log-likelihood of the data"
    },
    {
      "term": "- Parameter that control how fast the learning takes place - Too high: Jumps back and forth - Too low: Takes too long to get to the solution",
      "definition": "Learning rate"
    },
    {
      "term": "______ transfer linear sequences of words into structures",
      "definition": "Semantic Analysis"
    },
    {
      "term": "Added to the activation function, translate the data",
      "definition": "ReLU"
    },
    {
      "term": "Every word is a row, every word is a column, the number is the number of times the two words occur in the same context",
      "definition": "What are some examples of co-occurence matrix technologies?"
    },
    {
      "term": "What is the Lexical Ambiguity?",
      "definition": "All of the others"
    },
    {
      "term": "The collection of documents, required for text analysis is known as ____",
      "definition": "Corpus"
    },
    {
      "term": "Topic model is a supervised learning method",
      "definition": "False"
    },
    {
      "term": "Viterbi algorithm preforms ___ decoding of convolutional codes.",
      "definition": "Maximum Likelihood"
    },
    {
      "term": "Where 1 = activation and 0 = no activation (for weighted sum of inputs)",
      "definition": "Linear activation function (step)"
    },
    {
      "term": "Which of the following is not an algorithm for decoding convolution codes?",
      "definition": "Ant colony optimization"
    },
    {
      "term": "Semantic Analysis means _____.",
      "definition": "This component transfers linear sequences of words into structures. It shows how the words are associated with each other. And focuses only on the literal meaning of words, phrases, and sentences."
    },
    {
      "term": "What Pragmatic Analysis does?",
      "definition": "It deals with the overall communicative and social content and its effect on interpretation. It means abstracting or deriving the me aningful use of language in situations."
    },
    {
      "term": "What is Syntax Analysis?",
      "definition": "It focuses about the proper ordering of words which can affec t its meaning. This involves analysis of the words in a sentence by following the grammatical structure of the sentence. The words are transformed into the structure to show how the words are related to each other."
    },
    {
      "term": "Discourse Integration means _____.",
      "definition": "It means a sense of the context. The meaning of any single sentence which depends upon those sentences. It also considers the meaning of the following sentence."
    },
    {
      "term": "How to implement NLP?",
      "definition": "Machine Learning & Statistical Inference."
    },
    {
      "term": "What Symbolic Approach performs?",
      "definition": "It performs extensive analysis of linguistic phenomena through explicit representation of facts about language and well-understood knowledge representation schemas and associated algorithms."
    },
    {
      "term": "How does the Statistical Approach work?",
      "definition": "It uses statistical methods to resolve some of the difficulties in symbolic approach. It does this by harnessing various mathematical techniques and often using large text corpora to develop approximately generalized models of linguistic phenomena based on actual examples."
    },
    {
      "term": "Connectionist Approach is based on_____.",
      "definition": "The interconnection of networks having simple processing units with knowledge stored in weights to identify connections between units."
    },
    {
      "term": "Symbolic Approach is also called _____.",
      "definition": "Rule based Approach."
    },
    {
      "term": "Statistical Approach is also called____.",
      "definition": "Corpus Based Approach."
    },
    {
      "term": "Connectionist Approach is widely known as___.",
      "definition": "Neural Network"
    },
    {
      "term": "What kind of ambiguities are faced by NLP?",
      "definition": "Both a & c"
    },
    {
      "term": "What is Lexical Ambiguity?",
      "definition": "Ambiguity of a single word when it can be used as a verb, noun or an adjective."
    },
    {
      "term": "What scope ambiguity involves?",
      "definition": "Operators and quantifiers"
    },
    {
      "term": "When semantic ambiguity occurs?",
      "definition": "when the meaning of the words themselves can be misinterpreted."
    },
    {
      "term": "______________ depicts analyzing,identifying and description of the structure of words.",
      "definition": "Morphical And Lexical Analysis"
    },
    {
      "term": "_____________includes dividing a text into paragraphs, words and the sentences.",
      "definition": "Morphological and Lexical Analysis"
    },
    {
      "term": "_____________transfers linear sequences of words into structures.",
      "definition": "Semantic Analysis"
    },
    {
      "term": "_______________shows how the words are associated with each other.",
      "definition": "Semantic Analysis"
    },
    {
      "term": "_______________focuses only on the literal meaning of words, phrases, and sentences.",
      "definition": "Semantic Analysis"
    },
    {
      "term": "________ deals with the overall communicative and social content and its effect on interpretation.",
      "definition": "Pragmatic Analysis"
    },
    {
      "term": "____ means abstracting or deriving the meaningful use of language in situations.",
      "definition": "PragmaticAnalysis"
    },
    {
      "term": "It focuses about the proper ordering of words which can affect its meaning.",
      "definition": "Syntax Analysis"
    },
    {
      "term": "This involves analysis of the words in a sentence by following the grammatical structure of thesentence.",
      "definition": "Syntax Analysis"
    },
    {
      "term": "The words are transformed into the structure to show how the words are related to each other. Thisprocess is called as____________",
      "definition": "Syntax Analysis"
    },
    {
      "term": "____means a sense of the context. The meaning of any single sentence which depends upon those sentences. It also considers the meaning of the following sentence.",
      "definition": "Discourse"
    },
    {
      "term": "Machine Learning & Statistical Inference are the popular methods for implementing___.",
      "definition": "NLP"
    },
    {
      "term": "It performs extensive analysis of linguistic phenomena through explicit representation of facts about language and well",
      "definition": "Rule based Approach."
    },
    {
      "term": "It uses statistical methods to resolve some of the difficulties in symbolic approach. It does this by harnessing various mathematical techniques and often using large text corpora to develop approximately generalized models of linguistic phenomena based on actual examples.",
      "definition": "Statistical Approach"
    },
    {
      "term": "The interconnection of networks having simple processing units with knowledge stored in weights to identify connections between units.",
      "definition": "Both a & b."
    },
    {
      "term": "Rule Based Approach is also called _____________",
      "definition": "Symbolic Approach."
    },
    {
      "term": "Corpus Based Approach is also called_________",
      "definition": "Statistical Approach."
    },
    {
      "term": "Neural Networks are also known as___________",
      "definition": "Connectionist Approach"
    },
    {
      "term": "Ambiguity of a single word when it can be used as a verb, noun or an adjective is called as________",
      "definition": "Lexical Ambiguity"
    },
    {
      "term": "Operators and Quantifiers are mostly responsible for___________",
      "definition": "Scope Ambiguity"
    },
    {
      "term": "when the meaning of the words themselves can be misinterpreted then ______ ambiguity occurs.",
      "definition": "Semantic Ambiguity"
    },
    {
      "term": "What refers to a situation where the context of a phrase gives it multiple interpretations?",
      "definition": "Pragmatic Ambiguity"
    },
    {
      "term": "What is Morphological Analysis?",
      "definition": "Morphological analysis is the process of providing grammatical information about the word on the basis of properties of the morpheme it contains."
    },
    {
      "term": "Morphological analyzer is composed of the following Three parts according to Kumar, 2013?",
      "definition": "Morpheme lexeme, Set of rules governing the spelling and composition of morphologically complex words & Decision algorithm"
    },
    {
      "term": "Morphological analysis is also known as___.",
      "definition": "Lexical Analysis"
    },
    {
      "term": "What are the various methods of Morphological Analysis?",
      "definition": "All of the above"
    },
    {
      "term": "____ is a model of behaviour composed of state, trans ition and actions.",
      "definition": "FSA"
    },
    {
      "term": "The lexical representation of a word-form is also called as_____.",
      "definition": "Morphophonemic"
    },
    {
      "term": "______has given a computational model of two-level morphology for word-form recognition and generation in his dissertation in 1983.",
      "definition": "Kimmo Koskenniemi"
    },
    {
      "term": "The two-level morphology model consists of two representations and one rule. What are they?",
      "definition": "The surface representation of a word-form, The lexical represen tation of a word-form, rules which map the two representations."
    },
    {
      "term": "The surface representation of a word-form, The lexical representation of a word-form, rules which map the two representations refers to ______.",
      "definition": "Two-level morphology model"
    },
    {
      "term": "_____is an advanced version of FSA(finite state automata)and is used to represent the lexicon computationally.",
      "definition": "FST"
    },
    {
      "term": "Finite State Transducer is an advanced version of _____ and is used to represent the lexicon computationally.",
      "definition": "FSA"
    },
    {
      "term": "In FST what components are used to build morphological analyzers?",
      "definition": "lexicon, orthographic rules and spelling variations"
    },
    {
      "term": "lexicon, orthographic rules and spelling variations are the components of ______.",
      "definition": "FST"
    },
    {
      "term": "An FST is simply a classical finite-state automaton whose transitions are ____ , rather than with single symbols.",
      "definition": "labeled with pairs"
    },
    {
      "term": "What is stemmer?",
      "definition": "It is used for stripping of affixes. It uses a set of rules containing a list of stems and replacement rules."
    },
    {
      "term": "The most widely used stemmer algorithm is _____.",
      "definition": "Porter Algorithm"
    },
    {
      "term": "_____ used for stripping of affixes. It uses a set of rules containing a list of stems and replacement rules.",
      "definition": "Stemmer"
    },
    {
      "term": "DAWG stands for ______.",
      "definition": "Directed Acyclic Word Graph"
    },
    {
      "term": "DAWG is ___.",
      "definition": "It is a very efficient data structure for lexicon representation and fast string matching with a great variety of applications."
    },
    {
      "term": "A ____ defines all the word forms of a given stem and also provides a feature structure with every word form. The _____ is efficient for inflectional rich languages.",
      "definition": "Paradigm, paradigm-based approach"
    },
    {
      "term": "The ANUSAARAKA research group has developed a language independent paradigm based morphological compiler program for ____. This or a variant of this scheme has been used widely in NLP.",
      "definition": "Indian Languages"
    },
    {
      "term": "The _______research group has developed a language independent paradigm based morphological compiler program for Indian languages. This or a variant of this scheme has been used widely in NLP.",
      "definition": "ANUSAARAKA"
    },
    {
      "term": "Morphology is divided into two branches:",
      "definition": "Both b & c"
    },
    {
      "term": "_____is a change in word form. This usually means the use of endings. For eg., He works, he worked, and he is working.",
      "definition": "Inflectional Morphology"
    },
    {
      "term": "________creates new words. For example, beauty becomes beautiful. The affix -ful changes the word from a noun to an adjective.",
      "definition": "Derivational Morphology"
    },
    {
      "term": "____________ morphology uses many more affixes than ____morphology.",
      "definition": "Derivational, inflectional"
    },
    {
      "term": "NLTK have following stemming classes:",
      "definition": "All of the above"
    },
    {
      "term": "In _____, the words are replaced by the root words or the words with similar context.",
      "definition": "Lemmatization"
    },
    {
      "term": "___are created by removing the suffixes or prefixes used with a word. This process is called as____",
      "definition": "Stems, Stemming"
    },
    {
      "term": "NLTK requires Python versions above__.",
      "definition": "2.7"
    },
    {
      "term": "A _____, often called a pattern, specifies a set of strings required for a particular purpose. A simple way to specify a finite set of strings is to list its elements or members.",
      "definition": "Regular Expression"
    },
    {
      "term": "a|b* denotes",
      "definition": "{ε, \"a\", \"b\", \"bb\", \"bbb\", ...}"
    },
    {
      "term": "(a|b)* denotes",
      "definition": "{ε, \"a\", \"b\", \"aa\", \"ab\", \"ba\", \"bb\", \"aaa\", ...}"
    },
    {
      "term": "ab*(c|ε) denotes",
      "definition": "{\"a\", \"ac\", \"ab\", \"abc\", \"abb\", \"abbc\", ...}"
    },
    {
      "term": "(aa)(bb)b denotes\na.{b, aab, aabbb, aabbbbb, aaaab, aaaabbb, ..............}\nb.{ε, \"a\", \"b\", \"aa\", \"ab\", \"ba\", \"bb\", \"aaa\", ...}\nc.{\"a\", \"ac\", \"ab\", \"abc\", \"abb\", \"abbc\", ...}\nd.None of the above",
      "definition": "(0 + 10*) denotes\na.{1, 01, 10, 010, 0010, ...}\nb.{ 0, 1, 10, 100, 1000, 10000, ... }\nc.{ε, 0, 1, 01}\nd.None of the above"
    },
    {
      "term": "____is the simplest machine to recognize patterns. It has a set of states and rules for moving from one state to another but it depends upon the applied input symbol.",
      "definition": "DFA"
    },
    {
      "term": "What is Q in the finite automata set?",
      "definition": "Finite set of states."
    },
    {
      "term": "Σ denotes in Finite Automata set as:",
      "definition": "set of Input Symbols."
    },
    {
      "term": "FA is characterized into two types & they are:",
      "definition": "NFA, DFA"
    },
    {
      "term": "In ___ null (or ε) move is not allowed.",
      "definition": "DFA"
    },
    {
      "term": "In ____ null (or ε) move is allowed i.e., it can move forward without reading symbols.",
      "definition": "NFA"
    },
    {
      "term": "What FS transducers do?",
      "definition": "It is a finite state automaton which produces output as well as reading input, it is useful for parsing."
    },
    {
      "term": "Transducers work in 4 modes. What are they?",
      "definition": "Both a & b"
    },
    {
      "term": "What is generation mode?",
      "definition": "It writes a string on one tape and a string on the other tape. Both strings have the same length."
    },
    {
      "term": "What recognition mode does?",
      "definition": "It accepts when the word on the first tape consists of exactly as many as the word on the second tape consists of."
    },
    {
      "term": "What are the advantages of Porter stemmer algorithm?",
      "definition": "All of the above."
    },
    {
      "term": "The ______ algorithm is a process of removing suffixes from words in English.",
      "definition": "Porter Stemmer"
    },
    {
      "term": "Disadvantages of Porter Stemming algorithm are:",
      "definition": "Both a & b"
    },
    {
      "term": "The _____ is a very interesting method and it is language independent.",
      "definition": "N-Gram Stemmer"
    },
    {
      "term": "N-Gram stemmer has following advantages:",
      "definition": "Both a & b"
    },
    {
      "term": "Limitations of N-Gram Stemmer are:",
      "definition": "All of the above"
    },
    {
      "term": "_________ is a vocabulary, a list of words, a dictionary.",
      "definition": "Lexicon"
    },
    {
      "term": "______________ is a lexical database for the English language.",
      "definition": "WordNet"
    },
    {
      "term": "__________ basically, means a body, and in the context of Natural Language Processing (NLP), it means a body of text.",
      "definition": "Corpus"
    },
    {
      "term": "What are the applications of FST?",
      "definition": "All of the above."
    },
    {
      "term": "______ are general rules used when breaking a word into its stem and modifiers. An example would be: singular English words ending with -y, when pluralized, end with -ies.",
      "definition": "Orthographic Rules"
    },
    {
      "term": "Types of stemming errors are:",
      "definition": "Both a and b"
    },
    {
      "term": "____ is when two words with different stems are stemmed to the same root. This is also known as a _____.",
      "definition": "Over Stemming, False Positive"
    },
    {
      "term": "______ is when two words that should be stemmed to the same root are not. This is also known as a ____.",
      "definition": "Under Stemming, False Negative"
    },
    {
      "term": "It is possible to use backtracking in ____.",
      "definition": "DFA"
    },
    {
      "term": "It is not possible to use backtracking at all times in the case of _____.",
      "definition": "NFA"
    },
    {
      "term": "The full form of DFA is____.",
      "definition": "Deterministic Finite Automata"
    },
    {
      "term": "The full form of NFA is ____.",
      "definition": "Non-deterministic Finite Automata"
    },
    {
      "term": "The generally accepted approach to morphological parsing is through the use of a _____, which inputs words and outputs their stem and modifiers.",
      "definition": "Finite StateTransducer(FST)"
    },
    {
      "term": "FST as recognizer:",
      "definition": "a transducer that takes a pair of strings as input and output accept if the string-pair is in the string-pair language, and a reject if it is not"
    },
    {
      "term": "FST as generator:",
      "definition": "a machine that outputs pairs of strings of the language. Thus the output is a yes or no, and a pair of output strings."
    },
    {
      "term": "FST as transducer:",
      "definition": "A machine that reads a string and outputs another string."
    },
    {
      "term": "FST as set relator:",
      "definition": "A machine that computes relation between sets"
    },
    {
      "term": "To construct a regular expression from a DFA, we replace each state in the ___one by one with a corresponding ___.",
      "definition": "DFA, regular expression"
    },
    {
      "term": "If we can eliminate________ from an FA, then our construction of an FA from a regular expression can be completed.",
      "definition": "Epsilon transitions"
    },
    {
      "term": "In the fields of computational linguistics and probability, an_____ is a contiguous sequence of n items from a given sample of text or speech. The items can be phonemes, syllables, letters, words or base pairs according to the application.",
      "definition": "N-grams"
    },
    {
      "term": "Applications of n-gram:",
      "definition": "All of the above"
    },
    {
      "term": "Syntactic n-grams are n-grams defined by paths in _________ dependency or constituent trees rather than the linear structure of the text.",
      "definition": "Syntactic"
    },
    {
      "term": "NLP is a subfield of ____________, computer science, and artificial intelligence concerned with the interactions between computers and human language",
      "definition": "Linguistics"
    },
    {
      "term": "NLP does not involves in -",
      "definition": "Computer vision"
    },
    {
      "term": "Which is the method of NLP",
      "definition": "All of the above"
    },
    {
      "term": "Which is not NLP task?",
      "definition": "Object recognition"
    },
    {
      "term": "Which is the goal of NLP?",
      "definition": "All of the above"
    },
    {
      "term": "Where NLP is not used?",
      "definition": "Predictive analysis"
    },
    {
      "term": "What input we can process with NLP?",
      "definition": "All of the above"
    },
    {
      "term": "Which is not a level of NLP process?",
      "definition": "Textual"
    },
    {
      "term": "Which difficulty occurs in NLP?",
      "definition": "Contextual Ambiguity"
    },
    {
      "term": "Which is not application of NLP?",
      "definition": "OCR"
    },
    {
      "term": "How many steps of NLP is there?",
      "definition": "5"
    },
    {
      "term": "____________________ is the step in which an input sentence is converted into a hierarchical structure that corresponds to the units of meaning in the sentence.",
      "definition": "Semantic Processing"
    },
    {
      "term": "What is Machine Translation",
      "definition": "Converts one human language to another"
    },
    {
      "term": "Which is not a step in NLP?",
      "definition": "Word analysis"
    },
    {
      "term": "Which of the following is demerits of Top-Down Parser?",
      "definition": "Both B and C"
    },
    {
      "term": "Which of the following is used to mapping sentence plan into sentence structure?",
      "definition": "Text Realization"
    },
    {
      "term": "Which is not a knowledge type of language processing?",
      "definition": "Symbol"
    },
    {
      "term": "In morphology, we care about the ______ that make up the sentence",
      "definition": "Words"
    },
    {
      "term": "Which is not an example of morphology?",
      "definition": "Word detection"
    },
    {
      "term": "In parsing stage, we focus more on the _________ of the words within a sentence",
      "definition": "Relationship"
    },
    {
      "term": "Syntactical analysis is done at_________ level",
      "definition": "Sentence"
    },
    {
      "term": "Morphological analysis is done at _________level",
      "definition": "Word"
    },
    {
      "term": "Natural Language Processing, or NLP for short, is broadly defined as the automatic _________of natural language, like speech and text, by software.",
      "definition": "Manipulation"
    },
    {
      "term": "NLP is originated from the idea of _________which came to existence during the second world war.",
      "definition": "Machine translation"
    },
    {
      "term": "What is full form of NLG?",
      "definition": "Natural Language Generation"
    },
    {
      "term": "In linguistic morphology_________ is the process for reducing inflected words to their root form.",
      "definition": "Stemming"
    },
    {
      "term": "Which of the following is used study of construction of words from primitive meaningful units?",
      "definition": "Morphology"
    },
    {
      "term": "Word level anlysis helps to find_________ resolution according to the context",
      "definition": "Ambiguity"
    },
    {
      "term": "Word level analysis helps in _________of given text",
      "definition": "Spellchecking"
    },
    {
      "term": "_________is the smallest part of a word",
      "definition": "Morpheme"
    },
    {
      "term": "The morphological level of linguistic processing deals with the study of word _________and word_________",
      "definition": "Structure & Formation"
    },
    {
      "term": "Which is the Morpheme from following?",
      "definition": "All of the above"
    },
    {
      "term": "Which is not used in Word level Analysis?",
      "definition": "Decidability and Countability"
    },
    {
      "term": "Which is not a approach of Morphology?",
      "definition": "context based"
    },
    {
      "term": "In Morpheme based morphology, Word forms are analysed as_________ of morphemes?",
      "definition": "Arrangements"
    },
    {
      "term": "Lexeme based morphology follows_________ and _________approach.",
      "definition": "Item & Process"
    },
    {
      "term": "Word based Morphology _________that hold between the forms of inflectional paradigms",
      "definition": "Generalizations"
    },
    {
      "term": "Stemming is basically removing the_________ from a word and reduce it to its root word",
      "definition": "Suffix"
    },
    {
      "term": "Over-stemming is when two _________with different stems are stemmed to the same root",
      "definition": "Words"
    },
    {
      "term": "Lemmatization usually refers to doing things properly with the use of a _________and_________ analysis of words",
      "definition": "Vobulary & Morphological"
    },
    {
      "term": "regular expression is _________given to a function on what and how to match or replace a set of strings",
      "definition": "Instruction"
    },
    {
      "term": "Which is not regex command from following?",
      "definition": "Strjoin()"
    },
    {
      "term": "_________allows to mention and have control over how many times specific character(s) pattern should occur in the given text",
      "definition": "Quantifiers"
    },
    {
      "term": "finite state automation is a model of behavior composed of state,_________ and_________",
      "definition": "Transitions & Actions"
    },
    {
      "term": "In Finite Automaton, transitions is process of _________over from one state to another state.",
      "definition": "Switching"
    },
    {
      "term": "To build Morphological Parser we need",
      "definition": "All of the above"
    },
    {
      "term": "Lexicon is repository of _________",
      "definition": "Words"
    },
    {
      "term": "A transducer maps between FST one set of _________and another.",
      "definition": "Symbols"
    },
    {
      "term": "Finite State Transducers is used to represent the_________ computationally",
      "definition": "Lexicon"
    },
    {
      "term": "Porter stemmer is a process for removing the commoner _________and _________endings from words in English",
      "definition": "Morphological & Inflexional"
    },
    {
      "term": "Porter Stemmer algorithm is part of a term _________process",
      "definition": "Normalisation"
    },
    {
      "term": "An n-gram is a contiguous _________of n items from a given sample of text or speech",
      "definition": "Sequence"
    },
    {
      "term": "N-gram is used with",
      "definition": "Markov Model"
    },
    {
      "term": "N-gram can improve_________ of auto completion system",
      "definition": "Prediction"
    },
    {
      "term": "N-gram uses Maximum likelihood _________to estimate probability",
      "definition": "Estimation"
    },
    {
      "term": "Which one is stemming algorithm?",
      "definition": "All of the above"
    },
    {
      "term": "Orthographic rules are general rules used when breaking a word into its _________and _________.",
      "definition": "Stems, Modifiers"
    },
    {
      "term": "Derivational morphology changes both the meaning and the content of a listeme, while inflectional morphology doesn't change the meaning, but changes the function.",
      "definition": "Meaning, Content, Listeme, function"
    },
    {
      "term": "Syntactic analysis or parsing may be defined as the process of_________ the_________ of symbols in natural language conforming to the rules of formal grammar",
      "definition": "Analyzing & Strings"
    },
    {
      "term": "Which is not role of parser?",
      "definition": "Correct any syntax error"
    },
    {
      "term": "In Top-down parsing, the parser starts constructing the parse tree from the _________.",
      "definition": "Start symbol"
    },
    {
      "term": "In Bottom-up parsing, the parser starts constructing the parse tree from the_________ .",
      "definition": "Input symbol"
    },
    {
      "term": "POS is the process of marking up a word in a text as corresponding to a particular part of speech, based on both its _________and its_________",
      "definition": "Definition & contexts"
    },
    {
      "term": "Rule-based taggers use dictionary or_________ for getting possible tags for tagging each word.",
      "definition": "Lexicon"
    },
    {
      "term": "Following property is of - These taggers are knowledge-driven taggers.",
      "definition": "Rule based tagging"
    },
    {
      "term": "The model that includes_________ or probability (statistics) can be called stochastic",
      "definition": "Frequency"
    },
    {
      "term": "Following property is of - This POS tagging is based on the probability of tag occurring.",
      "definition": "Stochastic tagging"
    },
    {
      "term": "Transformation based tagging is _________algorithm for automatic tagging",
      "definition": "Rule based"
    },
    {
      "term": "Which is the step taken in Transformation based tagging?",
      "definition": "All of the above"
    },
    {
      "term": "The Penn Treebank, or PTB for short, is a dataset maintained by the_________",
      "definition": "University of Pennsylvania"
    },
    {
      "term": "The job of a POS tagger is to resolve this _________accurately based on the context of use.",
      "definition": "Ambiguity"
    },
    {
      "term": "In English, many common words have multiple meanings and therefore multiple POS.",
      "definition": "Multiple meanings"
    },
    {
      "term": "A context-free grammar (CFG) is a list of rules that define the set of all well-formed sentences in a language.",
      "definition": "List of Rules"
    },
    {
      "term": "In CFG, Each rule has a _________side",
      "definition": "Option A and B"
    },
    {
      "term": "In CFG, Left hand side identifies_________ and right hand side defines_________",
      "definition": "Syntactic Categories and component parts"
    },
    {
      "term": "subcategorization denotes the_________ for lexical items (usually verbs) to require/allow the presence and types of the syntactic arguments with which they co-occur",
      "definition": "Ability"
    },
    {
      "term": "Sequence labeling is a typical NLP task which assigns a _________or _________to each_________ in a given input sequence.",
      "definition": "Class, Label, token"
    },
    {
      "term": "Types of Sequence labeling",
      "definition": "Option A and B"
    },
    {
      "term": "HMMs a e \"a statistical Ma koÖ model in ×hich the sÝstem being modeled is assumed to be a _________process with _________states\".",
      "definition": "Markov, Unobservable"
    },
    {
      "term": "HMM are designed to model the joint distribution P(H , O) , where H is the hidden state and O is the observed state.",
      "definition": "Hidden, Observed"
    },
    {
      "term": "HMM graphs consist of a Hidden Space and Observed Space, where the hidden space consists of the _________and the observed space is the_________ .",
      "definition": "Labels, Input"
    },
    {
      "term": "HMMs are limited to only _________states and only take into account the last known_________ .",
      "definition": "Discrete, State"
    },
    {
      "term": "Maximum Entropy Markov Models use a maximum entropy_________ for_________ and local_________ .",
      "definition": "Framework, Features, Normalization"
    },
    {
      "term": "In the context of POS tagging, the objective would be to build an HMM to model P(_________ |_________ ) and compute the label probabilities given observations using _________Rule.",
      "definition": "Word, Tag, Bayes"
    },
    {
      "term": "In HMMs, spaces are connected_________ via matrices {T,A} to represent the probability of_________ from one state to another following their_________ .",
      "definition": "Transitions, Transitioning, Connections"
    },
    {
      "term": "Each connection in HMM represents a _________over possible options; given our _________, this results in a large search space of the_________ of all words given the tag.",
      "definition": "Distribution, tags, probability"
    },
    {
      "term": "In question answering and search tasks, we can use spans as entities to specify our search query",
      "definition": "Classes, Objects"
    },
    {
      "term": "The label bias problem was introduced due to MEMMs applying local normalization.",
      "definition": "Label bias, normalization"
    },
    {
      "term": "This often leads to the model getting stuck in _________ during_________ .",
      "definition": "Local minima, decoding"
    },
    {
      "term": "The_________ minima trap occurs because the overall model favors_________ with the least amount of transitions.",
      "definition": "Local, nodes"
    },
    {
      "term": "Semantic analysis is the process of understanding the _________and_________ of words, signs and sentence structure",
      "definition": "Meaning, interpretation"
    },
    {
      "term": "Elements of Semantic analysis",
      "definition": "All of the above"
    },
    {
      "term": "In homonymy, the meanings of the words are not related",
      "definition": "Related"
    },
    {
      "term": "word sense disambiguation (WSD) is the problem of determining which \"sense\" (meaning) of a word is activated by the use of the word in a particular_________ .",
      "definition": "Context"
    },
    {
      "term": "Which is not method of WSD?",
      "definition": "Unsupervised learning"
    },
    {
      "term": "Which algorithm is for WSD?",
      "definition": "All of the above"
    },
    {
      "term": "WordNet is the_________ database",
      "definition": "Lexical"
    },
    {
      "term": "WordNet does not links words into semantic relations for?.",
      "definition": "Homonyms"
    },
    {
      "term": "WordNet can be used for",
      "definition": "All of the above"
    },
    {
      "term": "and are the most common semantic roles.(No Answer)",
      "definition": "Agents and themes"
    },
    {
      "term": "When two or more different forms have the same pronunciation, they are called _________.",
      "definition": "Homophones"
    },
    {
      "term": "compositional semantics deals with how those_________ meanings. meanings combine to form more_________",
      "definition": "Lexical, complex"
    },
    {
      "term": "Which is a step of Lexical semantics?",
      "definition": "All of the above"
    },
    {
      "term": "semantic ambiguity happens when a sentence contains an _________word or phrase.",
      "definition": "Ambiguous"
    },
    {
      "term": "semantic analyzer would reject a sentence like_________",
      "definition": "Option A and B"
    },
    {
      "term": "Semantic T eebanks use a fo mal _________of sentence's semantic st uctu e.",
      "definition": "Representation"
    },
    {
      "term": "Lexical analysis is based on _________token but on the other side semantic analysis focuses on _________chunks.",
      "definition": "Smaller, larger"
    },
    {
      "term": "In lexical semantics, we do study of_________",
      "definition": "Individual words"
    },
    {
      "term": "In Hyponymy, It may be defined as the relationship between a generic_________ and_________ of that generic term.",
      "definition": "Term, instances"
    },
    {
      "term": "In Hyponymy, the generic term is called hypernym and its instances are called hyponyms.",
      "definition": "Hypernym, Hyponyms"
    },
    {
      "term": "Semantic analysis creates a _________of the meaning of a sentence.",
      "definition": "Representation"
    },
    {
      "term": "Which is the building block of semantic systems",
      "definition": "Option A and B"
    },
    {
      "term": "What is reason for need of Meaning representations?",
      "definition": "All of the above"
    },
    {
      "term": "What is required for evaluation of WSD?",
      "definition": "Option A and B"
    },
    {
      "term": "Which is a difficulty for WSD?",
      "definition": "All of the above"
    },
    {
      "term": "polysemy has the same spelling but_________ meaning.",
      "definition": "Different and related"
    },
    {
      "term": "Synonymy is the relation between two items having different but expressing the same or a close meaning.",
      "definition": "Lexical, forms"
    },
    {
      "term": "Antonymy is the relation between two lexical items having between their semantic relative to an axis.",
      "definition": "Symmetry, Components"
    },
    {
      "term": "Which is a Application of WSD?",
      "definition": "All of the above"
    },
    {
      "term": "the sense of the word depends on the words of that particular word.",
      "definition": "Neighboring"
    },
    {
      "term": "Semantic analysis the text elements and assigns them to their logical and grammatical role.",
      "definition": "Identifies"
    },
    {
      "term": "Semantic analysis relates to concepts like and , which is the particular combination of words that can be or frequently are surrounding a single word.",
      "definition": "Connotations, Collocation"
    },
    {
      "term": "Pragmatic Analysis is part of the process of extracting from text. a. Context",
      "definition": "Information"
    },
    {
      "term": "focuses on taking a set of text and figuring out what the actual was.",
      "definition": "Structured & Meaning"
    },
    {
      "term": "deixis is the process of via language",
      "definition": "Pointing"
    },
    {
      "term": "The linguistic forms we use to accomplish this 'pointing' is called deictic .",
      "definition": "Expression"
    },
    {
      "term": "Which is not a type of Deixis?",
      "definition": "Simple"
    },
    {
      "term": "\"Implicature\" denotes either the act of meaning or ________ one thing by saying something else, or the _______ of that act.",
      "definition": "Implying, Object"
    },
    {
      "term": "Implicatures can be determined by sentence ________ or by ___________ context.",
      "definition": "Meaning, Conversational"
    },
    {
      "term": "Which is not a type of Implicature?",
      "definition": "Conditional"
    },
    {
      "term": "A presupposition is an _________ about the world or background belief",
      "definition": "Implicit assumption"
    },
    {
      "term": "A presupposition must be mutually known or assumed by the _______ and ________ for the utterance to be considered appropriate in context.",
      "definition": "Speaker, Addressee"
    },
    {
      "term": "A presupposition trigger is a ________ item or linguistic construction which is responsible for the presupposition, and thus \"triggers\" it.",
      "definition": "Lexical, Linguistic"
    },
    {
      "term": "speech act is something expressed by an individual that not only presents _________, but performs an _______ as well.",
      "definition": "Information, Action"
    },
    {
      "term": "Which is not a level of Speech act?",
      "definition": "Definite"
    },
    {
      "term": "Which is primitive Speech act from following?",
      "definition": "All of the above"
    },
    {
      "term": "Discourse deals with how the immediately preceding sentence can affect the _________ of the next sentence.",
      "definition": "Interpretation"
    },
    {
      "term": "Which is the mode of discourse from following",
      "definition": "Option A and B"
    },
    {
      "term": "Feature of Discourse structure?",
      "definition": "All of the above"
    },
    {
      "term": "reference resolution may be defined as the task of __________what entities are referred to by which __________ expression.",
      "definition": "Determining, Linguistic"
    },
    {
      "term": "Which is type of reference resolution",
      "definition": "All of the above"
    },
    {
      "term": "Which is not a task of reference resolution",
      "definition": "Constraint Resolution"
    },
    {
      "term": "Simple natural language phenomena (e.g., NP-NP, V-NP-NP patterns) can be described using_________",
      "definition": "CFG"
    },
    {
      "term": "Which is not a Semantic and Syntactic Constraint?",
      "definition": "Addition"
    },
    {
      "term": "Which is not a distinctionfor Coreference?",
      "definition": "Combined Antecedents"
    },
    {
      "term": "Which is not the application of Coreference resolution?",
      "definition": "Text Recognition"
    },
    {
      "term": "coreference resolution is a well-studiedproblem in __________.",
      "definition": "Discourse"
    },
    {
      "term": "Algorithms intended to resolve coreferences commonly look first for the nearest ____________ that is compatible with the referring ____________.",
      "definition": "Preceding individual, Expressions"
    },
    {
      "term": "'anaphora' is an intra-linguistically __________ relation, whereas 'co-reference' necessarily requiresaccess to 'extra-linguistic' ____________.",
      "definition": "Determinable, information"
    },
    {
      "term": "co-reference always implies ____________, whereas anaphora does not.",
      "definition": "Identity of reference"
    },
    {
      "term": "Pragmatic Ambiguity arises when the___________ of words of a sentence is not specific; it concludes different meanings.",
      "definition": "Meaning"
    },
    {
      "term": "Pragmatics is the study of the functions of the __________ and its use in context.",
      "definition": "Language"
    },
    {
      "term": "Reference may bedefined as the _____________ expression to denote an entity or individual.",
      "definition": "Linguistic"
    },
    {
      "term": "The coherence of entire discourse can also be considered by ___________ structure between _______ relations.",
      "definition": "Hierarchical, Coherence"
    },
    {
      "term": "Pragmatic ambiguity refers to the situation where the context of a phrase gives it multiple______________.",
      "definition": "Interpretations"
    },
    {
      "term": "Machine Translation (MT) is the task of automatically converting one natural _______ into another, preserving the meaning of the input text, and _____ fluent text in the output language.",
      "definition": "Language, Producing"
    },
    {
      "term": "Which is not MT approach?",
      "definition": "Symbol"
    },
    {
      "term": "MT performs __________ substitution of words in one language for words in another",
      "definition": "Mechanical"
    },
    {
      "term": "Information retrieval (IR) is finding material (usually documents) of an _____ nature that satisfies an information need from within large _______.",
      "definition": "Unstructured, collections"
    },
    {
      "term": "Which is not a model of Information retrieval?",
      "definition": "Alternative"
    },
    {
      "term": "Which is not a componentof IR?",
      "definition": "Reviewing system"
    },
    {
      "term": "A perfect IR system will retrieve only relevant documents.",
      "definition": "Relevant"
    },
    {
      "term": "Sentiment analysis is the ________ and _______ of emotions (positive, negative and neutral) withintext data using text analysis techniques.",
      "definition": "Interpretation, Classification"
    },
    {
      "term": "Whichalgorithm is used in Classification of SE?",
      "definition": "Linear regression"
    },
    {
      "term": "Which is a challenge for SE?",
      "definition": "All of the above"
    },
    {
      "term": "Which is not a SE classification technique?",
      "definition": "Semi-automated"
    },
    {
      "term": "Which is application of SE?",
      "definition": "All of the above"
    },
    {
      "term": "Which is a step of finding Sentiment Polarity?",
      "definition": "All of the above"
    },
    {
      "term": "Feature selection includes",
      "definition": "Option A and B"
    },
    {
      "term": "Named entity recognition is a popular technique used in information extraction to________ and__________ the named entities and __________ them under various predefined classes.",
      "definition": "Identify, Segment, Categorize"
    },
    {
      "term": "Entity extraction is really useful for analyzing _________ text",
      "definition": "Unstructured"
    },
    {
      "term": "Which is A method for Named-entity extractions",
      "definition": "All of the above"
    },
    {
      "term": "Rule-based systems for entity extraction employ a ______ of grammatical ______ hand-crafted bycomputational ________.",
      "definition": "Series, Rules, Linguists"
    },
    {
      "term": "Which is not a application of Named-entity extractions",
      "definition": "Recognizing characters from images"
    },
    {
      "term": "It is a process of generating a concise and meaningful __________ of ________ from multiple text resources such as books, news articles, blog posts, research papers, emails, and tweets.",
      "definition": "Summary, text"
    },
    {
      "term": "In extractive Summarization, we identify the important _______ or ______ from the original text and______ only those from the text.",
      "definition": "Sentences, phrases, extracts"
    },
    {
      "term": "In abstractive summarization, we ___________ new sentences from the _______ text.",
      "definition": "Generate, original"
    },
    {
      "term": "text summarization in NLP is treated as a _______ machine learning problem",
      "definition": "Supervised"
    },
    {
      "term": "Text classification also known as text _______ or text ________ is the process of categorizing text into________ groups.",
      "definition": "Tagging, Categorization, organized"
    },
    {
      "term": "Text classification is used in",
      "definition": "All of the above"
    },
    {
      "term": "Which is not a text classification technique?",
      "definition": "OCR"
    },
    {
      "term": "Which is a type of text based classification?",
      "definition": "Option A and B"
    },
    {
      "term": "Sentiment analysis refers to the use of natural language processing to systematically ________,_______, ________, and _____ affective states and subjective information.",
      "definition": "Identify, extract, quantify, study"
    },
    {
      "term": "Which is a example of Sentiment analysis?",
      "definition": "All of the above"
    },
    {
      "term": "Which model is not used in Information Retrieval?",
      "definition": "Bayesian model"
    },
    {
      "term": "What is pragmatic Analysis?",
      "definition": "All of the above"
    },
    {
      "term": "_________analysis deals with the overall communicative and social content and its effect on interpretation. It means abstracting or deriving the meaningful use of language in situations",
      "definition": "Pragmatic Analysis"
    },
    {
      "term": "We could also say that ____is the process of 'pointing' via language.",
      "definition": "Deixis"
    },
    {
      "term": "Deictic expressions are among the first forms to be acquired and spoken by very young children. They can be used to point to a person via_______(me,you)",
      "definition": "Person deixis"
    },
    {
      "term": "Deictic expressions are among the first forms to be acquired and spoken by very young children.They can be used to point to a location via_______(here,there)",
      "definition": "Spatial deixis"
    },
    {
      "term": "Deictic expressions are among the first forms to be acquired and spoken by very young children.They can be used to point to time via__________ (now,then).",
      "definition": "Temporal deixis"
    },
    {
      "term": "An________is something the speaker suggests or implies with an utterance, even though it is not literally expressed.",
      "definition": "Implicature"
    },
    {
      "term": "_______can aid in communicating more efficiently than by explicitly saying everything we want to communicate.",
      "definition": "Implicature"
    },
    {
      "term": "A_______is an implicit assumption about the world or background belief relating to an utterance whose truth is taken for granted in discourse.",
      "definition": "Presupposition(PSP)"
    },
    {
      "term": "_____________ represent a key concept in the field of pragmatics which can be broadly defined as language use in context taking into account the speaker's and the addressee's verbal and non-verbal contributions to the negotiation of meaning in interaction.",
      "definition": "Speech acts"
    },
    {
      "term": "What are the types of speech acts according to John Searle?",
      "definition": "All of the above"
    },
    {
      "term": "Speech Acts are of following types:",
      "definition": "Both a & b"
    },
    {
      "term": "Essentially,______is about the way conversation works in practice.",
      "definition": "Conversational Structure"
    },
    {
      "term": "____________ commit a speaker to the truth of an expressed proposition.",
      "definition": "Representatives"
    },
    {
      "term": "_________ commit a speaker to some futureaction.",
      "definition": "Comisessives"
    },
    {
      "term": "___________are used by a speaker who attempts to get the addressee to carry out an action.",
      "definition": "Directives"
    },
    {
      "term": "__________affect an immediate change of affairs.",
      "definition": "Declarations"
    },
    {
      "term": "_______________ express some sort of psychological state.",
      "definition": "Expressive"
    },
    {
      "term": "__________may be defined as the linguisticexpression to denote an entity or individual.",
      "definition": "Reference"
    },
    {
      "term": "_____________may be defined as the task of determining what entities are referred to by which linguistic expression.",
      "definition": "Reference Resolution"
    },
    {
      "term": "The natural language expression that is used to perform reference is called a ____.",
      "definition": "Referring expression"
    },
    {
      "term": "It is the entity that is referred:",
      "definition": "Referent"
    },
    {
      "term": "When two expressions are used to refer to the same entity, they are called_____.",
      "definition": "Corefers"
    },
    {
      "term": "The term has the license to use another term:",
      "definition": "Antecedent"
    },
    {
      "term": "____may be defined as the reference to an entity that has been previously introduced into the sentence. And, the referring expression is called ____.",
      "definition": "Both b & c"
    },
    {
      "term": "The model that contains the representations of the entities that have been referred to in the discourse and the relationship they are engaged in.",
      "definition": "Discourse Model"
    },
    {
      "term": "Referring Expressions have following types:",
      "definition": "All of the above"
    },
    {
      "term": "Types of Referring expressions are:",
      "definition": "Both a & b"
    },
    {
      "term": "What are the reference tasks?",
      "definition": "Both a & b"
    },
    {
      "term": "What is Coreference resolution?",
      "definition": "It is the task of finding referring expressions in a text that refer to the same entity."
    },
    {
      "term": "What is a Pronominal Anaphora expression?",
      "definition": "It is defined as the task of finding the ant ecedent for a single pronoun."
    },
    {
      "term": "What are the types of Coreference?",
      "definition": "All of the above"
    },
    {
      "term": "In a coreference resolution task, the ____is the number of noun phrase pairs correctly labeled as coreferent (true positives) divided by the total number of pairs labeled as coreferent",
      "definition": "Precision"
    },
    {
      "term": "____ in this context is defined as the number of true positives divided by the total number of pairs that actually corefer.",
      "definition": "Recall"
    },
    {
      "term": "What are the three machine learning approaches for coreference resolution?",
      "definition": "All of the above"
    },
    {
      "term": "What is the concept of Clustering approach for coreference?",
      "definition": "If the distance between two noun phrases is less than the clustering radius t hreshold r and their coreference equivalence classes are compatible, then the classes are merged"
    },
    {
      "term": "What is the Decision tree approach for Coreference?",
      "definition": "Applying Decision tree for coreference resolution requires a set of features describing pairs of noun phrases and recasting the coreference problem as a classification task."
    },
    {
      "term": "What is the function of Algorithm based on a Bell tree?",
      "definition": "In each step of the algorithm, one mention is added by either linking to each of existing entities, or starting a new entity. A new layer of nodes is created to represent all possible coreference outcomes by adding one mention. The number of tree leaves is the number of possible coreference outcomes and it equals the Bell number"
    },
    {
      "term": "An anaphora and all its antecedents form a coreference sequence called ___________________",
      "definition": "Coreferential chain"
    },
    {
      "term": "A typical coreference resolution system takes an _______as input and produces the appropriate coreferential chains as output.",
      "definition": "Arbitrary document"
    },
    {
      "term": "Coreference is hard because ________________",
      "definition": "Both a & b"
    },
    {
      "term": "Applications of Co-reference:",
      "definition": "All of the above"
    },
    {
      "term": "If the distance between two noun phrases is less than the clustering radius threshold r and their coreference equivalence classes are compatible, then the classes are merged. This concept relates to____.",
      "definition": "Clustering Approach"
    },
    {
      "term": "In each step of this algorithm, one mention is added by either linking to each of existing entities, or starting a new entity. A new layer of nodes is created to represent all possible coreference outcomes by adding one mention. The number of tree leaves is the number of possible coreference outcomes and it equals the Bell number.",
      "definition": "Algorithm based on Bell tree"
    },
    {
      "term": "Applying tree algorithms for coreference resolution requires a set of features describing pairs of noun phrases and recasting the coreference problem as a classification task.",
      "definition": "Decision Tree Algorithm"
    },
    {
      "term": "Anaphora is a see also of coreference. As nouns the difference between anaphora and coreference is that ____________ is (rhetoric) the repetition of a phrase at the beginning of phrases, sentences, or verses, used for emphasis while ____ is (grammar) the relationship between multiple terms that have a common referent.",
      "definition": "anaphora, coreference"
    },
    {
      "term": "_____is the task of automatically converting one natural language into another, preserving the meaning of the input text, and producing fluent text in the output language.",
      "definition": "Machine Translation"
    },
    {
      "term": "Machine translation algorithm are as follows:",
      "definition": "All of the above"
    },
    {
      "term": "What is Rule-based machine translation approach?",
      "definition": "a general term that denotes machine translation systems based on linguistic information about source and target languages basically retrieved from (bilingual) dictionaries and grammars covering the main semantic, morphological, and syntactic regularities of each language respectively."
    },
    {
      "term": "What is corpus based machine translation?",
      "definition": "As its name points, a bilingual parallel corpus to obtain knowledge for new incoming translation. This approach uses a large amount of raw data in the form of parallel corpora."
    },
    {
      "term": "What is hybrid based machine translation?",
      "definition": "This approach to develop translation from source to target language, which is based on both rules and statistics."
    },
    {
      "term": "Hybrid machine translation is a method of machine translation that is characterized by the use of ___________ machine translation approaches within a single machine translation system.",
      "definition": "Multiple"
    },
    {
      "term": "_______, also known as Knowledge-Based Machine Translation and Classical Approach of MT,",
      "definition": "Rule-based machine translation approach."
    },
    {
      "term": "RBMT methodology applies a set of linguistic rules in three different phases:",
      "definition": "All of the above"
    },
    {
      "term": "A rule-based system requires:",
      "definition": "Both a & b"
    },
    {
      "term": "___________ may be defined as a software program that deals with the organization, storage, retrieval and evaluation of information from document repositories particularly textual information",
      "definition": "Information retrieval"
    },
    {
      "term": "A______that denotes machine translation systems based on linguistic information about source and target languages basically retrieved from (bilingual) dictionaries and grammars covering the main semantic, morphological, and syntactic regularities of each language respectively.",
      "definition": "Rule-based machine translation approach."
    },
    {
      "term": "As its name points, a bilingual parallel corpus to obtain knowledge for new incoming translation. _____approach uses a large amount of raw data in the form of parallel corpora.",
      "definition": "Corpus-based"
    },
    {
      "term": "_________ approach to develop translation from source to target language, which is based on both rules and statistics.",
      "definition": "Hybrid machine translation approach"
    },
    {
      "term": "A______ first analyses the source language input and creates an internal representation. This representation is manipulated and transferred to a form suitable for the target language.",
      "definition": "Machine Translation system"
    },
    {
      "term": "In ____retrieval, the user must enter a query in natural language that describes the required information. Then the IR system will return the required documents related to the desired information.",
      "definition": "Ad-hoc retrieval"
    },
    {
      "term": "What are the types of Information retrieval model?",
      "definition": "All of the above"
    },
    {
      "term": "This model is based on mathematical knowledge that was easily recognized and understood as well.",
      "definition": "Classical IR model"
    },
    {
      "term": "What are the types of classical IR models?",
      "definition": "All of the above"
    },
    {
      "term": "Such kinds of IR models are based on principles other than similarity, probability, Boolean operations.",
      "definition": "Non-classical IR"
    },
    {
      "term": "What are the examples of Non-classical IR models?",
      "definition": "All of the above"
    },
    {
      "term": "It is the enhancement of classical IR models making use of some specific techniques from some other fields.",
      "definition": "Alternative IR model"
    },
    {
      "term": "Following are the examples of Alternative IR models:",
      "definition": "All of the above."
    },
    {
      "term": "______ is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.",
      "definition": "Question answering (QA)"
    },
    {
      "term": "What is Question answering in NLP?",
      "definition": "It is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language"
    },
    {
      "term": "In information retrieval, an _____ question answering system aims at returning an answer in response to the user's question. The returned answer is in the form of short texts rather than a list of relevant documents.",
      "definition": "Open domain"
    },
    {
      "term": "The open domain question answering system uses a combination of techniques from ______for finding answers.",
      "definition": "All of the above"
    },
    {
      "term": "What Open system question answering system aims to?\n\na. This representation is manipulated and transferred to a form suitable for the target language. Then at last output is generated in the target language\nb. as its name points, a bilingual parallel corpus to obtain knowledge for new incoming translation. This approach uses a large amount of raw data in the form of parallel corpora.\nc. This system aims at returning an answer in response to the user's question. The returned\nanswer is in the form of short texts rather than a list of relevant documents.\nd. None of the above",
      "definition": "An open source ____question answering system based on Ask Platypus and Wikidata was published in 2018.\n\na. math-aware\nb. Close domain\nc. Open domain\nd. IR system"
    },
    {
      "term": "An open source math-aware question answering system takes an _____natural language question as input and returns a mathematical formula retrieved from Wikidata as a succinct answer.",
      "definition": "English or spanish"
    },
    {
      "term": "______ is the interpretation and classification of emotions (positive, negative and neutral) within text data using text analysis techniques.",
      "definition": "Hybrid analysis"
    },
    {
      "term": "_______ tools allow businesses to identify customer sentiment toward products, brands or services in online feedback.",
      "definition": "Sentiment Analysis"
    },
    {
      "term": "Types of sentiment analysis are:",
      "definition": "All of the above"
    },
    {
      "term": "What are the polarity categories?",
      "definition": "All of the above"
    },
    {
      "term": "This type of sentiment analysis aims at detecting emotions, like happiness, frustration, anger, sadness, and so on.",
      "definition": "Aspect-based Sentiment Analysis"
    },
    {
      "term": "Many emotion detection systems use ____or complex machine learning algorithms.",
      "definition": "Lexicons"
    },
    {
      "term": "Usually, when analyzing sentiments of texts, let's say product reviews, you'll want to know which particular features people are mentioning in a positive, neutral, or negative way. That's where ______ can help,",
      "definition": "Emotion detection"
    },
    {
      "term": "Benefits of sentiment analysis includes:",
      "definition": "All of the above"
    },
    {
      "term": "Sentiment analysis uses various Natural Language Processing (NLP) methods and algorithms, The main types of algorithms used include:",
      "definition": "All of the above"
    },
    {
      "term": "What are the Sentiment analysis challenges?",
      "definition": "All of the above"
    },
    {
      "term": "What are the applications of sentiment analysis?",
      "definition": "All of the above"
    },
    {
      "term": "___________also known as text tagging or text categorization is the process of categorizing text into organized groups.",
      "definition": "Text classification"
    },
    {
      "term": "By using Natural Language Processing (NLP), _____can automatically analyze text and then assign a set of pre-defined tags or categories based on its content.",
      "definition": "None of the above"
    },
    {
      "term": "Some of the most common examples and use cases for automatic text classification include the following:",
      "definition": "Topic Detection"
    },
    {
      "term": "___________is the process of understanding if a given text is talking positively or negatively about a given subject (e.g. for brand monitoring purposes).",
      "definition": "All of the above"
    },
    {
      "term": "_______________ is the task of identifying the theme or topic of a piece of text (e.g. know if a product review is about Ease of Use, Customer Support, or Pricing when analyzing customer feedback).",
      "definition": "Language Detection"
    },
    {
      "term": "The ____________ is a procedure of detecting the language of a given text (e.g. know if an incoming support ticket is written in English or Spanish for automatically routing tickets to the appropriate team).",
      "definition": "Topic Detection"
    },
    {
      "term": "Text classification techniques include:",
      "definition": "Hybrid systems"
    },
    {
      "term": "______classify text into organized groups by using a set of handcrafted linguistic rules.",
      "definition": "All of the above"
    },
    {
      "term": "Some of the most popular machine learning algorithms for creating text classification models include:",
      "definition": "Naive Bayes"
    },
    {
      "term": "Generally, a classification technique could be divided into ____approaches.",
      "definition": "Both b & c"
    },
    {
      "term": "It is a process of generating a concise and meaningful summary of text from multiple text resources such as books, news articles, blog posts, research papers, emails, and tweets.",
      "definition": "Text Summarization"
    },
    {
      "term": "Text summarization methods are as follows:",
      "definition": "None of the above"
    },
    {
      "term": "_______________ methods function by identifying the important sentences or excerpts from the text and reproducing them verbatim as part of the summary. No new text is generated; only existing text is used in the summarization process.",
      "definition": "Text Summarization"
    },
    {
      "term": "What is extractive text summarization?",
      "definition": "methods employ more powerful natural language processing techniques to interpret text and generate new summary text, as opp osed to selecting the most representative existing excerpts to perform the summarization."
    },
    {
      "term": "____________ methods employ more powerful natural language processing techniques to interpret text and generate new summary text, as opposed to selecting the most representative existing excerpts to perform the summarization.",
      "definition": "Text Summarization"
    },
    {
      "term": "What is abstractive text summarization?",
      "definition": "It is a process of generating a concise and meaningful summary of text from multiple text resources such as books, news articles, blog posts, research papers, emails, and tweets."
    },
    {
      "term": "___________ is the task of identifying and categorizing key information (entities) in text.",
      "definition": "Extractive Summarization"
    },
    {
      "term": "An __________ can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category.",
      "definition": "None of the above"
    },
    {
      "term": "At the heart of any NER model is a two-step process:",
      "definition": "Categorize the entity"
    },
    {
      "term": "Is The Type Of Morphology That Changes The Word Category And Affects The Meaning.\nA. Inflectional\nB. Derivational\nC. Cliticization\nD. Text-Proofing",
      "definition": "B. Derivational\n3 phương án trắc nghiệm"
    },
    {
      "term": "What are the approaches of NLP?\nA. Morphological and Lexical Analysis, Syntactic Analysis, Semantic Analysis, Discourse Integration, Pragmatic Analysis\nB. Symbolic, Statistical, Connectionist and Hybrid\nC. Machine Learning, Deep Learning & Al\nD. None of the others",
      "definition": "A. Morphological and Lexical Analysis, Syntactic Analysis, Semantic Analysis, Discourse Integration, Pragmatic Analysis\n3 phương án trắc nghiệm"
    },
    {
      "term": "The branches of linguistics that focus on the meaning of a language\nA. Semantics & phonology\nB. Semantics & pragmatics\nC. Morphology & pragmatics\nD. Pragmatics & phonology",
      "definition": "B. Semantics & pragmatics\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following technique is used to remove semantic ambiguity?\nA. Fuzzy Logic\nB. Shallow Semantic Analysis\nC. Syntactic analysis\nD. Word Sense Disambiguation",
      "definition": "D. Word Sense Disambiguation\n3 phương án trắc nghiệm"
    },
    {
      "term": "When we encounter two or more words with the same form and related meanings, we have what is known as _______\nA. Hyponymy\nB. Polysemy\nC. Homonyms\nD. Source",
      "definition": "B. Polysemy\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which of the following is not a problem when using Maximum Likelihood Estimation to obtain parameters in a language model?\nA. Unreliable estimates where there is little training data\nB. Out-of-vocabulary terms\nC. Overfitting\nD. Smoothing",
      "definition": "D. Smoothing\n3 phương án trắc nghiệm"
    },
    {
      "term": "What Can Be Called As \"The Knowledge Of What Has Been Said Earlier\"\nA. Situational Context\nB. Background Knowledge\nC. Co-Textual Context\nD. Operational Knowledge",
      "definition": "C. Co-Textual Context\n3 phương án trắc nghiệm"
    },
    {
      "term": "He doesn't know is an example of ____________ type of deixis\nA. Personal\nB. Time\nC. Social\nD. Space",
      "definition": "A. Personal\n3 phương án trắc nghiệm"
    },
    {
      "term": "Parts-of-Speech tagging Does not determine __________\nA. part-of-speech for each word dynamically as per meaning of the sentence\nB. part-of-speech for each word dynamically as per sentence structure\nC. all part-of-speech for a specific word given as input\nD. all part-of-speech for a specific stem from input",
      "definition": "D. all part-of-speech for a specific stem from input\n3 phương án trắc nghiệm"
    },
    {
      "term": "What pragmatic ambiguity refers?\nA. It refers to a situation where the context of a phrase gives it multiple interpretation\nB. It refers to Statistical analysis\nC. It refers to only Misinterpreted words\nD. All of the others",
      "definition": "A. It refers to a situation where the context of a phrase gives it multiple interpretation\n3 phương án trắc nghiệm"
    },
    {
      "term": "___________ ambiguity refers to a situation where the context of a phrase gives it multiple interpretation\nA. Pragmatic\nB. Anaphoric\nC. Discourse\nD. Cataphoric",
      "definition": "A. Pragmatic\n3 phương án trắc nghiệm"
    },
    {
      "term": "_________ used for stripping of affixes. It uses a set of rules containing a list of stems and replacement rules.\nA. Two-level morphology model\nB. Chomsky Model\nC. Finite State Automata\nD. Stemmer",
      "definition": "D. Stemmer\n3 phương án trắc nghiệm"
    },
    {
      "term": "Suppose you have the following training data for Naive Bayes: I liked the dish [LABEL = POS] I disliked the dish because it contains sugar [LABEL = NEG] Really tasty dish [LABEL = POS] What is the unsmoothed Maximum Likelihood Estimate (MLE) of P(POS) for this data?\nA. 1/2\nB. 1/3\nC. 2/3\nD. 1",
      "definition": "C. 2/3\n3 phương án trắc nghiệm"
    },
    {
      "term": "How many trigrams phrases can be generated from the following sentence, after performing stop word removal? Google is one of the most widely used search engine in Vietnam.\nA. 2\nB. 3\nC. 4\nD. 5",
      "definition": "C. 4\n3 phương án trắc nghiệm"
    },
    {
      "term": "This type of automata maps between two sets of symbols.\nA. DFA\nB. Turing Machine\nC. FST\nD. NFA",
      "definition": "C. FST\n3 phương án trắc nghiệm"
    },
    {
      "term": "What is the number of trigrams in a normalized sentence of length n words?\nA. n\nB. n-1\nC. n-2\nD. n-3",
      "definition": "C. n-2\n3 phương án trắc nghiệm"
    },
    {
      "term": "What are the components of Morphological Analyzer acc., to Shrivastava et. al 2005?\nA. The recognition engine, identifying suffixes, and finding a stem within the input word algorithms\nB. Morpheme lexeme, Set of rules governing the spelling and composition of morphologically complex words & Decision algorithm\nC. The recognition engine, set of rules & Algorithm\nD. All of the others",
      "definition": "A. The recognition engine, identifying suffixes, and finding a stem within the input word algorithms\n3 phương án trắc nghiệm"
    },
    {
      "term": "NLP stands for Natural Language Processing.\nA. True\nB. False",
      "definition": "A. True\n1 phương án trắc nghiệm"
    },
    {
      "term": "In NLP, The process of converting a sentence or paragraph into tokens is referred to as Stemming\nA. True\nB. False",
      "definition": "B. False\n1 phương án trắc nghiệm"
    },
    {
      "term": "When the meaning of the words themselves can be misinterpreted then ___________ ambiguity occurs.\nA. Scope Ambiguity\nB. Pragmatic Ambiguity\nC. Semantic Ambiguity\nD. None of the others",
      "definition": "C. Semantic Ambiguity\n3 phương án trắc nghiệm"
    },
    {
      "term": "Discrete representation, aka integerized words\nA. pre-cursor to words as vectors\nB. distributed word representations\nC. advantages of distributed word representations\nD. notion of context as meaning",
      "definition": "A. pre-cursor to words as vectors\n3 phương án trắc nghiệm"
    },
    {
      "term": "An example of unstructured data is ______\nA. age information\nB. customer reviews.\nC. movie rating score\nD. gender of customers",
      "definition": "B. customer reviews.\n3 phương án trắc nghiệm"
    },
    {
      "term": "P(rolling an odd number or a # >4) on a die\nA. 5/6\nB. 2/3\nC. 1/6\nD. 1/3",
      "definition": "B. 2/3\n3 phương án trắc nghiệm"
    },
    {
      "term": "This involves analysis of the words in a sentence by following the grammatical structure of the sentence.\nA. Tokens\nB. Lexical Analysis\nC. Discourse\nD. Syntax Analysis",
      "definition": "D. Syntax Analysis\n3 phương án trắc nghiệm"
    },
    {
      "term": "Which application use to determine people in context?\nA. Stemming\nB. Lemmatization\nC. Stop word removal\nD. Named entity recognition",
      "definition": "D. Named entity recognition\n3 phương án trắc nghiệm"
    },
    {
      "term": "IR (information Retrieval) and IE (Information Extraction) are the two same thing.\nA. TRUE\nB. FALSE",
      "definition": "B. FALSE\n1 phương án trắc nghiệm"
    },
    {
      "term": "What is the type of the return value of the re.findall() method?\nA. A list of strings\nB. An integer\nC. A boolean\nD. A single character",
      "definition": "A. A list of strings\n3 phương án trắc nghiệm"
    },
    {
      "term": "________ is also known as shallow parsing.\nA. Rooting\nB. Chunking\nC. Steaming\nD. Lemmatization",
      "definition": "B. Chunking\n3 phương án trắc nghiệm"
    },
    {
      "term": "Suppose you have the following training data for Naive Bayes: I liked the dish [LABEL = POS] I disliked the dish because it contains sugar [LABEL = NEG] Really tasty dish [LABEL = POS] What is the unsmoothed Maximum Likelihood Estimate (MLE) of P(POS) for this data?",
      "definition": "2/3"
    },
    {
      "term": "1 :\nWhich of the following is not a learning approach for QA system\nUnsupervised approach\nSupervised approach\nKnowledge based approach\nSense disambiguation approach",
      "definition": "Sense disambiguation approach"
    },
    {
      "term": "2 :\nWhich of the following is not true input for the NLP?\nImage\nText\nTypes input\nSpeech",
      "definition": "Image"
    },
    {
      "term": "3 : How is the word \"changing\" lematized?",
      "definition": "change"
    },
    {
      "term": "4 :\nImage summarization finds the most representative images within an _____ collection\nText\nImage\nSound\nWord",
      "definition": "Image"
    },
    {
      "term": "5 :\nWhich is not types of antonyms\nPolar antonyms\nEquipollent antonyms\nOverlapping antonyms\nUnipolar antonyms",
      "definition": "---------"
    },
    {
      "term": "6 :\nRule for removing suffix will be given in form \"(Condition) S1 ® S2\", where S1 is suffix. If the condition is \"(*d)\" then which of the following is correct interpretation?\nThe stem ends with S.\nThe stem contain vowel.\nThe stem ends with a double consonant (eg. -TT, -SS)\nThe stem ends CVC, where second C is not W, X, or Y",
      "definition": "The stem ends with a double consonant (eg. -TT, -SS)"
    },
    {
      "term": "7 :\nWhat is the main challenge of NLP?\nHandling Tokenization\nHandling Ambiguity of Sentences\nCleaning Text\nFiltering Text",
      "definition": "Handling Ambiguity of Sentences"
    },
    {
      "term": "8 :\nIdentify odd one out\nNoun phrase\nVerb phrase\nPrepositional phrase\nSentences",
      "definition": "Sentences"
    },
    {
      "term": "9 : \"The car hit the pole while it was moving.\" what type of ambiguity exists in above sentence?",
      "definition": "Semantic"
    },
    {
      "term": "10 : Which is standard notation for characterizing text sequences?",
      "definition": "Regular expression"
    },
    {
      "term": "11 :\nDictionary-based sentiment analysis is a computational approach relies on a pre-defined list (or dictionary) of sentiment-laden words.\nprobability model.\na pre-defined list of sentiment-laden words.\nCRF\nHMM",
      "definition": "a pre-defined list of sentiment-laden words."
    },
    {
      "term": "12 :\nWhat Creates Problems In Machine Translation?\nDifferent Level Of Ambiguities\nProcessing Power\nMemory\nDiversity",
      "definition": "Different Level Of Ambiguities"
    },
    {
      "term": "13 : TF-IDF helps in ....... Finding the most frequently occurring word in the document",
      "definition": "Spelling Corrections"
    },
    {
      "term": "14 :\nGiven a sound clip of a person or people speaking, determine the textual representation of the speech.\nText-to-speech\nSpeech-to-text\nSpeech recognition\nspeech generation",
      "definition": "Speech-to-text"
    },
    {
      "term": "15 :\nWhat is Syntax Analysis?\nThis only abstracts the dictionary meaning or the real meaning from the given context.\nThis component transfers linear sequences of words into structures. It shows how the words are associated with each other.\nIt deals with the overall communicative and social content and its effect on interpretation. It means abstracting or deriving the meaningful use of language in situations.\nIt focuses about the proper ordering of words which can affect its meaning. This involves analysis of the words in a sentence by following the grammatical structure of the sentence. The words are transformed into the structure to show how the words are related to each other.",
      "definition": "It focuses about the proper ordering of words which can affect its meaning. This involves analysis of the words in a sentence by following the grammatical structure of the sentence. The words are transformed into the structure to show how the words are related to each other."
    },
    {
      "term": "16 :\nHuman Usually Write 'M, To State Am, In Which Type Of Morphology You Can Categorize The Example?\nPlural Noun\nCliticization\nSingular Noun\nInflectional",
      "definition": "Cliticization"
    },
    {
      "term": "17 :\nWhich of the following best describes grammar induction?\nSupervised learning problem\nMaximum-A-Posteriori (MAP) estimation problem\nConditional Random Field problem and Unsupervised learning problem\nReinforcement Learning",
      "definition": "---------"
    },
    {
      "term": "18 : _________is the study of how the language is used to refer (and re-refer) to people and things?",
      "definition": "Pragmatics"
    },
    {
      "term": "19 :\nWhich of the following is a kind of text summarization?\nTopic-based summarization\nExtraction-based summarization\nHistory-based summarization\nSummarizing a text or article",
      "definition": "Extraction-based summarization"
    },
    {
      "term": "20 :\nThe words 'there' and 'their' causes which of the following type of ambiguity?\nSyntactic\nSemantic\nPhonological\nPragmatic",
      "definition": "Phonological"
    },
    {
      "term": "21 :\nChoose form the following areas where NLP can be useful\nAutomatic Question-Answering Systems\nMobile Computing\nFrontpage Designing\nWeb Development",
      "definition": "Automatic Question-Answering Systems"
    },
    {
      "term": "22 :\n_________ Is the Third Stage in NLP?\nSyntactic Analysis\nDiscourse Analysis\nSemantic Analysis\nPragmatic Analysis",
      "definition": "Semantic Analysis"
    },
    {
      "term": "23 :\nPorter Stemmer algorithm use for _______.\nLemmatization\nSyntax Analysis\nStemming\nPart of speech tagging",
      "definition": "Stemming"
    },
    {
      "term": "24 :\nWho is the father of NLP?\nEnjamin Bandler\nRichard Bandler\nElijah Bandler\nMarvin Minsky",
      "definition": "Richard Bandler"
    },
    {
      "term": "25 : This type of automata maps between two sets of symbols.",
      "definition": "ERROR: Cannot find option FST"
    },
    {
      "term": "26 :\nThe english words through and threw are examples of____________\nAutomymy\nPolysemy\nSynonymy\nHomophony",
      "definition": "Synonymy"
    },
    {
      "term": "27 :\n__ involves resolving words to their dictionary form\nOverstemming\nUnderstemming\nLemmatization\nNER",
      "definition": "Lemmatization"
    },
    {
      "term": "28 :\nConceal - cover is a example of ________\nAntonym\nSynonym\nPolysemy\nHomonym",
      "definition": "Synonym"
    },
    {
      "term": "29 :\nWhen Spelling Changes Upon Combination Of Words Added, Belong To Which Type Of Rule?\nOrthographic Rules\nGrammer Rules\nBound Morpheme\nFree Morpheme",
      "definition": "Orthographic Rules"
    },
    {
      "term": "30 :\nThe standard approach to information retrieval system evaluation involves around the notion of:\nQuantity of documents in the collection\nRelevant and non relevant documents.\nAccuracy\nuser happiness",
      "definition": "Relevant and non relevant documents."
    },
    {
      "term": "31 :\nWhat is the right order for a text classification model components 1. Text cleaning 2. Text annotation 3. Gradient descent 4. Model tuning 5. Text to predictors\n12345\n13425\n12534\n13452",
      "definition": "12534"
    },
    {
      "term": "32 :\nWhich of the following is true?\nGiven a CFG and its corresponding CNF, they both produce the same language.\nFor a given grammar, there can be only one CNF.\nIt requires '2n+1' productions or steps in CNF to generate a string w of length 'n'.\nCFG and CNF both are same",
      "definition": "ERROR: No options for answer a"
    },
    {
      "term": "33 :\nThe list of web pages that a web crawler has queued up to index is called the:\nWeb Page Queue\nSeed set\nURL Filter\nURL Frontier",
      "definition": "---------"
    },
    {
      "term": "34 : HMM is used in __________ phase of NLP.",
      "definition": "Syntactic"
    },
    {
      "term": "35 :\n_________ Is The Type Of Morphology That Changes The Word Category And Affects The Meaning.\nInflectional\nDerivational\nCliticization\nText-Proofing",
      "definition": "Derivational"
    },
    {
      "term": "36 :\n\"It is the inverse probability of the test data which is normalized by the number of words.\" This is the definition of\nLanguage Model\nN-gram\nPerplexity\nLaplace smoothing",
      "definition": "Perplexity"
    },
    {
      "term": "37 :\nIn HMMs, spaces are connected via ______ matrices {T,A} to represent the probability of ________ from one state to another following their _____\nTransitions, Transitioning, Connections\nAttribute, Changing, groups\nLabel, moving, sets\nAttribute, moving, sets",
      "definition": "Transitions, Transitioning, Connections"
    },
    {
      "term": "38 :\nWhich of the following features cannot be used for accuracy improvement of a classification model?\nPart of Speech Tag\nDependency Grammar\nVector Notation of sentence\nLinear regression",
      "definition": "Linear regression"
    },
    {
      "term": "39 : Perfect homonyms create problems in ..............",
      "definition": "Speech Recognition"
    },
    {
      "term": "40 :\n\"I bought a beautiful dress at the mall\". The part of speech of underline word is_____\nPreposition\nAdjective\nNoun\nAdverb",
      "definition": "Adjective"
    },
    {
      "term": "41 :",
      "definition": "ERROR: Cannot find option NLTK"
    },
    {
      "term": "42 :\nGiven a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\")\nAnaphora Resolution\nCoreference Resolution\nNoun Resolution\nPronoun Resolution",
      "definition": "Coreference Resolution"
    },
    {
      "term": "43 :\nWordNet is the _______________ database\nSymbol\nWord\nLexical\nAnnotation",
      "definition": "Lexical"
    },
    {
      "term": "44 :\nHeadlines in newspaper: \"Stolen gems found by Caves\"\nAnaphoric Ambiguity\nLexical Ambiguity\nSyntax Ambiguity\nUnknown Ambiguity",
      "definition": "Unknown Ambiguity"
    },
    {
      "term": "45 :\nAmong Which Of Following Models Identify Dependency Between Each State And The Entire Input Sequences\nConditional Random Fields\nMaximum Entropy Markov Model\nNaive Bayes Model\nDepth-First Model",
      "definition": "Conditional Random Fields"
    },
    {
      "term": "46 :\n----------is the study of internal structure of word.\nMorphological Processing\nSyntax Processing\nParser\nSemantic Processing",
      "definition": "Morphological Processing"
    },
    {
      "term": "47 :\nIf we want to capture a request, or perform an action, use an ________.\nentity\ncontent\nidentity\nintent",
      "definition": "---------"
    },
    {
      "term": "48 :\nGiven a set of unigram and bigram probabilities, what is the probability of the following sequence ' do Sam I like' according to the bigram language model? P(do|) = 2/11, P(do|Sam) = 1/11, P(Sam|) = 4/11, P(Sam|do) = 1/8, P(I|Sam) = 4/11, P(Sam|I) = 2/9, P(I|do) = 2/8, P(I|like) = 2/7, P(like|I) = 3/11, P(do) = 3/8, P(Sam) = 2/11, P(I) = 4/11, P(like) = 5/11\n3/11 2/11 4/11 * 5/11\n2/11 1/8 4/11 * 3/11\n2/11 1/11 2/9 * 2/7\n2/11 + 1/11 + 2/9 + 2/7",
      "definition": "2/11 1/8 4/11 * 3/11"
    },
    {
      "term": "49 :\nWhich are words that have the same form but have different, unrelated meanings\nPolysemy\nHomonyms\nSynonymy\nAntonymy",
      "definition": "Polysemy"
    },
    {
      "term": "50 :\nWhat Type Of Ambiguity Exists In The Word Sequence \"Time Flies\"?\nSyntactic\nSemantic\nPhonological\nAnaphoric",
      "definition": "Semantic\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 2 ---"
    },
    {
      "term": "51 :",
      "definition": "nltk   BERT"
    },
    {
      "term": "52 :\nThe Area Of Ai That Investigates Methods Of Facilitating Communication Between People And Computers Is:\nNatural Language Processing\nSymbolic Processing\nDecision Support\nRobotics",
      "definition": "Natural Language Processing"
    },
    {
      "term": "53 :\nTrains two independent LSTM language model left to right and right to left and shallowly concatenates them\nGPT\nBERT\nULMFit\nELMo",
      "definition": "ELMo"
    },
    {
      "term": "54 :\n\"Rohan Was With Her, They Both Go Together\", In The Given Sentence Who Is Her Is Unclear, Specify The Type Of Ambiguity ?\nSemantic Ambiguity\nAnaphoric Ambiguity\nPragmetic Ambiguity\nLexical Ambiguity",
      "definition": "Anaphoric Ambiguity"
    },
    {
      "term": "55 : Which of the following technique is used to remove semantic ambiguity?",
      "definition": "Word Sense Disambiguation"
    },
    {
      "term": "56 :\nWhat is outcome thinking?\nKnowing what you want rather than what you don't want.\nKnow about others\nKnow about the society None\nlanguage",
      "definition": "Knowing what you want rather than what you don't want."
    },
    {
      "term": "57 : Identify the POS tag for the word \"nice\" in following sentence \"It was indeed a nice night\"?",
      "definition": "JJ"
    },
    {
      "term": "58 :\nWhat is the name for information sent from robot sensors to robot controllers?\nsignal\ntemperature\nfeedback\npressure",
      "definition": "---------"
    },
    {
      "term": "59 :\nTypically the first or preliminary model of something, especially from which other forms are developed; helps explain the meaning of certain words e.g. (furniture-->desk, table) is called as_________\nPrototype\nMetonymy\nHyponym\nHomonyms",
      "definition": "Prototype"
    },
    {
      "term": "60 :\nChoose form the following areas where NLP can be useful.\nAutomatic Text Summarization\nAutomatic Question-Answering Systems\nInformation Retrieval\nAutomatic Text Summarization & Automatic Question-Answering Systems & Information Retrieval",
      "definition": "Automatic Text Summarization & Automatic Question-Answering Systems & Information Retrieval"
    },
    {
      "term": "61 :\nGB theory dose not representation includes________-\ns-structure\nd-structure\nphonetic form.\nparsing",
      "definition": "phonetic form."
    },
    {
      "term": "62 :\nIn this technique, content is extracted from the original data,but the extracted content is not modified in any way\nExtraction-based summarization\nAbstraction-based summarization\nAided summarization\nKeyphrase extraction",
      "definition": "Extraction-based summarization"
    },
    {
      "term": "63 :\nWhich sentence describes inflectional morphology?\nAdding a morpheme to produce a new word but the same lexeme.\nAdding a morpheme to produce a new word and different lexeme.\nAdding a morpheme to produce the same word but different lexeme.\nAdding a morpheme to produce the same sentence but different lexeme.",
      "definition": "Adding a morpheme to produce a new word but the same lexeme."
    },
    {
      "term": "64 :\nWhat is function of Sequence classfier(HMM)?\nAssign some label or class to each unit in a sequence.\nAassign part of speech to sequence.\nFind probability\nCalculate likelihood.",
      "definition": "Find probability"
    },
    {
      "term": "65 :\n\"I Saw The Boy With A Pony Tail \", What Type Of Ambiguity Does Sentence Have\nSemantic Ambiguity\nPragmetic Ambiguity\nStructured Ambiguity\nSimplex",
      "definition": "Semantic Ambiguity"
    },
    {
      "term": "66 : \"You better go to the clinic\", is which type of speech act?",
      "definition": "Directives"
    },
    {
      "term": "67 :\nWhich of the following is not correct with respect to levels of semantic analysis?\nWord level\nCharacter level\nSentence level\nUtterance level",
      "definition": "Utterance level"
    },
    {
      "term": "68 :\nWhich Of The Below Are Nlp Use Cases?\nDetecting Objects From An Image\nFacial Recognition\nSpeech Biometric\nText Summarization",
      "definition": "Text Summarization"
    },
    {
      "term": "69 :\nSemantics: ___ meaning,Pragmatics: ___ meaning\nPresupposition\nLiteral; unconventional\nLinguistic context\nPhysical context",
      "definition": "Linguistic context"
    },
    {
      "term": "70 :\nGiven a sound clip of a person or people speaking, determine the textual representation of the speech.\nText-to-speech\nSpeech-to-text\nText Summarization\nText Classification",
      "definition": "Speech-to-text"
    },
    {
      "term": "71 : Named entity recognition is a technqiue to locate and classify __________ entities in unstructured text.",
      "definition": "Proper Nouns"
    },
    {
      "term": "72 :\nWhich of the factors affect the performance of learner system does not include?\nRepresentation scheme used\nTraining scenario\nType of feedback\nGood data structures",
      "definition": "---------"
    },
    {
      "term": "73 :\nWhich of the following is not a primitive operation of a regular expression?\nConcatenation\nClosure\nUnion\nProjection",
      "definition": "Projection"
    },
    {
      "term": "74 :\nChoose the correct answer to the following question: Which of the following words is an example of a preposition?\nInto\nIf\nMany\nYou",
      "definition": "Into"
    },
    {
      "term": "75 :\nPragmetics\nDisclosure\nSemantic\nLexemes",
      "definition": "Disclosure"
    },
    {
      "term": "76 :\n\"He was running quickly into the stadium\". What type of phrase is this?\nNoun phrase\nVerb phrase\nPrepositional phrase\nAdjectival phrase",
      "definition": "Verb phrase"
    },
    {
      "term": "77 :\nNouns, Verbs, Adjectives, Adverbs belong to ____ class type in POS\nJoin Class\nOpen Class\nSub Class\nClosed class",
      "definition": "Open Class"
    },
    {
      "term": "78 :\nWhat Was First Defined For Natural Language By Chomsky (1957)\nContext-Free Grammar (Cfg)\nFinite Automata (Fa)\nPush Down Automata (Pda)\nTuring Machine",
      "definition": "Context-Free Grammar (Cfg)"
    },
    {
      "term": "79 :\nTwo words with very closely related meanings\nAntonyms\nHomonyms\nSynonyms\nHyponymy",
      "definition": "Synonyms"
    },
    {
      "term": "80 :\nFollowing are examples of Artificial Languages except\nC\nEnglish\nPython\nScilab",
      "definition": "English"
    },
    {
      "term": "81 :\nHomophones for the word piece\nPeace\nConflict\nNoise\nIrritation",
      "definition": "Peace"
    },
    {
      "term": "82 :\nA set of words that denotes a subcategory of a more general class\nHyponymy\nMeronymy\nPolysemy\nClines",
      "definition": "Hyponymy"
    },
    {
      "term": "83 :\nIn a HMM, the possible state transitions are from state JJ to states NN, VB, JJ and RB. Following are the known state transitions probabilities; P(NN|JJ) = 1/4. P(VB|JJ) = 1/6, and P(JJ|JJ) = 1/3. What is the transition probability value of P(RB|JJ)?\n01-04-2020 12:00:00 AM\n01-02-2020 12:00:00 AM\n01-05-2020 12:00:00 AM\n01-03-2020 12:00:00 AM",
      "definition": "01-04-2020 12:00:00 AM"
    },
    {
      "term": "84 :\ntwo or more words with the same form and related meanings by extension (foot of a person, of a bed, of a mountain); based on similarity\nMetonymy\nhyponymy\npolysemy\nhyponym",
      "definition": "polysemy"
    },
    {
      "term": "85 :\nThe word bank can be (river bank or financial institution) it denotes\nAntonymy\nPolysemy\nHomonyms\nSynonymy",
      "definition": "Homonyms"
    },
    {
      "term": "86 :\nBeverage = coffee - tea - shake, is example of ______\nMeronymy\nHyponymy\nPolysemy\nClines",
      "definition": "Hyponymy"
    },
    {
      "term": "87 :\nWhat can words often be divided into?\nMorphemes\nLexemes\nParagraph\nStem",
      "definition": "Morphemes"
    },
    {
      "term": "88 :\nthe entity that is involved in or affected by the action, or that is simply being described (The boy kicked --> the ball.) (-->The ball was red.)\ndenotation\nsemantic features\nhomophones\ntheme (\"patient\")",
      "definition": "theme (\"patient\")"
    },
    {
      "term": "89 : \"I saw bats\" contains which type of ambiguity?",
      "definition": "Lexical"
    },
    {
      "term": "90 :\nWhat does 'discourse' refer to in the study of language?\nthe vocabulary of a text\nthe structure, organisation and layout of a text\nthe meaning behind the vocabulary of a text\nthe mode of a text",
      "definition": "the structure, organisation and layout of a text"
    },
    {
      "term": "91 :\nre.findall(r \"^\\d\", \" 3 is my favorite number\") What will the above regular expression do?\nWill ignore all integers in text\nWill search for digit at end\nWill search for digit at the beginning\nSearches for a pattern",
      "definition": "---------"
    },
    {
      "term": "92 :\nWhat is full form of NLU?\nNature Language Understanding\nNatural Long Understanding\nNatural Language Understanding\nNatural Language Understudy",
      "definition": "Natural Language Understanding"
    },
    {
      "term": "93 :\nWhich one of the following is type of spelling errors?\nSentence errors\nNon-word errors\nNon-cognitive errors\nSyntax errors",
      "definition": "Non-word errors"
    },
    {
      "term": "94 : ___ are created when the constituents within the sentence describe the role of the entities (We look at the NP in a sentence to see who/what is creating the action in the VP); found in each sentence",
      "definition": "Semantic Roles"
    },
    {
      "term": "95 :\nProgmatic Analysis Is the ________ Stage in NLP?\nFirst\nSecond\nFifth\nForth",
      "definition": "Forth"
    },
    {
      "term": "96 :\nNamed entities can be recognized and classified by:\nViterbi Algorithm\nFeatured-based or neural sequence labelling techniques.\nHidden Markov Model\nMaximum Likelihood Estimation",
      "definition": "Featured-based or neural sequence labelling techniques."
    },
    {
      "term": "97 :\n\"We always play football after work.\" Which is a prepositional phrase?\nAlways play football\nAfter work\nAlways play\nFootball after",
      "definition": "After work"
    },
    {
      "term": "98 :\nFeatures that are used to represent the abstract letter pattern of the word by mapping lower-case letters to 'x', upper-case to 'X', numbers to 'd', and retaining punctuation are called as: (For example I.M.F would map to X.X.X. and DC10-30 would map to XXdd-dd)\nAcronym\nX-maps\nWord Shape\nWord Mapper",
      "definition": "Word Shape"
    },
    {
      "term": "99 :\n\"He finished the show very well\". What is part of speech of underlined word?\nNoun\nAdjective\nAdverb\nPreposition",
      "definition": "Adverb\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 3 ---"
    },
    {
      "term": "100 :\nthe entity that performs the action; can be human or non-human (-->The boy kicked the ball.)\nagent\nsource\ninstrument\nhyponym",
      "definition": "agent"
    },
    {
      "term": "101 : How is the word \"change\" stemmed using Porter Stemmer?",
      "definition": "chang"
    },
    {
      "term": "102 : The words \"bank/data bank/blood bank\" is an example of -----------",
      "definition": "Polysemy"
    },
    {
      "term": "103 :\n\"He lifted the beetle with red cap.\" contain which type of ambiguity ?\nLexical ambiguity\nSyntax Level ambiguity\nReferential ambiguity\nSentiment analysis",
      "definition": "Syntax Level ambiguity"
    },
    {
      "term": "104 :\nGenerating natural, conversational language that explains complex concepts in a way that is easy to consume.\nIntuitive\nRelevant\nTimely\nSpace",
      "definition": "Intuitive"
    },
    {
      "term": "105 :\nThe metric to measure \"the degree of control exerted by the stimulus\" in emotion modeling is:\nControllability\nValence\nArousal\nDominance",
      "definition": "---------"
    },
    {
      "term": "106 :\nIn a relation between the entities the type and condition of the relation should be specified. That is called as______attribute.\nDesciptive\nDerived\nRecursive\nRelative",
      "definition": "Desciptive"
    },
    {
      "term": "107 :\nFollowing are the basic regular expression patterns, which one is incorrect pattern?\nDisjunction\nCaret\nRanges\nConjunction",
      "definition": "Conjunction"
    },
    {
      "term": "108 :\nChoose from the following areas where NLP can be useful.\nAutomatic Text Summarization\nAutomatic Question-Answering Systems\nInformation Retrieval\nAll of the above",
      "definition": "All of the above"
    },
    {
      "term": "109 :\nWhich is not type of Sentiment Analysis?\nEmotion Detection\nAspect based\nWord based\nBilingual",
      "definition": "Word based"
    },
    {
      "term": "110 :\nNatural language understanding is used in:\nnatural language interfaces\nnatural language front ends\ntext understanding systems\nAll of the mentioned",
      "definition": "All of the mentioned"
    },
    {
      "term": "111 :\nParaphrase detection does not much contributes to which NLP task\nText summarization\nDocument Clustering\nSpech Recognition",
      "definition": "Answering"
    },
    {
      "term": "112 :\nFor machine learning based tagger, which is required\nKnowledge database of rules required\nKnowledge database of rules not required\nLearns automatically all rules\nKnowledge database of rule, learning from database",
      "definition": "Spech Recognition"
    },
    {
      "term": "113 :\nAutomatic document classification doesn't techniques include\nK-nearest neighbour algorithms\nSupport vector machines (SVM)\nPredicate Logic\nNaive Bayes classifier",
      "definition": "Knowledge database of rule, learning from database"
    },
    {
      "term": "114 :\nThe choice between two ______________ is generally associated with some notion of spatial proximity.\ninferrables\ndemonstratives\ngenerics\nnoun phrase",
      "definition": "Predicate Logic"
    },
    {
      "term": "115 :\nHMM are designed to model the joint distribution P(H , O) , where H is the _____state and O is the ________ state\nHidden, Observed\nUnobservable, Hidden\nClassified, Completed\nOpen, Completed",
      "definition": "---------"
    },
    {
      "term": "116 :\n\"I Bought A Printer Today. The Printer Didn'T Work Properly.\" What Type Of Reference In The Discourse Context Is Done In This Statement?\nDefinite Refernce\nIndefinite Reference\nPronominal Refenece\nDemonstrative Reference",
      "definition": "Hidden, Observed"
    },
    {
      "term": "117 :\nWhich of the following dosen't require application of natural language processing algorithm\nClassifing spam emails from good ones\nclassifing image of scanned document as handwritten\nAutomatically generating captions for images\nbuilding a sentiment analyzer for tweets on twitter",
      "definition": "Definite Refernce"
    },
    {
      "term": "118 :\nMorphological Segmentation?\nDoes Discourse Analysis\nSeparate words into individual morphemes and identify the class of the morphemes\nIs an extension of propositional logic\nAnalysis",
      "definition": "Classifing spam emails from good ones"
    },
    {
      "term": "119 :\nCohesion : Textual Phenomenon : : Coherence : ?\nTextual Phenomenon\nMental Phenomenon\nPhysical Phenomenon\nNo Phenomenon",
      "definition": "Separate words into individual morphemes and identify the class of the morphemes"
    },
    {
      "term": "120 :\nWhen we encounter two or more words with the same form and related meanings, we have what is known as ______\nHyponymy\nPolysemy\nHomonyms\nSource",
      "definition": "Mental Phenomenon"
    },
    {
      "term": "121 :\nRegular expressions are combination of simple units as given in options, select incorrect unit.\nCharacter or string\nConcatenation\nKleen star\nConjunction",
      "definition": "Polysemy"
    },
    {
      "term": "122 :\nBeverage = coffee - tea - shake, is example of ______\nMeronymy\nHyponymy\nPolysemy\nClines",
      "definition": "Conjunction"
    },
    {
      "term": "123 :\nThe Words \"Window\" And \"Room\" Are In A Lexical Semantic Relation\nHypernym - Hyponym\nHypernym - Meronym\nHolonym - Hyponym\nMeronym - Holonym",
      "definition": "Hyponymy"
    },
    {
      "term": "124 :\nHistory of Natural Language Processing does not include\nAutomata Theory\nCompression Algorithms\nCFG by Chomsky\nPredicate and First Order Logic",
      "definition": "Meronym - Holonym"
    },
    {
      "term": "125 :\n\"He lifted the beetle with red cap.\" contain which type of ambiguity?\nLexical ambiguity\nSyntax Level ambiguity\nReferential ambiguity\nSemantic Ambiguity",
      "definition": "Compression Algorithms"
    },
    {
      "term": "126 :\n\"He doesn't know\" is an example of __________ _type of deixis\nPersonal\nTime\nSocial\nSpace",
      "definition": "Syntax Level ambiguity"
    },
    {
      "term": "127 : Singular: Fish, Plural : Fish. Singular: Goose, Plural : Geese. Which rules are applied",
      "definition": "NLP rules"
    },
    {
      "term": "128 :\nTyping buckled when you meant bucked is a type of which Spelling error\nNon-word Errors\nReal Word Errors\nCognitive Errors\nShort forms/Slang/Lingo",
      "definition": "Morphological rule"
    },
    {
      "term": "129 :\nWhich Application Of Nlp Is Concerned With Intendifing Documents Relevant To A User'S Query?\nSpeech Recognition\nNatural Language Interfaces To Db\nInformation Extraction\nInformation Retrieval",
      "definition": "Real Word Errors"
    },
    {
      "term": "130 :\nConditional random fields (CRFs) are a class of statistical modeling method often applied in\nMorphology\nSyntactic Analysis\nPattern recognition and machine learning\nDiscourse -reference resolution",
      "definition": "Information Retrieval"
    },
    {
      "term": "131 :\nWhere did the first recognisable NLP application developed ?\nAt Birkbeck College, London\nAt IBM Research.\nAt Thomas College , Newyork\nAt the University of America",
      "definition": "Pattern recognition and machine learning"
    },
    {
      "term": "132 :\nAssume a corpus with 350 tokens in it. We have 20 word types in that corpus (V = 20). The frequency (unigram count) of word types \"short\" and \"fork\" are 25 and 15 respectively. Which of the following is the probability of \"short\" (PMLE(\"short\"))?\n25/350\n26/370\n26/350\n25/370",
      "definition": "At Birkbeck College, London"
    },
    {
      "term": "133 :\nDifferent learning methods does not include?\nMemorization\nAnalogy\nDeduction\nIntroduction",
      "definition": "25/350"
    },
    {
      "term": "134 :\nA bottom up parser generates\nRight most derivation\nRightmost derivation in reverse\nLeftmost derivation\nLeftmost derivation in reverse",
      "definition": "Introduction"
    },
    {
      "term": "135 :\nThe stem is not necessarily the linguistic root of the word.\nTrue\nFalse\nCan't say\nRandom and unpredictable",
      "definition": "Rightmost derivation in reverse"
    },
    {
      "term": "136 :\nCorrect rule to write noun phrase for the sentence \"The foggy morning\"\nNP - (Det) (AP)Nom(PP)\nNP - Det Noun\nNP - Adj Noun\nNP - Pronoun",
      "definition": "True"
    },
    {
      "term": "137 :\nHow Many Different Lexemes Are There In The Following List?Man, Men, Girls , Girl , Mouse\n2\n3\n1\n4",
      "definition": "---------"
    },
    {
      "term": "138 :\nWhich data is used to use supervised approach for Machine translation\nPlain text\nLabelled text\nDictionary\nVectors",
      "definition": "3"
    },
    {
      "term": "139 :\nHow many uni-grams phrases can be generated from the following sentence, after performing following text cleaning steps: Stop word Removal and Replacing punctuations by a single space i. \"Delhi is the capital of but Mumbai is the financial capital of India.\"\n8\n7\n6\n5",
      "definition": "Labelled text"
    },
    {
      "term": "140 :\nWhat are the input and output of an NLP system?\nSpeech and noise\nSpeech and Written Text\nNoise and Written Text\nNoise and value",
      "definition": "5"
    },
    {
      "term": "141 :\nWhich Algorithm Is Used For Solving Temporal Probabilistic Reasoning?\nHidden Markov Model\nBreadth-First Search\nHill-Climbing Search\nDepth-First Search",
      "definition": "Speech and Written Text"
    },
    {
      "term": "142 :\nWhich of these techniques is used for normalization in text mining?\nRooting\nStop words removal\nRemoving stopwords\nText wrapping",
      "definition": "Hidden Markov Model"
    },
    {
      "term": "143 :\n\"Tubers\" is a hyponym of ____\nPotatoes\nCarrots\nRoots\nVegetables",
      "definition": "---------"
    },
    {
      "term": "144 :\nWhich is NOT a conjunction?\nBut\nand\nor\nthat",
      "definition": "Potatoes"
    },
    {
      "term": "145 : What Will Be The Perplexity Value If You Calculate The Perplexity Of An Unsmoothed Language Model On A Test Corpus With Unseen Words?",
      "definition": "Inefficient"
    },
    {
      "term": "146 :\nWhich of the following is the smallest unit within a language system?\nPhoneme\nSyntax\nMorpheme\nSentence",
      "definition": "Infinity"
    },
    {
      "term": "147 :\nIn The Sentence, \"They Bought A Blue House\", The Underlined Part Is An Example Of _____.\nNoun Phrase\nVerb Phrase\nPrepositional Phrase\nAdverbial Phrase",
      "definition": "Phoneme"
    },
    {
      "term": "148 :\nWhat is the right order for a text classification model components 1. Text cleaning 2. Text annotation 3. Gradient descent 4. Model tuning 5. Text to predictors\n12345\n13425\n12534\n13452",
      "definition": "Noun Phrase"
    },
    {
      "term": "149 : _______ of a transducer is useful because it makes it easy to convert a FST-as-parser into an FST-as-generator.",
      "definition": "composition"
    },
    {
      "term": "150 :\nWhich of the following includes major tasks of NLP?\nAutomatic Summarization\nDiscourse Analysis\nMachine Translation\nAutomatic Summarization & Discourse Analysis & Machine Translation",
      "definition": "inversion"
    },
    {
      "term": "Automatic Summarization & Discourse Analysis & Machine Translation\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 4 ---",
      "definition": "151 :\nA web page whose content doesn't vary from one request to another is called a:\nText Page\nDynamic Page\nActive Server Page\nStatic Page"
    },
    {
      "term": "152 :\nWhich of the following is an advantage of normalizing a word?\nIt guarantees word to be inconsistent\nIt helps in reducing the randomness in the word\nIt increases the false negatives\nIt increases the dimensionality of the input",
      "definition": "---------"
    },
    {
      "term": "153 :\nClosed classes of POS are those with relatively fixed membership\nYes\nNo\nCannot Say\nMay be yes",
      "definition": "It helps in reducing the randomness in the word"
    },
    {
      "term": "154 :\nStop words are-\nwords that frequently found in a document\nlong sound words\nwords that are not important for text wrapping\nCreating a set repeting words",
      "definition": "Yes"
    },
    {
      "term": "155 :\nElements of Semantic analysis\nHyponymy\nHomonymy\nPolysemy\nHyponymy, Homonymy, Polysemy",
      "definition": "words that frequently found in a document"
    },
    {
      "term": "156 :\nConsider the following given sentences. Match the lexical relations between the first word (w​1​) to the second word (w​2​) i.e. w​1​ is a of w​2. Invention of the wheel​ is one of the landmarks in the history of mankind. Companies are trying to make driverless car. Golden daffodils​ are fluttering and dancing in the breeze. Mumbai has unique flower ​park. 1. Holonym --> i.wheel-car 2. Hyponym --> ii. car-wheel 3. Meryonym --> iii. daffodils-flower 4. Hypernym --> iv. flower- daffodils\n1-iii, 2-ii, 3-iv, 4-i\n1-ii, 2-iii, 3-i, 4-iv\n1-ii, 2-iii, 3-iv, 4-i\n1-i, 2-ii, 3-iii, 4-iv",
      "definition": "Hyponymy, Homonymy, Polysemy"
    },
    {
      "term": "157 :",
      "definition": "A word that is quite hard to spell"
    },
    {
      "term": "158 :\n1.\"The Tank Was Full Of Water.\". \"I Saw The Military Tank\".Here Tank Is Used In Different Context, Which Type Of Ambiguity Is This?\nSemantic Ambiguity\nSyntactic Ambiguity\nAnaphoric Ambiguity\nSyntactical Ambiguity",
      "definition": "Words that are context bound where meaning depends on who is being referred to, where something is happening or when something is happening."
    },
    {
      "term": "159 :\nHMM model formula is combination of\nN gram and Naive bayes\nLogistic regression\nSVM\nEuclidean distance between words",
      "definition": "Semantic Ambiguity"
    },
    {
      "term": "160 : ___________technique looks at the meaning of the word.",
      "definition": "ERROR: Cannot find option SVM"
    },
    {
      "term": "161 : \" I appoint you chairman of the committee\" is which type of speech act?",
      "definition": "Directives"
    },
    {
      "term": "162 : Software designed for taking i/p data(text) and give structural representation of the input after checking the correct syntax or grammar is",
      "definition": "Painter"
    },
    {
      "term": "163 :\nWhich of the following is a example of irregular noun form?\nFox\nDog\nMouse\nCat",
      "definition": "Parser"
    },
    {
      "term": "164 :\nFunction morphemes are also called ______\nopen-class morphemes\nsub-class morphemes\nsuper-class morphemes\nclosed-class morphemes",
      "definition": "Mouse"
    },
    {
      "term": "165 :\nWhich statement is true\nRule based methods are language independent\nStochastic methods are language independent\nIt is highly complex task to resolve ambiguities especially at lower levels of NLP\nDisambiguation task are is more challenging in Resourceful language as compared to Resourceless language",
      "definition": "closed-class morphemes"
    },
    {
      "term": "166 :\nFor HMM Model, with N hidden states, V observable states, what is the dimension of State Transition Probability Matrix\nN×V\nN×1\nN×N\n1For HMM Model, with N hidden states, V observable states, what is the dimension of Emission Probability ×N",
      "definition": "Stochastic methods are language independent"
    },
    {
      "term": "167 :\nWhen a referent is first mentioned in a discourse, we say that a representation for it is __________ into the model.\ncreated\nevoked\naccessed\ninitiated",
      "definition": "N×N"
    },
    {
      "term": "168 :\nWhich one of the following is not a pre-processing technique in NLP\nStemming and Lemmatization\nSentiment analysis\nRemoval of stop words\nConverting to lowercase",
      "definition": "---------"
    },
    {
      "term": "169 :\nMini-Corpus given, I am Sam Sam I am I do not like green eggs and ham What will be bigram probability of P(am | I)?\n0.67\n0.33\n0.5\n0.25",
      "definition": "Sentiment analysis"
    },
    {
      "term": "170 :\nIn Sentiment analysis\nList the topics that a document deals with\nAssess the emotional content of a document\nCompress a document as much as possible without losing meaning, producing another document\nGiven a question in natural language, provide an appropriate answer in natural language",
      "definition": "67"
    },
    {
      "term": "171 :\nDog is hyponym of\nForest\nHuman\nAnimal\nAutomobile",
      "definition": "Assess the emotional content of a document"
    },
    {
      "term": "172 :\nIn NLP, The algorithm decreases the weight for commonly used words and increases the weight for words that are not used very much in a collection of documents\nTerm Frequency (TF)\nInverse Document Frequency (IDF)\nWord2Vec\nLatent Dirichlet Allocation (LDA)",
      "definition": "Animal"
    },
    {
      "term": "173 :\nWhich application use to determine people in context?\nStemming\nLemmatization\nStop word removal\nNamed entity recognition",
      "definition": "---------"
    },
    {
      "term": "174 :\nThe original Brown tagset uses two of the most commonly used tagsets are__________ & _____________.\n50-tag Penn Treebank tagset, the medium-sized 70 tag C5 tagset\nMedium 10-tag Penn Treebank tagset, the medium-sized 21 tag C5 tagset\nSmall 45-tag Penn Treebank tagset, the medium-sized 61 tag C5 tagset\nMedium 87-tag Penn Treebank tagset, the 45 medium-sized 21 tag C5 tagset",
      "definition": "ERROR: No options for answer d"
    },
    {
      "term": "175 :\nTf-Idf Helps You To Establish?\nMost Frequently Occurring Word In The Document\nMost Important Word In The Document\nMost Important Sentence In The Document\nMost Frequently Occurring Sentence In The Document",
      "definition": "Small 45-tag Penn Treebank tagset, the medium-sized 61 tag C5 tagset"
    },
    {
      "term": "176 :\nWhich of the following techniques is most appropriate to the process of word normalization\nStemming\nLemmatization\nStop word removal\nRooting",
      "definition": "Most Important Word In The Document"
    },
    {
      "term": "177 :\nTo evaluate the effectiveness of an IR system the output from a standard query executed against the test IR system is compared with the known output from a:\ninternet collection\nreference book\nseparate IR system.\nstandard test collection",
      "definition": "Stemming"
    },
    {
      "term": "178 :\nGet (to take) - get (to become), is example of ______\nSynonym\nHyponym\nHomonym\nPolysemy",
      "definition": "standard test collection"
    },
    {
      "term": "179 :\nIdentify the artificial language\nJava\nMaori\nKazakh\nZulu",
      "definition": "Homonym"
    },
    {
      "term": "180 :\n..............ambiguity refers to a situation where the context of a phrase gives it multiple interpretation\nPragmatic\nAnaphoric\nDiscourse\nCataphoric",
      "definition": "Java"
    },
    {
      "term": "181 :",
      "definition": "Morphological Segmentation _______________"
    },
    {
      "term": "182 :\nThe statement \" eat a pizza\" can be represented as\nNP → Verb VP\nVP → Verb PP\nVP → Verb NP\nVP → Verb NP PP",
      "definition": "Separate words into individual morphemes and identify the class of the morphemes"
    },
    {
      "term": "183 :\ne.g. 'do', 'eat', 'go' are examples of which type of verb\nRegular verb\nIrregular verb\nComplex verb\nNormal verb",
      "definition": "VP → Verb NP"
    },
    {
      "term": "184 :\nWhat Can Be Called As \"The Knowledge Of What Has Been Said Earlier\"\nSituational Context\nBackground Knowledge\nCo-Textual Context\nOperational Knowledge",
      "definition": "Irregular verb"
    },
    {
      "term": "185 :\nWhich of the following is not true input for the NLP?\nImage\nText\nTypes input\nSpeech",
      "definition": "Co-Textual Context"
    },
    {
      "term": "186 :\nWhich Of The Following Is An Nlp Task That Involves Determining All Referring Expressions That Point To The Same Real-World Entity?\nCoreference Resolution\nNamed Entity Recognition\nInformation Extraction\nStop Word",
      "definition": "Image"
    },
    {
      "term": "187 :\nClock = digital - analog - alarm\nPolysemy\nMeronymy\nHyponymy\nCline",
      "definition": "Coreference Resolution"
    },
    {
      "term": "188 :\nHow many bi-grams can be generated from given sentence:- \"This is NLP book.\"?\n3\n2\n4\n1",
      "definition": "Hyponymy"
    },
    {
      "term": "189 : ________________ extracts all the documents containing the key words",
      "definition": "Information Extraction"
    },
    {
      "term": "190 :\nNLP Stands for.\nNatural Language Protocol\nNatural Lingual Protocol\nNatural Lingual Processing\nNatural Language Processing",
      "definition": "Information Retrieval"
    },
    {
      "term": "191 :\nTwo words are there with different spelling but sound is same wring(1) and wring(2). First one means to twist something and second one means you wear in your finger. This is an example of\nHomonymy\nHyponymy\nPolysemy\nHomophony",
      "definition": "Natural Language Processing"
    },
    {
      "term": "192 :\nMango is hyponym of\nForest\nHuman\nFruits\nSweet",
      "definition": "Homonymy"
    },
    {
      "term": "193 :\nWhich of the following component of NLP?\nPragmatic analysis\nEntity extraction\nSyntactic analysis\nPragmatic analysis & Entity extraction & Syntactic analysis",
      "definition": "Fruits"
    },
    {
      "term": "194 :\nToken and morpheme are always same.\nYes\nNO\nProbability based\nRandomization based",
      "definition": "Pragmatic analysis & Entity extraction & Syntactic analysis"
    },
    {
      "term": "195 :\nWhere the additional variables does are added in HMM?\na)Temporal model\nb)Reality model\nc)Probability model\nd)In all three models, temporal, reality and probability model",
      "definition": "---------"
    },
    {
      "term": "196 :\n___: How we put words together,___ : word meanings, ___ : speaker meaning\nSyntax,semantics,pragmatics\nSemantics,syntax,pragmatics\nSemantics,syntax,pragmatics\nSocial; academic, semantic",
      "definition": "a)Temporal model"
    },
    {
      "term": "197 :\nInferrables, discontinuos sets and ______ are the three types of referents that complicate the reference resolution problem.\nIndefinite Noun phrases\ndemonstratives\none anaphora\ngenerics",
      "definition": "Syntax,semantics,pragmatics"
    },
    {
      "term": "198 :\nSyntactic analysis or parsing may be defined as the process of ________ the _______ of symbols in Natural language conforming to the rules of formal grammar.\nAnalyzing & Strings\nDefining & Groups\nReducing & Arrays\nReviewing & Letters",
      "definition": "---------"
    },
    {
      "term": "199 :\nCorpus-Based Approaches Use Either Supervised Or Unsupervised Learning. Supervised Methods Require ___________ Whereas Unsupervised Methods Eliminate The Need Of Tagged Data But Usually Perform Only _________________.\nTagged Data, Word Sense Discrimination\nUntagged Data, Word Sense Discrimination\nUntagged Data, Word Commonsense Discrimination\nUntagged Data, Word Sense Indiscrimination",
      "definition": "Analyzing & Strings"
    },
    {
      "term": "200 :\nIn the English language inflectional morphemes can be...\nPrefixes, Suffixes and Infixes\nSuffixes only\nInfixes Only\nPrefixes, Suffixes and Infixes",
      "definition": "Tagged Data, Word Sense Discrimination"
    },
    {
      "term": "Suffixes only\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 5 ---",
      "definition": "201 :\nIn The English Language Inflectional Morphemes Can Be Which Of Following\nSuffixes Only\nPrefix Only\nPrefix And Suffix\nAny Word"
    },
    {
      "term": "202 :\nRule-based POS taggers doesnt possess which of the following properties\nThe rules in Rule-based POS tagging are built auto\nThese taggers are knowledge-driven taggers\nThese taggers are consist of many hand written rules\nThe information is coded in the form of rules.",
      "definition": "Suffixes Only"
    },
    {
      "term": "203 :\nSyntactical analysis is done at ______________ level\nSentence\nWord\nLexicon\nSymbol",
      "definition": "The rules in Rule-based POS tagging are built auto"
    },
    {
      "term": "204 :\nIt is not word embedding library\nWord2vec\nGlove\nFasttext\nTextBlog",
      "definition": "Sentence"
    },
    {
      "term": "205 :\nIn NLP, The process of removing words like \"and\", \"is\", \"a\", \"an\", \"the\" from a sentence is called as\nStemming\nLemmatization\nStop word\nderivation",
      "definition": "TextBlog"
    },
    {
      "term": "206 :\nWhat Is Machine Translation?\nAtomatic Translation Of Text From One Language To Another\nManual Translation Of Text From One Language To Another\nInformation Retrival\nData Mining",
      "definition": "Stop word"
    },
    {
      "term": "207 :\nWhich of the following is used to mapping sentence plan into sentence structure?\nText planning\nSentence planning\nText Realization\nText Summarization",
      "definition": "Atomatic Translation Of Text From One Language To Another"
    },
    {
      "term": "208 :\nInflectional morphology have the scope of__________________\nunlimited applicability\npossibly literal\nno communicability\nmore base allomorph",
      "definition": "Text Realization"
    },
    {
      "term": "209 :\n____ concerns how the immediately preceding sentences affect the interpretation of the next sentence\nPragmatics\nSyntax\nDiscourse\nSemantics",
      "definition": "---------"
    },
    {
      "term": "210 :\nFamous Stemming algorithm\nPorter's Stemmer algorithm\nLovins Stemmer\nDawson Stemmer\nSnowball Stemmer:",
      "definition": "Discourse"
    },
    {
      "term": "211 :\n\"Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo\" Identify the ambiguity\nLexical Ambiguity\nAnaphoric Ambiguity\nSyntax Ambiguity\nSemantic Ambiguity",
      "definition": "Porter's Stemmer algorithm"
    },
    {
      "term": "212 :\nWhat is 'indefinite noun phrases' in reference phonomena?\nIntroduces entities that are new to the hearer into the discourse context\nIntroduces entities that are previous or old to the hearer into the discourse context\nEntities that accept the irregular pharses\nEntities that accept the regular pharses",
      "definition": "Lexical Ambiguity"
    },
    {
      "term": "213 :\n______ morphology is a type of word formation that creates new lexemes\nDerivational morphology\nCompound morphology\nInflectional morphology\nComplex morphology",
      "definition": "Introduces entities that are new to the hearer into the discourse context"
    },
    {
      "term": "214 :\nWhich one of the following is morpheme of the word \"unbelievable\"?\nun\nunbe\nevable\nable",
      "definition": "Derivational morphology"
    },
    {
      "term": "215 :\nWhat is morphology?\nThe study of the rules governing the sounds that form words\nThe study of the rules governing sentence formation\nThe study of the rules governing word formation\nThe study of the rules governing sounds",
      "definition": "un"
    },
    {
      "term": "216 :\nWhich is a finite state machine with two tapes: an input tape and an output tape\nFinite State Transducers (FSTs)\nFinite State Translators (FSTs)\nFinite Automata\nDeterministic Finite Automaton",
      "definition": "The study of the rules governing word formation"
    },
    {
      "term": "217 :\n\"I Bought A Printer Today. I Had Bought One Earlier In004. This One Cost Me Rs. 6000 Whereas That One Cost Me Rs.2000.\" In This Statement, \"This\" And \"That\" Are Known As Which Type Of Reference In The Discourse Context?\nDefinite Refernce\nIndefinite Reference\nPronominal Refenece\nDemonstrative Reference",
      "definition": "Finite State Transducers (FSTs)"
    },
    {
      "term": "218 :\nA Bidirectional Feedback Loop Links Computer Modelling With:\nArtificial Science\nHeuristic Processing\nHuman Intelligence\nCognitive Science",
      "definition": "Demonstrative Reference"
    },
    {
      "term": "219 :\nParts-of-Speech tagging determines ___________ . 1) part-of-speech for each word dynamically as per meaning of the sentence 2) part-of-speech for each word dynamically as per sentence structure 3) all part-of-speech for a specific word given as input\nOnly 1 is correct\n1 and 2 are correct\n1 and 3 are correct\nAll (1,2 and 3) are correct.",
      "definition": "Cognitive Science"
    },
    {
      "term": "220 :\nConsider the statement \" The students went to class\" . Assign POS tags for the statement.\nDT NN VB P NN\nDT NN NN P NN\nNN NN VBG P NN\nDT NN VB P DT",
      "definition": "All (1,2 and 3) are correct."
    },
    {
      "term": "221 : Video summarization extracts the most important frames from the _____ content",
      "definition": "Video"
    },
    {
      "term": "222 :\nPorter Stemmer algorithm consists of how many steps\n4\n3\n5\n6",
      "definition": "Video"
    },
    {
      "term": "223 :\nWhich Of The Following Model Is Used For Speech Recognition?\nLemmatization Model\nHidden Markov Model\nFinite State Transducers Model\nGrammer Model",
      "definition": "5"
    },
    {
      "term": "224 :\nA program that captures and indexes content from web pages is known as what insect:\nFly\nCentipede\nMosquito\nSpider",
      "definition": "Hidden Markov Model"
    },
    {
      "term": "225 :\nThe branches of linguistics that focus on the meaning of a language\nSemantics & phonology\nSemantics & pragmatics\nMorphology & pragmatics\nPragmatics & phonology",
      "definition": "---------"
    },
    {
      "term": "226 :\nParts-of-Speech tagging Does not determine ___________\npart-of-speech for each word dynamically as per meaning of the sentence\npart-of-speech for each word dynamically as per sentence structure\nall part-of-speech for a specific word given as input\nall part-of-speech for a specific stem from input",
      "definition": "Semantics & pragmatics"
    },
    {
      "term": "227 :\nTo whether \"duck\" is a verb or a noun can be solved by ______\nPart-of-speech tagging.\nLexical analysis\nSemantic analysis\nPragmatic analysis",
      "definition": "all part-of-speech for a specific stem from input"
    },
    {
      "term": "228 :\nA frequently used statistical model in nlp\nStochestic\nHybrid\nHMM\nLengustic",
      "definition": "Part-of-speech tagging."
    },
    {
      "term": "229 : _____is a phrase whose head is a noun or a pronoun, optionally accompanied by a set of modifiers.",
      "definition": "ERROR: Cannot find option HMM"
    },
    {
      "term": "230 :\nWhich Among The Following Is Important Component Of Natural Language Processig?\nRepresentation\nDescription\nExposion\nNarration",
      "definition": "Noun Phrase"
    },
    {
      "term": "231 :\nessential to the study of language acquisition; important for understanding language in social contexts (varieties of English, effects on style)\nsemantics\nlocation\nSemantic roles\nhomonyms",
      "definition": "Representation"
    },
    {
      "term": "232 :\nDivide the word \"truthfulness\" into base form + morphemes will give the output as\ntruthful-ness\ntruth-ful-ness\ntruth-fulness\ntruthfulness",
      "definition": "semantics"
    },
    {
      "term": "233 :\n_________________is mapping sentence plan into sentence structure.\nText planning\nSentence Planning\nText Realisation\nText Mapping",
      "definition": "truth-ful-ness"
    },
    {
      "term": "234 :\nThe reference to an entity that has been previously introduced into the sentence is called as __________ .\ndiscourse\nanaphora\nco refer\nreferent",
      "definition": "Text Realisation"
    },
    {
      "term": "235 :\nWhat is Global coherence?\nIt is how each sentence relates to the previous sentence.\nIt is how each sentence relates to the topic\nIt is how each sentence not relates to the topic\nIt is how each sentence not relates to the previous sentence.",
      "definition": "anaphora"
    },
    {
      "term": "236 :\nWhich of the following techniques is most appropriate to get root of word without considering word syntax\nStemming\nLemmatization\nStop word removal\nRooting",
      "definition": "---------"
    },
    {
      "term": "237 :\n_________are based on the analysis of large volumes of bilingual text\nRules Based Machine Translation\nStatistical MachineTransaltion\nHybrid Machine Translation\nNeural Machine Translation.",
      "definition": "Lemmatization"
    },
    {
      "term": "238 :\nSyntax Analyser is also known as __________________.\nHierarchical Analysis\nSequential Analysis\nGeneral Analysis\nHierarchical Analysis and Parsing",
      "definition": "Statistical MachineTransaltion"
    },
    {
      "term": "239 : _________ Is the Second Stage in NLP?",
      "definition": "Pragmatic Analysis"
    },
    {
      "term": "240 :\nWhich one of the following is TRUE about CRF (Conditional Random Field) and HMM (Hidden Markov Model)?\nCRF is generative model and HMM is discriminative model\nBoth CRF and HMM are generative model\nCRF is discriminative model and HMM is generative model\nBoth CRF and HMM are discriminative model",
      "definition": "Syntactic Analysis"
    },
    {
      "term": "241 :\n______has the same spelling and sound, but do not have related meanings\nHomophones\nPolysemy\nHomonymy\nSynonymy",
      "definition": "CRF is discriminative model and HMM is generative model"
    },
    {
      "term": "242 :\nUsing pronouns to refer back entities already introduced in the text is called as ________problem .\nAnaphora\nMisspellings\nMultiple Meaning\nLexical problem",
      "definition": "Homonymy"
    },
    {
      "term": "243 : Discourse Analysis Involves The Study Of Relationship Between?",
      "definition": "Programming Language And Contextual Foreground"
    },
    {
      "term": "244 :\nWhat is anaphora?\nrepetition of a phrase at the end of sentences\nrepetition of a phrase at the beginning of sentences\nrepetition of a phrase in the middle of sentences\nrepetition of a phrase in a direct row",
      "definition": "Language And Contextual Background"
    },
    {
      "term": "245 :\nWords with just one free morpheme are\nSimple words\nComplex words\nJoint Words\nCompound words",
      "definition": "repetition of a phrase at the beginning of sentences"
    },
    {
      "term": "246 :\nwhat a speaker (or writer) assumes is true or known by a listener (or reader)\npresupposition\nspatial deixis\nsupposition\nPragmatics",
      "definition": "Simple words"
    },
    {
      "term": "247 :\nWhich of the following are Anchors in regular expression?\n* and +\n^ and $\n? and {}\n\\d and \\w",
      "definition": "presupposition"
    },
    {
      "term": "248 :\nWhich of the following grammars generates strings with any number of 1's?\nS --> 1A, A --> ε\nS -->1S, S--> ε\nS -->S1, S--> ε\nS -->1SA, S--> ε",
      "definition": "^ and $"
    },
    {
      "term": "249 :\nPhrase structure riles are of the form A->BC which states that\nA is directed towards BC\nA implies B and C\nConstituents A can be written as two constitutes B and C\nBC holds value of A",
      "definition": "S -->1S, S--> ε"
    },
    {
      "term": "250 :\n________________ used to point to things (it, this, these) and people (him, them, those idiots).\nSpatial deixis\nPragmatics\nTemporal deixis\nPersonal deixis",
      "definition": "Constituents A can be written as two constitutes B and C"
    },
    {
      "term": "d\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 6 ---",
      "definition": "251 :\nThe linker\nIs similar to interpreter\nUses source code as its input\nI s required to create a load module\nNone of the mentioned"
    },
    {
      "term": "252 :\nWhich Of The Following Architecture Can Be Trained Faster And Needs Less Amount Of Training Data\nLstm Based Language Modelling\nTransformer Architecture\nWord Sense Disambiguation\nN-Grams",
      "definition": "I s required to create a load module"
    },
    {
      "term": "253 :\n_______ Is used to decode the optimal tag sequence\nEarly algorithm\nViterbi algorithm\nLexk algorithm\nA centering algorithm",
      "definition": "Transformer Architecture"
    },
    {
      "term": "254 :\nSolve the equation according to the sentence \"I am planning to visit New York to attend International Film Fare Festival\". A = (# of words with Noun as the part of speech tag) B = (# of words with Verb as the part of speech tag) C = (# of words with frequency count greater than one) What are the correct values of A, B, and C?\n5, 5, 2002\n5, 5, 2002\n7, 5, 2001\n7, 4, 2001",
      "definition": "Viterbi algorithm"
    },
    {
      "term": "255 :\nWhat is transformation based learning?\nA machine learning technique,in which rules are automatically induced from the data.\nA machine learning technique,in which rules are manually induced from the data.\nA machine learning technique,in which rules are transformed into another data.\nA machine learning technique,in which rules are not used.",
      "definition": "ERROR: No options for answer d"
    },
    {
      "term": "256 :\nSelect the correct statements related to \"Grammatical polarity\"\nThe grammatical category associated with affirmative and negative is called polarity\nThe process of converting affirmative to negative is called negation\nAll of the mentioned\nNone of the mentioned",
      "definition": "A machine learning technique,in which rules are automatically induced from the data."
    },
    {
      "term": "257 :\nWhat Is The Name For Information Sent From Robot Sensors To Robot Controllers?\nTemperature\nPressure\nFeedback\nSignal",
      "definition": "The grammatical category associated with affirmative and negative is called polarity"
    },
    {
      "term": "258 :\nIt is not example of text summaries\nHeadlines\nOutlines\nDigest\nCorpus",
      "definition": "Feedback"
    },
    {
      "term": "259 :\nIt is not step of text summarization.\nConvert the paragraph into sentences\nText processing\nEvaluate the weighted occurrence frequency of the words\nCategorization",
      "definition": "Corpus"
    },
    {
      "term": "260 :\nWhat Is Full Form Of Nlg?\nNatural Language Generation\nNatural Language Genes\nNatural Language Growth\nNatural Language Generator",
      "definition": "Categorization"
    },
    {
      "term": "261 :\nWhich of the text parsing techniques can be used for noun phrase detection, verb phrase detection, subject detection, and object detection in NLP.\nPart of speech tagging\nSkip Gram and N-Gram extraction\nContinuous Bag of Words\nDependency Parsing and Constituency Parsing",
      "definition": "Natural Language Generation"
    },
    {
      "term": "262 :\nThe statement \"Which team won the match?\" can be represented as\nN->Wh-NP VP\nS->Wh-NP VP\nVP->Wh-NP VP\nS->Wh-NP NP",
      "definition": "Part of speech tagging"
    },
    {
      "term": "263 :\nCharacterizing the meaning of words in terms of its relationship to other words such as synonymy, antonymy, and hyponymy is called ________________.\nLexical relationship\nSemantic analysis\nCollocation\nGradable antonyms",
      "definition": "S->Wh-NP VP"
    },
    {
      "term": "264 : Which is not the Classification levels in Sentiment Analysis",
      "definition": "Character-level"
    },
    {
      "term": "265 :\nWhich is correct option\nPragmatics is one of the approach of discourse analysis\nDiscourse Analysis is Study of utterance meaning\nA and B Both\nNone of them",
      "definition": "Character-level"
    },
    {
      "term": "266 :\n\"Sunder Pichal is the CEO of Google having headquarter in California\" , How many named entities exist in above sentence\n4\n2\n3\n1",
      "definition": "---------"
    },
    {
      "term": "267 : Selecting the appropriate speech act strategies and the linguistic forms for realizing it depends on the social status and the culture of the interlocutors",
      "definition": "All of these"
    },
    {
      "term": "268 :\nIn this sentence: \"...no benefits justify the risk of nuclear weapons...I will explain why nuclear technology has a future on our planet despite its dangers.\" Which type of lexical cohesion can you find?\nHyponymy\nSynonymy\nAntonymy\nHyponymy",
      "definition": "All of these"
    },
    {
      "term": "269 :\nThe study of which words occur together, and their frequency of co-occurrence is called as _______.\nConnotation\nCollocation\nImplication\nLocation",
      "definition": "Synonymy"
    },
    {
      "term": "270 : In CFG,terminals mainly correspond to ...............while pre-terminals mainly correspond to ........",
      "definition": "Words in the language, POS categories"
    },
    {
      "term": "271 : Which is example of homophony?",
      "definition": "be-bo"
    },
    {
      "term": "272 : What Is The Major Difference Between Crf (Conditional Random Field) And Hmm (Hidden Markov Model)? Crf Is Generative Whereas Hmm Is Discriminative Model Crf Is Discriminative Whereas Hmm Is Generative Model",
      "definition": "Crf And Hmm Are Generative Model"
    },
    {
      "term": "273 :\nThe metric to measure \"the intensity of emotion provoked by the stimulus\" in emotion modeling is:\nSeverity\nValence\nArousal\nDominance",
      "definition": "Crf Is Discriminative Whereas Hmm Is Generative Model"
    },
    {
      "term": "274 :\nA verb phrase cannot have a\na verb followed by an NP {VP → Verb NP}\na verb followed by a PP {VP → Verb PP}\na verb followed by two NPs {VP → Verb NP NP}\na verb followed by two APs {VP → Verb AP AP}",
      "definition": "Arousal"
    },
    {
      "term": "275 :\nThe words Blood bank, Sperm bank and Egg bank are the example of,\nPolysemy\nHypernym\nAntonym\nMetonymy",
      "definition": "---------"
    },
    {
      "term": "276 :\n\"I Saw Two Laser Printers In A Shop. They Were The Fastest Printers Available\". In This Statement, \"They\" Is Known As Which Type Of Reference In The Discourse Context?\nGeneric Refernce\nIndefinite Reference\nQuantifier/Ordinal Refenece\nDemonstrative Reference",
      "definition": "Polysemy"
    },
    {
      "term": "277 :\nGiven A Sound Clip Of A Person Or People Speaking, Determine The Textual Representation Of The Speech.\nText-To-Speech\nSpeech-To-Text\nText\nSpeech",
      "definition": "Generic Refernce"
    },
    {
      "term": "278 :\nWhich Approach Does Direct Translation Use?\nNo Approach\nWord By Word Translation\nSentential Translation\nParagraph By Paragraph Translation",
      "definition": "Speech-To-Text"
    },
    {
      "term": "279 :\nWhich algorithm is used for solving temporal probabilistic reasoning?\nHill-climbing search\nHidden markov model\nDepth-first search\nBreadth-first search",
      "definition": "Word By Word Translation"
    },
    {
      "term": "280 :\nThe performance of an utterance and its meaning\npositive face\nperlocutionary act\nlocutionary act\nillocutionary act",
      "definition": "Hidden markov model"
    },
    {
      "term": "281 :\nIn text summarisation an ___________ uses different words to describe the contents of the document.\nAbstract\nExtract\nInformation\nProse",
      "definition": "locutionary act"
    },
    {
      "term": "282 :\n\"I Met This Girl Earlier In A Conference.\" In This Statement, \"This\" Is Known As Which Type Of Reference In The Discourse Context?\nDefinite Refernce\nIndefinite / Non-Anaphoric Reference\nPronominal Refenece\nDemonstrative Reference",
      "definition": "Abstract"
    },
    {
      "term": "283 :\n\"John and Mary love their Acuras. They drive them all the time\". It is example of _______\nIndefinte noun pharse\nDefinte noun pharse\nDemostrative\nDiscontinuous sets",
      "definition": "Indefinite / Non-Anaphoric Reference"
    },
    {
      "term": "284 :\nIn linguistic morphology, _____________ is the process for reducing inflected words to their root form.\nRooting\nStemming\nText-Proofing\nProofing",
      "definition": "Discontinuous sets"
    },
    {
      "term": "285 :\nWhich one of the following statement is false?\nThe CFG can be converted to Chomsky normal form\nThe CFG can be converted to Greibach normal form\nCFG is accepted by pushdown automata\nCFG is accepted by Chomsky normal form",
      "definition": "Stemming"
    },
    {
      "term": "286 :\nIn information retrieval, extremely common words which would appear to be of little value in helping select documents that are excluded from the index vocabulary are called:\nStop Words\nTokens\nLemmatized Words\nStemmed Terms",
      "definition": "CFG is accepted by Chomsky normal form"
    },
    {
      "term": "287 :\nThe process of understanding the meaning and interpretation of words, signs and sentence structure is called as ________________.\nTokenization\nLexical Analysis\nSemanitc Analysis\nSentiment Analysis",
      "definition": "Stop Words"
    },
    {
      "term": "288 : Which Of The Text Parsing Techniques Can Be Used For Noun Phrase Detection, Verb Phrase Detection, Subject Detection, And Object Detection In Nlp.",
      "definition": "Continuous Bag Of Words"
    },
    {
      "term": "289 :\nWhat are the input and output of an NLP system?\nSpeech and noise\nSpeech and Written Text\nNoise and Written Text\nNoise and value",
      "definition": "Dependency Parsing And Constituency Parsing"
    },
    {
      "term": "290 :\n\" I promise to come\" is which type of speech act?\nCommissives\ndirectives\nDeclarations\nRepresentatives",
      "definition": "Speech and Written Text"
    },
    {
      "term": "291 : Each connection in HMM represents a _______ over possible options; given our ______, this results in a large search space of the ________ of all words given the tag.",
      "definition": "Value, variables, associativity"
    },
    {
      "term": "292 :\nAnaphoric relations hold between _______ phrases that refer to the same person or thing.\nVerb\nNoun\nPreposition\nAdjective",
      "definition": "Distribution, tags, probability"
    },
    {
      "term": "293 :\nSpeech Acts is defined as\nUsing paralinguistic features when speaking\nThe awareness of others' needs to be approved of and liked\nCommunicative acts that carry meaning beyond the words and phrases used within them, for example, apologies and promises\nThe reference of others is important",
      "definition": "Noun"
    },
    {
      "term": "294 :\n____________________________ transfers linear sequences of words into structure.\nSemantic Analysis\nTokens\nLexical analysis\nDiscourse",
      "definition": "Communicative acts that carry meaning beyond the words and phrases used within them, for example, apologies and promises"
    },
    {
      "term": "295 :\nParts-of-Speech tagging determines ___________\npart-of-speech for each word dynamically as per meaning of the sentence\npart-of-speech for each word dynamically as per sentence structure\nall part-of-speech for a specific word given as input\nall of the mentioned",
      "definition": "Semantic Analysis"
    },
    {
      "term": "296 :\n\"Sita loves her mother and Gita does too\" contain which type of ambiguity?\nSyntactic\nSemantic\nLexical\nAnaphoric",
      "definition": "all of the mentioned"
    },
    {
      "term": "297 :",
      "definition": "The likelihood of a POS tag given a word"
    },
    {
      "term": "298 :\nIn Sentiment analysis\nList the topics that a document deals with\nAssess the emotional content of a document\nCompress a document as much as possible without losing meaning, producing another document\nGiven a question in natural language, provide an appropriate answer in natural language",
      "definition": "The likelihood of a word given a POS tag"
    },
    {
      "term": "299 :\n________is the problem of selecting a sense for a word from a set of predefined possibilities.\nShallow Semantic Analysis\nDiscourse\nWord Sense Disambiguation\nPragmatic",
      "definition": "Assess the emotional content of a document"
    },
    {
      "term": "300 :\nText summarization finds the most informative sentences in a ____;\nVideo\nImage\nSound\nDoccument",
      "definition": "Word Sense Disambiguation"
    },
    {
      "term": "Doccument\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 7 ---",
      "definition": "301 :\nLook At That Dog With One Eye - Am I To Close An Eye And Look At The Dog Or Does The Dog Have One Eye? Which Type Of Ambiguity Do You Experience In This Sentence.\nSemantic Ambiguity\nSyntactic Ambiguity\nPragmetic Ambiguity\nAnaphoric Ambiguity"
    },
    {
      "term": "302 :\nWhich is the process whereby meaning representations are composed and assigned to linguistic inputs\nSemantic analysis\nLexical analysis\nSyntax Analysis\nMorphology Analysis",
      "definition": "Syntactic Ambiguity"
    },
    {
      "term": "303 :\nWhich of the following is not correct with respect to Word Sense Disambiguation (WSD)\nIt offers sense definitions of words\nIdentifies synsets of synonyms\nDefines a number of semantic relations\nIt's not free",
      "definition": "Semantic analysis"
    },
    {
      "term": "304 :\nHMMs are \"a statistical Markov model in which the system being modeled is assumed to be a ________process with ________ states\".\na)Convolution, completed\nb)Markov, Unobservable\nc)Analyzing, Categorized\nd)Complete, Observed",
      "definition": "Identifies synsets of synonyms"
    },
    {
      "term": "305 :\nIdentifying intentions in dialogue is ________\nMorphology\nSemantics\nPragmatics\nDiscourse",
      "definition": "b)Markov, Unobservable"
    },
    {
      "term": "306 :\nSentence Realization\nSyntactic Analysis\nDiscourse Analysis\nSemantic Analysis\nPragmatic Analysis",
      "definition": "---------"
    },
    {
      "term": "307 :\nIn the context of POS tagging, the objective would be to build an HMM to model P(____ | ___) and Compute the label probabilities given observations using _____ Rule.\nValue, Label, Markov\nWord, Tag, Bayes\nAttribute, Variable, Bayes\nInput, Label, Markov",
      "definition": "Syntactic Analysis"
    },
    {
      "term": "308 :\nWhat are the most common and the rarest term of the corpus?\nt5, t1\nt5, t6\nt4, t6\nt3, t5",
      "definition": "Word, Tag, Bayes"
    },
    {
      "term": "309 :\nRSG stands for\nRich Sentence Graph\nReal Summary Graph\nRich Syntactic Graph\nRich Semantic Graph",
      "definition": "---------"
    },
    {
      "term": "310 :\n_____ is a word with the most specific meaning\nhyponym\nsynonymy\nhypernym\nhomonyms",
      "definition": "Rich Semantic Graph"
    },
    {
      "term": "311 :\nModern Nlp Algorithms Are Based On .......................\nNeural Language Processing\nMachine Learning\nArtificial Intelligence\nMachine Translation",
      "definition": "---------"
    },
    {
      "term": "312 :\nVisiting relatives can be boring\nThe text is unambiguous\nThe text is ambiguous\nThe text clear and precise\nThe text is indisputable",
      "definition": "Machine Learning"
    },
    {
      "term": "313 :\nWhat is inference?\nThe process of deriving implied meanings\nThe process of signalling attitude\nThe concept of how all communication relies on presenting a 'face'\nThe process of syntax checking",
      "definition": "The text is ambiguous"
    },
    {
      "term": "314 :\nConceal - cover is a example of ________\nAntonym\nSynonym\nPolysemy\nHomonym",
      "definition": "The process of deriving implied meanings"
    },
    {
      "term": "315 :\nWhat is a meaning of Morphology?\nThe study of word format\nThe study of sentence format\nThe study of syntax of sentence\nThe study of semantics of sentence.",
      "definition": "Synonym"
    },
    {
      "term": "316 :\nHow many ambiguties exist in the following sentence. \" I know little Italian\".\n1\n3\n2\n0",
      "definition": "The study of word format"
    },
    {
      "term": "317 : \"The System Recognizes If Emails Belong In One Of Three Categories (Primary, Social, Or Promotions) Based On Their Contents.\" What This Application Is Called?",
      "definition": "Smart Assistant"
    },
    {
      "term": "318 :\nWhat is output of Morhological analysis for the input word 'mice'?\nmice N SG\nmouse N SG\nmouse N PL\nmice N PL",
      "definition": "Email Filters"
    },
    {
      "term": "319 : Which of the following is the fastest logic ?",
      "definition": "CMOS"
    },
    {
      "term": "320 : The word \"Putting\" is handle and clean up by which stemming rule? \"Putting ® Put\"",
      "definition": "{(X) -ing ® -ing}"
    },
    {
      "term": "321 :\nGoogle News Aggregator is example of ______________.\nMachine Translation Application\nText Summarization Application\nNER Application\nInformation Retrival Application",
      "definition": "{(X) -ing ® ϵ} and {--CC® C}"
    },
    {
      "term": "322 : Which python library use to implement natural language processing?",
      "definition": "Scrapy"
    },
    {
      "term": "323 : Which of the following measurements are used to evaluate the quality of entity recognition?",
      "definition": "ERROR: Cannot find option NLTK"
    },
    {
      "term": "324 :\nResults from a search engine that are based upon the retrieval of items using a method of term weighting such as cosine similarity is a form of:\nSponsored Search\nAlgorithmic Search\nInformational Search\nNavigational Search",
      "definition": "Recall"
    },
    {
      "term": "325 :\nWords automatic, automation, are converted to automat. This the output of which process.\nFSA\nLemmatization\nStemming\nParser",
      "definition": "---------"
    },
    {
      "term": "326 :\n\"She eats fish with the fork\". Identify ambiguity in the given sentence\nAnaphoric Ambiguity\nLexical Ambiguity\nSyntax Ambiguity\nSemantic Ambiguity",
      "definition": "Stemming"
    },
    {
      "term": "327 :\nThe Knowledge Sources Used By Which Algorithms Include Context Of Word, Sense Frequency, Selectional Preferences, Collocation And Domain?\nFuzzy Logic\nWord Sense Disambiguation\nShallow Semantic Analysis\nArtificial Intelligence",
      "definition": "Syntax Ambiguity"
    },
    {
      "term": "328 :\nIn an HMM, observation likelihoods measure\nThe likelihood of a POS tag given a word\nThe likelihood of a POS tag given the preceding tag\nThe likelihood of a word given a POS tag\nThe likelihood of a POS tag given two preceding tags",
      "definition": "Word Sense Disambiguation"
    },
    {
      "term": "329 :\nJohn has a cat and Mary has a rabbit. They play with them all the time. Identify the reference resolution problem in the above statement\nGenerics\nDiscontinuous sets\nInferrables\none anaohora",
      "definition": "The likelihood of a word given a POS tag"
    },
    {
      "term": "330 :\n____ concerns how sentences are used in different situations and how use affects the interpretation of the sentence.\nSyntax\nPhonology\nPragmatics\nDiscourse",
      "definition": "---------"
    },
    {
      "term": "331 :\nNoun resolutionx\nN×1\nN×N\n1×N\nN×V",
      "definition": "Pragmatics"
    },
    {
      "term": "332 :\nWhich of the following entities are identified by NER?\nProper Nouns\nNoun Phrase\nVerb Phrase\nAdverb",
      "definition": "N×V"
    },
    {
      "term": "333 : In which of the following stages of NLP, does one draws parse tree?",
      "definition": "Morphological"
    },
    {
      "term": "334 :",
      "definition": "Language experts needed"
    },
    {
      "term": "335 :\nParts-of-Speech tagging determines ___________\npart-of-speech for each symbol only generated dynamically as per meaning of the sentence\npart-of-speech for each word dynamically as per sentence structure\nall stem for a specific word given as input\nall lema for a specific word given as input",
      "definition": "Language experts needed"
    },
    {
      "term": "336 :\nWhich is an automatic way of determining the scope of negation and inverting the polarities of opinionated words that are actually affected by a negation.\nOpinion Handling\nNegation handling\nDiscourse Handling\nScope Handling",
      "definition": "part-of-speech for each word dynamically as per sentence structure"
    },
    {
      "term": "337 :\nWhich of the following is NOT an example of a typical discourse structure?\nnarratee\nlist\nnarrative\nquestion-answer",
      "definition": "Negation handling"
    },
    {
      "term": "338 :\nWhich among the following is one of the stages in NLP pipeline?\nSentiment Analysis\nTokenization\nSpell Checking\nSyntax Analysis",
      "definition": "narratee"
    },
    {
      "term": "339 : Which Application Of Nlp Refers To Automatic Production Of Speech (Utterance Of Natural Language Of Sentences)?",
      "definition": "Information Retrieval"
    },
    {
      "term": "340 :\nWhich of the options is not a NLP application?\nSentiment analysis\nTranslation from English to French\nTranslation from C++ to Java\nNamed entity recognition",
      "definition": "Speech Synthesis"
    },
    {
      "term": "341 :\nFormat of words is given in options, select incorrect option.\nBooks ® Book + Noun + Plural\n0\nCats ® Cat + Verb\nWent®go + Verb + Past",
      "definition": "Translation from C++ to Java"
    },
    {
      "term": "342 :\nCar is hyponym of\nScooter\nCycle\nRickshaw\nAutomobile",
      "definition": "Cats ® Cat + Verb"
    },
    {
      "term": "343 :\n____________ POS tagger uses probabilities.\nRule based\nStochastic\nProcedure based\nObject based",
      "definition": "Automobile"
    },
    {
      "term": "344 :\nMujhe khaanna khaanna hai. What will be tag of third word in the given sentence.\nNoun\nVerb\nAdverb\nAuxiliary verb",
      "definition": "Stochastic"
    },
    {
      "term": "345 :\nWhich NLP application involves conversion of Hindi text into SQL queries\nNatural Language Convertion to Database\nInformation retrieval\nNatural Language Extraction from Database\nNatural Language Interface to Database",
      "definition": "Verb"
    },
    {
      "term": "346 :\nFamous Tag set for English\nPenn Treebank\nOXFORD ENGLISH CORPUS PART-OF-SPEECH TAGSET\nENGLISH CLAWS PART-OF-SPEECH TAGSET\nNLTK",
      "definition": "Natural Language Convertion to Database"
    },
    {
      "term": "347 :\n\"Zuha Forgets Her Pendrive In Lab.\" In This Statement, \"Her\" Is Known As Which Type Of Reference In The Discourse Context?\nDefinite Refernce\nIndefinite Reference\nPronominal Refenece\nDemonstrative Reference",
      "definition": "---------"
    },
    {
      "term": "348 :\nIn CFG, Each rule has a __________side\nRight hand only\nLeft hand only\nRight hand and left hand\nSub hand",
      "definition": "Pronominal Refenece"
    },
    {
      "term": "349 :\nPragmatics cannot be defined as\nIt is the study of speaker meaning\nIt is the study of contextual meaning\nIt is the study of how more gets communicated than is said\nIt is the study of sound",
      "definition": "Right hand and left hand"
    },
    {
      "term": "350 :\nIr System : Subset Of Documents : : ? : Subset Of Information Within Document\nSpeech Recognition\nNatural Language Interfaces To Db\nInformation Extraction\nInformation Retrieval",
      "definition": "---------"
    },
    {
      "term": "Information Extraction\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 8 ---",
      "definition": "351 :\nWhich one of the following models can not perform text classification\nNaive Bayes\nSVM\nK-means\nOLAP"
    },
    {
      "term": "352 : CFG captures -----------------------------.",
      "definition": "Constituency and ordering"
    },
    {
      "term": "353 : Number of states require to accept string ends with 10.",
      "definition": "3"
    },
    {
      "term": "354 :\nIs Inflectional morphology performed in google translation?\nPerformed\nNot performed\nPartly performed\nDepends on situation",
      "definition": "3"
    },
    {
      "term": "355 :\n_____________________ is a group of words that may behave as a single unit or phrase.\nConstituency\nGrammatical Relation\nSub-categorization\nDependancies",
      "definition": "---------"
    },
    {
      "term": "356 : Summarization which creates new phrases paraphrasing the original source.",
      "definition": "Extraction-based"
    },
    {
      "term": "357 :\n______has the same spelling and sound, but do not have related meanings\nHomophones\nPolysemy\nHomonymy\nSynonymy",
      "definition": "Abstraction-based"
    },
    {
      "term": "358 :\nWhich of the following belongs to the open class group?\nVerb\nPrepositions\nDeterminents\nConjunctions",
      "definition": "Homonymy"
    },
    {
      "term": "359 : An anaphoric reference...",
      "definition": "Helps the text make sense"
    },
    {
      "term": "360 :\nPolysemy is defined as the coexistence of multiple meanings for a word or phrase in a text object. Which of the following models is likely the best choice to correct this problem?\nRandom Forest Classifier\nConvolutional Neural Networks\nGradient Boosting\nKeyword Hashing",
      "definition": "Refers back to another part of the text"
    },
    {
      "term": "361 :\nIn syntax analysis the input is provded from\nMorphology Analysis\nPhonology Analysis\nSemantics Analysis\nPragmatic Analyis",
      "definition": "Convolutional Neural Networks"
    },
    {
      "term": "362 :\nWhich Is The Type Of Morphology That Changes The Word Category And Affects The Meaning\nInflectional\nDerivational\nCliticization\nRational",
      "definition": "Morphology Analysis"
    },
    {
      "term": "363 :\nThe area of AI that investigates methods of facilitating communication between people and computers is:\nnatural language processing\nsymbolic processing\ndecision support\nrobotics",
      "definition": "Derivational"
    },
    {
      "term": "364 :\ninstead of thinking of words as containers of meaning, we look at the \"roles\" they fulfill within the situation described by a sentence\nsemantic roles (thematic roles)\nsemantic features\nSemantic roles\nsemantically; syntactically",
      "definition": "natural language processing"
    },
    {
      "term": "365 :\nStochastic tagger also known as............\nHM tagger\nRMM tagger\nHMM tagger\nSuper tagger",
      "definition": "semantic roles (thematic roles)"
    },
    {
      "term": "366 :",
      "definition": "How and which morphemes can be affixed to a stem"
    },
    {
      "term": "367 :\nWhich of the following is a single valued attribute\nRegister_number\nAddress\nSUBJECT_TAKEN\nReference",
      "definition": "How and which morphemes can be affixed to a stem"
    },
    {
      "term": "368 :\nWhich class words are limited in number\nOpen class\nClosed class\nTree bank\nDictionary",
      "definition": "Register_number"
    },
    {
      "term": "369 :\nWhich best describes the English language?\nEnglish has complex morphology and less rigid syntax.\nEnglish has less complex morphology but more rigid syntax.\nEnglish has complex morphology and rigid syntax.\nEnglish has complex morphology",
      "definition": "Closed class"
    },
    {
      "term": "370 :\nSuppose a language model assigns the following conditional n-gram probabilities to a 3-word test set: 1/4, 1/2, 1/4. Then P(test-set) = 1/4 1/2 1/4 = 0.03125. What is the perplexity?\n0.25\n0.03125\n32\n3.175",
      "definition": "English has less complex morphology but more rigid syntax."
    },
    {
      "term": "371 :\nNamed Entity Recognition means:\nFinding spans of text that constitute proper names and then classifying the type of the entity.\nMapping between name and entity.\nClassification of text into subject and predicates.\nSearching text for proper nouns.",
      "definition": "175"
    },
    {
      "term": "372 :\nIn An Hmm, Observation Likelihoods Measure\nThe Likelihood Of A Pos Tag Given A Word\nThe Likelihood Of A Pos Tag Given The Preceding Tag\nThe Likelihood Of A Word Given A Pos Tag\nThe Likelihood Of A Pos Tag Given Two Preceding Tags",
      "definition": "Finding spans of text that constitute proper names and then classifying the type of the entity."
    },
    {
      "term": "373 :\nConjunctions are used to ______ two phrases, clauses, or sentences\nSeparate\nIdentify\nDistinguish\nJoin",
      "definition": "The Likelihood Of A Word Given A Pos Tag"
    },
    {
      "term": "374 :\n\"I want an early upgrade\" What is the type of word class for word \"want\" ?\nVerb\nDeterminant\nPersonal Pronoun\nAdjective",
      "definition": "Join"
    },
    {
      "term": "375 : The basic operation of a web browser is to pass a request to the web server. This request is an address for a web page and is known as the:",
      "definition": "UAL: Universal Address Locator"
    },
    {
      "term": "376 :\nFST cannot work as _____________\nrecognizer\ngenerator\ntranslator\nlexicon",
      "definition": "HTTP: Hypertext transfer protocol"
    },
    {
      "term": "377 :\nChoose from the following where NLP is not being useful.\nAutomatic Text Summarization\nAutomatic Question-Answering Systems\nPartially Observable systems\nInformation Retrieval",
      "definition": "lexicon"
    },
    {
      "term": "378 :\nWhich One Of The Following Is Not A Pre-Processing Technique In Nlp\nConverting To Lowercase\nRemoving Punctuations\nRemoval Of Stop Words\nSentiment Analysis",
      "definition": "Partially Observable systems"
    },
    {
      "term": "379 :\nN-Gram language models cannot be used for -------.\nSpelling Correction\nPredicting the completion of a sentence\nRemoving semantic ambiguity\nSpeech Recognition",
      "definition": "Sentiment Analysis"
    },
    {
      "term": "380 :",
      "definition": "ERROR: Cannot find option c"
    },
    {
      "term": "381 :\nIn POS, using discriminative approach, direction of flow is from class to words\nYes\nNo\nDepends on sentence\nRandomly",
      "definition": "Regular verb"
    },
    {
      "term": "382 :\nOne of the main challenges of NLP Is _____________.\nHandling Ambiguity of Sentences\nHandling Tokenization\nHandling POS-Tagging\nAll of the mentioned",
      "definition": "No"
    },
    {
      "term": "383 :\nWord-Right , Word-Write are\nHomophones\nHomograph\nSynonyms\nAntonyms",
      "definition": "Handling Ambiguity of Sentences"
    },
    {
      "term": "384 :\nGiven A Sentence S=\"W1 W2 W3 ... Wn\", To Compute The Likelihood Of S Using A Bigram Model. How Would You Compute The Likelihood Of S?\nCalculate The Conditional Probability Of Each Word In The Sentence Given The Preceding Word And Add The Resulting Numbers\nCalculate The Conditional Probability Of Each Word In The Sentence Given The Preceding Word And Multiply The Resulting Numbers\nCalculate The Conditional Probability Of Each Word Given All Preceding Words In A Sentence And Add The Resulting Numbers\nCalculate The Conditional Probability Of Each Word Given All Preceding Words In A Sentence And Multiply The Resulting Numbers",
      "definition": "Homophones"
    },
    {
      "term": "385 :\nWhere does the Hidden Markov Model is used?\nSpeech recognition\nUnderstanding of real world\nBoth Speech recognition & Understanding of real world\nUnderstanding of real world images",
      "definition": "Calculate The Conditional Probability Of Each Word In The Sentence Given The Preceding Word And Multiply The Resulting Numbers"
    },
    {
      "term": "386 :\n\"I went to the school, and they told me come on next day\". What type of ambiguity present in the given sentence?\nSyntactic ambiguity\nAnaphoric ambiguity\nSemantic ambiguity\nLexical ambiguity",
      "definition": "Speech recognition"
    },
    {
      "term": "387 :\nWhich Application Of Nlp Allows Querying A Structured Database Using Natural Language Sentences?\nSpeech Recognition\nNatural Language Interfaces To Db\nInformation Extraction\nInformation Retrieval",
      "definition": "Anaphoric ambiguity"
    },
    {
      "term": "388 :\nIn the English language derivational morphemes can be...\nPrefixes ,Suffixes,Infixes\nPrefixes ,Suffixes\nInfixes only\nSuffixes only",
      "definition": "Natural Language Interfaces To Db"
    },
    {
      "term": "389 :\nWhich of the following pair represents Antonomy lexical relation?\n(fat, thin)\n(crow,bird)\n(window, door)\n(head,nose)",
      "definition": "Prefixes ,Suffixes"
    },
    {
      "term": "390 : Which of the following NLP tasks use sequential labeling technique?",
      "definition": "POS tagging"
    },
    {
      "term": "POS tagging & Named Entity Recognition & Speech recognition",
      "definition": "391 :\nHow many types of Deixis eixsts?\n3\n5\n4\n2"
    },
    {
      "term": "392 : Which of the following computer language is used for artificial intelligence? FORTRAN PROLOG",
      "definition": "ERROR: Cannot find option b"
    },
    {
      "term": "393 : What is Machine Translation?",
      "definition": "ERROR: Cannot find option PROLOG"
    },
    {
      "term": "394 :\nWhich is the true in NLP study?\nMachine learning is a subdivision of deep learning.\nShallow learning is the simplest form of deep learning.\nDeep learning is a subdivision of machine learning.\nNLP is the acronym for Neural Language Processing.",
      "definition": "Converts one human language to another"
    },
    {
      "term": "395 :\nHow many lexemes are there in following list.man,men,girls,girl,mouse\n4\n5\n3\n2",
      "definition": "Deep learning is a subdivision of machine learning."
    },
    {
      "term": "396 :\nGiven A Sequence Of Observations And A Hmm Model, Which Of The Following Fundamental Problems Of Hmm Finds The Most Likely Sequence Of States That Produced The Observations In An Efficient Way?\nEvaluation Problem\nLikelihood Estimation Problem\nDecoding Problem\nLearning Problem",
      "definition": "3"
    },
    {
      "term": "397 :\nWhich is not the main challenges in machine translation?\nWord Translation\nPhrase Translation\nSyntactic Translation\nSpecial Characters Translation",
      "definition": "Decoding Problem"
    },
    {
      "term": "398 :\nSolve the equation according to the sentence \"I am planning to visit New Delhi to attend Analytics Vidhya Delhi Hackathon\". A = (# of words with Noun as the part of speech tag) B = (# of words with Verb as the part of speech tag) C = (# of words with frequency count greater than one) What are the correct values of A, B, and C?\n5,5,2\n5,5,0\n7,5,1\n7,4,2",
      "definition": "---------"
    },
    {
      "term": "399 :\nWhich of the following will be POS Tagger output when the input sentence is \"And now for something completely different\"?\n[('And', 'CC'), ('now', 'RB'), ('for', 'IN'), ('something', 'RB'), ('completely', 'RB'), ('different', 'JJ')]\n[('And', 'CC'), ('now', 'RB'), ('for', 'IN'), ('something', 'NN'), ('completely', 'JJ'), ('different', 'RB')]\n[('And', 'CC'), ('now', 'RB'), ('for', 'IN'), ('something', 'NN'), ('completely', 'RB'), ('different', 'JJ')]\n\"[('And', 'CC'), ('now', 'RB'), ('for', 'CC'), ('something', 'NN'), ('completely', 'RB'), ('different', 'JJ')]\"",
      "definition": "7,4,2"
    },
    {
      "term": "400 : \"Make Computers As They Can Solve Problems Like Humans And Think Like Humans \" Is",
      "definition": "Stage Of Nlp"
    },
    {
      "term": "Challege Of Nlp\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 9 ---",
      "definition": "401 :\nwhen two or more different (written) forms have the same pronunciation (bare/bear)\nhyponymy\nhyponym\nhomonyms\nhomophones"
    },
    {
      "term": "402 :\nIn NLP, The process of identifying people, an organization from a given sentence, paragraph is called\nStemming\nLemmatization\nStop word removal\nNamed entity recognition",
      "definition": "homophones"
    },
    {
      "term": "403 :\nBoth _____ and finite-state automata can be used to describe regular languages\nLanguage model\nDeterministic Finite Automata\nRegular expressions\nFinite State Translators (FSTs)",
      "definition": "Named entity recognition"
    },
    {
      "term": "404 :\nWhich is not one of the four frequently used meaning representations\nFirst Order Predicate Calculus (FOPC)\nSyntatic Network\nSemantic Network\nConceptual Dependency diagram",
      "definition": "Regular expressions"
    },
    {
      "term": "405 :\nAmbiguity cannot occurs in\nLexical\nDiscourse\nSemantic\nPragmatic",
      "definition": "---------"
    },
    {
      "term": "406 :\nIdentify correct POS for a given sentence \"I am a boxer\"\nDET aux. verb DET NN\nPRP aux. verb DET PRP\nNN verb DET NN\nPRP aux. verb DET NN",
      "definition": "Discourse"
    },
    {
      "term": "407 :\nA Network With Named Nodes And Labeled Arcs That Can Be Used To Represent Certain Natural Language Grammars To Facilitate Parsing.\nTree Network\nStar Network\nTransition Network\nComplete Network",
      "definition": "PRP aux. verb DET NN"
    },
    {
      "term": "408 :\nWhich of these is NOT a feature of pragmatics?\nCultural references\nUse of humour and irony\nAssumptions about audiences\nCohesion",
      "definition": "Transition Network"
    },
    {
      "term": "409 :\n\"She Got Her Trousers Shortened By One Inch\". In This Statement, \"One\" Is Known As Which Type Of Reference In The Discourse Context?\nGeneric Refernce\nIndefinite Reference\nQuantifier/Ordinal Refenece\nDemonstrative Reference",
      "definition": "Cohesion"
    },
    {
      "term": "410 :\nHow many noun phrases are there in the following sentence ,\" The thief robbed the apartment\"?\n1\n2\n3\n4",
      "definition": "Quantifier/Ordinal Refenece"
    },
    {
      "term": "411 : The Boy Said To Girl , \" Call Me A Cab\", Girl Said \"Ok You Are A Cab!\",Which Type Of Ambiguity Do You Experience In Thi",
      "definition": "Semantic Ambiguity"
    },
    {
      "term": "412 :\nis used to remove the suffixes from an English word and obtain its stem which becomes very useful in the field of Information Retrieval (IR).\nHMM Stemmer\nPorter Stemmer\nMarkov Stemmer\nBert Stemmer",
      "definition": "Syntactic Ambiguity"
    },
    {
      "term": "413 :\nWhich of the following NLP problems can not be solved with Hidden Markov Model (HMM)?\nPOS tagging\nSpeech recognition\nSpelling correction\nStemming",
      "definition": "Porter Stemmer"
    },
    {
      "term": "414 :\nSpam E-mail detection is __________________\nText Summarization system\nText Categorization System\nSentiment analysis System\nMachine Translation System",
      "definition": "Stemming"
    },
    {
      "term": "415 :\nWhich Of The Following Technique Is Not A Part Of Flexible Text Matching?\nSoundex\nMetaphone\nEdit Distance\nKeyword Hashing",
      "definition": "Text Categorization System"
    },
    {
      "term": "416 :\nWhat Includes Cultural Knowledge And Interpersonal Knowledge\nSituational Context\nBackground Knowledge\nCo-Textual Context\nOperational Knowledge",
      "definition": "Keyword Hashing"
    },
    {
      "term": "417 :\nDistance measure used to calculate semantic similarity between words is ____\nCosine Similarity\nManhattan Distance\nEuclidean Distance\nLevenshtein Distance",
      "definition": "Background Knowledge"
    },
    {
      "term": "418 :\nRegular expressions are\ncase neutral\ncase sensitive\ncase exclusive\nDepends on the expressions",
      "definition": "---------"
    },
    {
      "term": "419 :\nWhich is not the component of logical expression in predicate logic\nPredicates\nConnectives\nQuantifiers\nIdentifiers",
      "definition": "case sensitive"
    },
    {
      "term": "420 :\n\"Excuse Me. You Are Standing On My Foot.\" This Sentence Is Not Just Plain Assertion; It Is A Request To Someone To Get Off Your Foot. Is An Example Of?\nDiscourse Analysis\nWord Level Analysis\nSemantic Analysis\nSyntax Analysis",
      "definition": "Connectives"
    },
    {
      "term": "421 :\ntwo or more words with the same form and related meanings by extension (foot of a person, of a bed, of a mountain); based on similarity\nMetonymy\nHyponymy\nPolysemy\nHyponym",
      "definition": "Discourse Analysis"
    },
    {
      "term": "422 :\n\"Yesterday I went to college\" contains __________type of deixis.\nPersonal\nTime\nSocial\nSpace",
      "definition": "Polysemy"
    },
    {
      "term": "423 : Which of the following is correct example of stem \"replayed\"?",
      "definition": "Play"
    },
    {
      "term": "424 :\nWhat is the major difference between CRF (Conditional Random Field) and HMM (Hidden Markov Model)?\nCRF is Generative whereas HMM is Discriminative model\nCRF is Discriminative whereas HMM is Generative model\nBoth CRF and HMM are Generative model\nBoth CRF and HMM are Discriminative model",
      "definition": "Play"
    },
    {
      "term": "425 :\nIn Nlp, Context Modeling Is Supported With Which One Of The Following Word Embeddings\nWord2Vec\nGlove\nBert\nSpelling Correction",
      "definition": "CRF is Discriminative whereas HMM is Generative model"
    },
    {
      "term": "426 :\nWhich of the following example is the type of free morphemes?\nDog\nUn-(unhappy)\nRe-(Reschedule)\n-y(smiley)",
      "definition": "Bert"
    },
    {
      "term": "427 :\nFollowing property is of -____________These taggers are knowledge-driven taggers\nRule Based Tagging\nStochastic tagging\nHMM POS Tagging\nTransformation-based Tagging",
      "definition": "Dog"
    },
    {
      "term": "428 :\nIn English language derivational morphemes can be.\nPrefixes,infixes and sufixes\nPrefixes and sufixes\nPrefixes only.\nSufixes only",
      "definition": "Rule Based Tagging"
    },
    {
      "term": "429 :\nWord- Bass - as pitch Word- Bass as fish are\nHomophones\nHomograph\nSynonyms\nAntonyms",
      "definition": "Prefixes and sufixes"
    },
    {
      "term": "430 :\nFSA define .................. while FST define .............\nRegular language, Regular language\nRegular relation, Regular language\nRegular language, Regular relation\nRegular relation, Regular relation",
      "definition": "Homograph"
    },
    {
      "term": "431 :\ntwo forms with opposite meanings\nantonyms\nsynonyms\nMetonymy\nhyponymy",
      "definition": "Regular language, Regular relation"
    },
    {
      "term": "432 :\nComponents of NLP?\nNLU,NLG\nNL simutator, NL analyser,NL scripting\nLR-Translator,LR-parser\nNLB-simulator, NLB-aquatiser",
      "definition": "antonyms"
    },
    {
      "term": "433 : The relatedness of polysemy is essentially based on similarity. ___ is using one to refer to the other.",
      "definition": "ERROR: Cannot find option NLU,NLG"
    },
    {
      "term": "434 :\nHow does the state of the process is described in HMM?\na)Literal\nb)Single random variable\nc)Single discrete random variable\nd)Literal and Single random variable",
      "definition": "Metonymy"
    },
    {
      "term": "435 :\n_____________ is as a machine that reads one string and generates another\nFSA\nFST\nFSM\nFSI",
      "definition": "c)Single discrete random variable"
    },
    {
      "term": "436 : In The English Language Derivational Morphemes Can Be.",
      "definition": "ERROR: Cannot find option FST"
    },
    {
      "term": "437 :\n_____used to point to things (it, this, these) and people (him, them, those idiots) (-->We built -->this city on rock and roll.)\nPartial deixis\nPragmatics\nTemporal deixis\nPersonal deixis",
      "definition": "Prefixes And Suffixes"
    },
    {
      "term": "438 :\nAlice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?' Which among the options is NOT a coreferrring expression?\nAlice, her\nAlice, she\nBook, her\nBook, it",
      "definition": "---------"
    },
    {
      "term": "439 :\nOne of the important factors for accurate machine translation is\nN-grams\nResolving sense ambiguity\nTesting data\nHuman translators",
      "definition": "Book, her"
    },
    {
      "term": "440 :\nA context free language is called ambiguous if _________\nIt has 2 or more left derivations for some terminal string ѡ є L (G)\nIt has 2 or more right derivations for some terminal string ѡ є L (G)\nIt has 2 or more left & right derivations for some terminal string ѡ є L (G)\nIt has 3 or more left & right derivations for some terminal string ѡ є L (G)",
      "definition": "N-grams"
    },
    {
      "term": "441 :\nLexical semantics (also known as lexicosemantics), is a subfield of _________________.\nSociology\nlinguistic semantics\nPhilosophy\nContent mining",
      "definition": "It has 2 or more right derivations for some terminal string ѡ є L (G)"
    },
    {
      "term": "442 :\nFor Research Article recommendation system ___________ NLP application can be used.\nInformation Retrieval\nText Classification\nText Summairzation\nNER",
      "definition": "linguistic semantics"
    },
    {
      "term": "443 :\nWhich Application Of Nlp When Given A Question And Set Of Documents, Attempts To Find The Precise Answer Or Precise Portion Of Texts In Which The Answer Appears\nText Summarization",
      "definition": "ERROR: No options for answer b"
    },
    {
      "term": "Answering\nInformation Extraction\nInformation Retrieval\nAnswer",
      "definition": "Answering"
    },
    {
      "term": "444 :\nWhat Is Full Form Of Nlg? M\nNatural Language Generation\nNatural Language Genes\nNatural Language Growth\nNatural Language Generator",
      "definition": "Natural Language Generation"
    },
    {
      "term": "445 :\nWhich of the follwing is an appication of NLP?\nSummarizing a text or article\nDesigning mobile computing\nfront page designing\nDatabase designing",
      "definition": "Summarizing a text or article"
    },
    {
      "term": "446 :\nOne way we organize our knowledge of words is on the basis of ___ (words that frequently occur together).We commonly associate certain words with other words. (Family Feud-esque, but with ONE word)\ncollocation\nhomophones\nlocation\ndenotation",
      "definition": "collocation"
    },
    {
      "term": "447 :\nHow Many Components Of Nlp Are There?\nTwo\nThree\nFour\nFive",
      "definition": "Two"
    },
    {
      "term": "448 :\n\"I almost bought an Acura Integra today, but a door had a dent and the engine seems noisy.\" This is an example of which type of referring expression\nReflexive\nGender Agreement\nInferrable\nSelectional Restriction",
      "definition": "Inferrable"
    },
    {
      "term": "449 :\nWhich of the following word contains derivational as well as inflectional suffixes\nregularity\ncarefully\nolder\navailabilities",
      "definition": "availabilities"
    },
    {
      "term": "450 :\nTwo words are there with same spelling as \"magazine\". One has meaning as something you read and another is cartridge to store bullets for a gun. However both words senses are related as to store or save somewhere. This is an example of\nMetonymy\nHyponymy\nPolysemy\nHyponym",
      "definition": "Polysemy\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 10 ---"
    },
    {
      "term": "451 :\nMaximum Entropy Model combines which features and in which model?\nHomogeneous features, probabilistic framework\nHeterogeneous features, dynamic framework\nHomogeneous features, randomized framework\nHeterogeneous features, probabilistic framework",
      "definition": "Heterogeneous features, probabilistic framework"
    },
    {
      "term": "452 :\nSubsequent reference to an already introduced entity; \"referring back\" (-->Paul's on the phone. I don't wanna talk to -->him.)\nFace\nWords\nAnaphora\nCataphora",
      "definition": "Anaphora"
    },
    {
      "term": "453 :\nA web link within a web page that references another part of the same page is called a:\nOut link\nVector\nIn link\nTendril",
      "definition": "---------"
    },
    {
      "term": "454 :\nFocus on what the words conventionally mean, rather than on what an individual speaker might think they mean, or want them to mean, on a particular occasion; concerned with objective or general meaning and avoids trying to account for subjective or local meaning\nsemantic features\nsemantic analysis\nSemantic roles\nsemantics",
      "definition": "semantic analysis"
    },
    {
      "term": "455 :\nConsider the statement: \"Ban on dancing on Governor's desk. \" would be interpreted as:\n(Ban (on dancing)) (on Governor's desk)\n(Ban on ((dancing) on Governor's desk)\n(Ban (on dancing on Governor's desk))\n(Ban on (dancing ) on ((governor's)) desk)",
      "definition": "(Ban on ((dancing) on Governor's desk)"
    },
    {
      "term": "456 :\nWhich Application Of Nlp Captures And Outputs Factual Information Contained Within A Document?\nSpeech Recognition\nNatural Language Interfaces To Db\nInformation Extraction\nInformation Retrieval",
      "definition": "Information Extraction"
    },
    {
      "term": "457 :\nThe input/output of a NLP system cannot be:\nSentence\nSpeech\n3D Model\nDocument",
      "definition": "3D Model"
    },
    {
      "term": "458 :\nInferrables, discontinuos sets, generics are the three types of referents that complicate the _________ problem.\nWord sense disambiguation\ndiscourse\nreference resolution\npragmatics",
      "definition": "---------"
    },
    {
      "term": "459 :\nWhat Does The Phenomena That Operates At Discourse Level Include?\nCohesion And Coherence\nCorrosion And Erosion\nConnection And Resolution\nCo-Ordination And Co-Operation",
      "definition": "Cohesion And Coherence"
    },
    {
      "term": "460 :\nIt is not type of text summarization\nExtraction based\nAbstraction based\nPredicted based\nInformation based",
      "definition": "Predicted based"
    },
    {
      "term": "461 :\n___________ tools allow businesses to identify customer sentiment toward products, brands or services in online feedback.\nLexical analysis\nSyntactical analysis\nHybrid analysis\nSentiment Analysis",
      "definition": "Sentiment Analysis"
    },
    {
      "term": "462 :\n'The Indian Soldiers fought like a Lion', in order to understand the real meaning the statement has to undergo\nSemantic Analysis\nPragmatic Analysis\nDiscourse Analysis\nSyntactic Analysis",
      "definition": "Semantic Analysis"
    },
    {
      "term": "463 :\nHow many bi-grams can be generated from given sentence:\"Analytics Vidhya is a great source to learn data science\"\n7\n8\n9\n10",
      "definition": "9"
    },
    {
      "term": "464 : Which would definitely be rejected by the English syntactic analyzer?",
      "definition": "The Rahul the go to the school"
    },
    {
      "term": "465 :\nMany words have more than one meaning; selecting the sensible meaning in context is done with\nRandomization\nShallow semantic analysis\nWord Sense Disambiguation\nPOS tagging",
      "definition": "Word Sense Disambiguation"
    },
    {
      "term": "466 :\nPolysemy is defined as the coexistence of multiple meanings for a word or phrase in a text object. Which of the following models is likely the best choice to correct this problem?\nRandom Forest Classifier\nConvolutional Neural Networks\nGradient Boosting\nClassification",
      "definition": "Convolutional Neural Networks"
    },
    {
      "term": "467 :\nLappin and Leass Algorithm is used for\nCoherence Relation\nPronoun Resolution\nAnaphora Resolution\nSyntax Analysis",
      "definition": "Pronoun Resolution"
    },
    {
      "term": "468 : The __________________ summarization technique involves pulling keyphrases from the source document.",
      "definition": "Extractive"
    },
    {
      "term": "469 :\nSemantic Analysis Is Concerned With\nMeaning Representation Of Linguistic Inputs\nAntonyms Of Linguistic Inputs\nSyntax Representation Of Linguistic Inputs\nMeaning Representation Of Programming Language Inputs",
      "definition": "Meaning Representation Of Linguistic Inputs"
    },
    {
      "term": "470 :\nParts-of-Speech tagging determines ___________\npart-of-speech for each word dynamically as per meaning of the sentence\npart-of-speech for each word dynamically as per sentence structure\nall part-of-speech for a specific word given as input\nevery thing mentioned above",
      "definition": "all part-of-speech for a specific word given as input"
    },
    {
      "term": "471 :\nGoogle Translate is one of the ________________ application.\nMachine translation\nInformation Retrieval\nInformation Extraction\nSummarisation",
      "definition": "---------"
    },
    {
      "term": "472 :\nTechniques not used in phrases extraction\nPart of speech tagging\nStatistical phrase extraction\nHybrid\nDecompounding",
      "definition": "Decompounding"
    },
    {
      "term": "473 : Morphological Segmentation is ......",
      "definition": "An extension of propositional logic"
    },
    {
      "term": "474 :\nWhich method of sentiment analysis uses a variety of words annotated by polarity score, to decide the general assessment score of a given content.\nWord-Based\nLexicon-Based\nHybrid\nOpinion-Based",
      "definition": "Lexicon-Based"
    },
    {
      "term": "475 :\nSyntactic n -grams are n -grams defined by paths in ________ dependency or constituent trees rather than the linear structure of the text\nSyntactic\nSemantic\nSymbolic\nLexical",
      "definition": "Syntactic"
    },
    {
      "term": "476 : \"Car is a ______ of \"vehical\".",
      "definition": "Hyponym"
    },
    {
      "term": "477 :\nSentiment analysis is also known as ____\nOpinion mining\nData mining\nText Analysis\nAutomatic Summerization",
      "definition": "Opinion mining"
    },
    {
      "term": "478 :\nA grammar that produces more than one parse tree for the same sentence is called as _______\nContiguous\nAmbiguous\nUnambiguous\nRegular",
      "definition": "Ambiguous"
    },
    {
      "term": "479 : For Hate Speech Detection from facebook messages __________NLP technique can be used.",
      "definition": "Text Classification"
    },
    {
      "term": "480 :\nThe statement \"Indirect speech acts are when there is no coincidence between the type of illocutionary act and the syntactic structure of the message\", means that:\nThe intention is not explicitly expressed in the message\nThe intention is expressed in the message\nThe act is expressed in intention\nThe intention is expressed as the act.",
      "definition": "The intention is not explicitly expressed in the message"
    },
    {
      "term": "481 :\nMentions are span of text referring to some entity. Which is not a mention here?\nNamed entities\nPronouns\nNoun phrases\nAdverb phrases",
      "definition": "---------"
    },
    {
      "term": "482 :\nPolysemy is a Greek word, which means\nMany names\nMany signs\nMany meanings\nMany verbs",
      "definition": "Many meanings"
    },
    {
      "term": "483 :\nMlmenu, A Natural Language Interface For The Ti Explorer, Is Similar To:\nEthernet\nNaturallink\nProlog\nThe Personal Consultant",
      "definition": "Naturallink"
    },
    {
      "term": "484 :\nWhat Is The Major Difference Between Crf (Conditional Random Field) And Hmm (Hidden Markov Model)?\nCrf Is Generative Whereas Hmm Is Discriminative Model\nCrf Is Discriminative Whereas Hmm Is Generative Model\nCrf And Hmm Are Generative Model\nCrf And Hmm Are Discriminative Model",
      "definition": "Crf Is Discriminative Whereas Hmm Is Generative Model"
    },
    {
      "term": "485 :\nThe area of AI that investigates methods of facilitating communication between people and computers is:\nnatural language processing\nsymbolic processing\ndecision support\nrobotics",
      "definition": "natural language processing"
    },
    {
      "term": "486 : which model is used for statistical machine translation",
      "definition": "ERROR: Cannot find option FST"
    },
    {
      "term": "487 :\nWhat Is Viewed As Problem Of Probabilistic Inference?\nSpeech Recognition\nSpeaking\nHearing\nUtterance",
      "definition": "Speech Recognition"
    },
    {
      "term": "488 :\nNP → Det Adj Noun, it denotes ____\nAdjective Phrase\nNoun Phrase\nNoun Adjective Phrase\nDeterminer Phrase",
      "definition": "Noun Phrase"
    },
    {
      "term": "489 :\nA prepositional phrase consists of a preposition and its\nObject\nSubject\nNoun\nVerb",
      "definition": "Object"
    },
    {
      "term": "490 :\nWhich algorithm is used to train HMM model?\nEarly algorithm\nLexk algorithm\nForward-backward or Welch algorithm\nA centering algorithm",
      "definition": "Forward-backward or Welch algorithm"
    },
    {
      "term": "491 :\nWhat is full form of NLP?\nNatural Language Processing\nNatural Language Procedure\nNatural Language Process\nNatural Language pages",
      "definition": "Natural Language Processing"
    },
    {
      "term": "492 :\nWhich is concerned with retrieval from a document collection where documents in multiple languages co-exist and need to be retrieved to a query in any language.\nCLIR\nBLIR\nMLIR\nMonolingual IR",
      "definition": "---------"
    },
    {
      "term": "493 : which type of summarizer will be suitable for summarizing tweets about Covid19 ?",
      "definition": "Extractive"
    },
    {
      "term": "494 :\nTool, instrument, implement, organ, utensil ---is example of ______\nHomonym\nAntonym\nHyponymy\nSynonymy",
      "definition": "Hyponymy"
    },
    {
      "term": "495 : ___________ tagger uses probabilistic and statistical information to assign tags to words.",
      "definition": "Stochastic tagger"
    },
    {
      "term": "496 :\nOver-stemming can also be regarded as __________________.\nFalse-Positives\nFalse-Negative\nTrue-Positive\nTrue-Negative",
      "definition": "False-Positives"
    },
    {
      "term": "497 :\nFollowing property is of - .These taggers are knowledge-driven\nRule based Tagging\nStochastic Tagging\nRule based Tagging and Stochastic Tagging\nNeither Rule based Tagging nor Stochastic Tagging",
      "definition": "Rule based Tagging"
    },
    {
      "term": "498 :\nWhich of the following is the example of surface segmentation?\nAchievability = achievabil + ity\nAchievability = achiev + ability\nAchievability = Achieve + able + ity\nAchievability = achiev + abil + ity",
      "definition": "Achievability = achiev + abil + ity"
    },
    {
      "term": "499 :\nIn text mining, how the words 'lovely' is converted to 'love'-\nBy stemming\nBy tokenization\nBy lemmatization\nBy rooting",
      "definition": "By stemming"
    },
    {
      "term": "500 :\nIt performs extensive analysis of linguistic phenomena through explicit representation of facts about language and well-understood knowledge representation schemas and associated algorithms. What is it?\nConvolutional Neural Networks\nRule based Approach\nCorpus based.\nHybrid",
      "definition": "Rule based Approach\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 11 ---"
    },
    {
      "term": "501 :\nthe study of the meaning of words, phrases, and sentences (meaning in a language)\nSemantic roles\nhomonyms\nlocation\nsemantics",
      "definition": "semantics"
    },
    {
      "term": "502 :\nWhat is morphology?\nThe study of the rules governing the sounds that form words\nThe study of the rules governing sentence formation\nThe study of the rules governing word formation\nThe study of the rules governing the sounds that form sentence",
      "definition": "The study of the rules governing sentence formation"
    },
    {
      "term": "503 :\nHow to compute probability of a sentence or sequence of sentence in N-gram model?\nP(W) = P(W1,W2, W3,..., Wn)\nP(W) = P(Wn+1|Wn-1)\nP(W) = P(Wn-1| Wn+1)\nP(W) = P(Wn+1 | Wn)",
      "definition": "P(W) = P(W1,W2, W3,..., Wn)"
    },
    {
      "term": "504 :\nIn which class, new words are added all the time\nOpen class\nClosed class\nTree bank\nWSD",
      "definition": "Open class"
    },
    {
      "term": "505 :\nIf your training loss increases with number of epochs, which of the following could be a possible issue with the learning process?\nRegularization is too low and model is overfitting\nRegularization is too high and model is underfitting\nStep size is too large\nStep size is too small",
      "definition": "---------"
    },
    {
      "term": "506 :\nThe statement \"Time passes very quickly\" can be represented as\nAdvP->(Intens) NP\nAdvP->(Intens) Adv\nN->Wh-NP VP\nS->Wh-NP VP",
      "definition": "AdvP->(Intens) NP"
    },
    {
      "term": "507 :\nFor understanding semantic relation between terms which type of technique used?\nSupervised learning\nClustering technique\nOntology based classification\nUnsupervised learning",
      "definition": "Ontology based classification"
    },
    {
      "term": "508 :\nWhich is not a POS tagging approaches\nRule based POS tagging\nStochastic POS tagging\nTransformation based Tagging\nFuzzy logic based Tagging",
      "definition": "Fuzzy logic based Tagging"
    },
    {
      "term": "509 :\nWhich two events are used by Hidden Markov model to build probalistic model?\nTransitive and Hidden events\nTransitive and emisson events\nObserved and Hidden events\nEmission and Hidden events",
      "definition": "Transitive and emisson events"
    },
    {
      "term": "510 :\nParsing determines ___________ (Grammatical Analysis) for a given sentence.\nParse Tree\nParse Graph\nParse Plan\nParse Model",
      "definition": "---------"
    },
    {
      "term": "511 :\nFor e.g. sentence is \"Park the car\". POS for words in sentences park: Noun, Verb. the: Determiner. car: Noun. How many hidden state sequences are possible\n4\n8\n7\n2",
      "definition": "2"
    },
    {
      "term": "512 :\nNumber,person,gender and case agreements are examples of which types of constraints on reference resolution?\nsemantic\nlexical\ndiscourse\nsyntactic",
      "definition": "---------"
    },
    {
      "term": "513 :\nWhich of the following is the example of overstemming?\nUnivers\nUniverse\nUniversal\nUniversity",
      "definition": "Univers"
    },
    {
      "term": "514 :\nReasoning about time can be facilitated by:\nDetection and normalization of temporal expressions.\nTimeBank Corpus\nSequence Models\nFixed set of slots",
      "definition": "Detection and normalization of temporal expressions."
    },
    {
      "term": "515 :\nTo automat HR recruitment process ________type of NLP application will be suitable.",
      "definition": "Answering System\nMachine Transltion\nSentiment Analysis\nNER"
    },
    {
      "term": "516 : ........... are the lexemes with the same orthographic form but different meaning.",
      "definition": "homographs"
    },
    {
      "term": "517 : Which of the following instances the regular expression \"\\b(one|two|three)\\b\" can recognize?",
      "definition": "\"one\""
    },
    {
      "term": "518 :\nSolve the equation according to the sentence \"I am planning to visit New Delhi to attend Analytics Vidhya Delhi Hackathon\". A = (# of words with Noun as the part of speech tag) B = (# of words with Verb as the part of speech tag) C = (# of words with frequency count greater than one) What are the correct values of A, B, and C?\n5, 5, 2002\n5, 5, 2000\n7, 5, 2001\n7, 4, 2002",
      "definition": "\"one\""
    },
    {
      "term": "519 :\nIn an HMM, observation likelihoods measure\nThe likelihood of a POS tag given a word\nThe likelihood of a POS tag given the preceding tag\nThe likelihood of a word given a POS tag\nThe likelihood of a POS tag given two preceding tags",
      "definition": "7, 4, 2002"
    },
    {
      "term": "520 :\nAssume a corpus with 350 tokens in it. We have 20 word types in that corpus (V = 20). The frequency (unigram count) of word types \"short\" and \"fork\" are 25 and 15 respectively. If we are using the Laplace smoothing, which of the following is PLaplace(\"fork\")?\n15/350\n16/370\n30/350\n31/370",
      "definition": "The likelihood of a word given a POS tag"
    },
    {
      "term": "521 :\nThe phase Syntax Analysis is modeled on the basis of\nHigh level language\nLow level language\nContext free grammar\nRegular grammar",
      "definition": "16/370"
    },
    {
      "term": "522 :\nPROLOG, LISP, NLP are the language of\nArtificial Intelligence\nMachine Learning\nInternet of Things\nDeep Learning",
      "definition": "Context free grammar"
    },
    {
      "term": "523 :\nWhich of the following models can be estimated by maximum likelihood estimator?\nSupport Vector Machines\nMaximum Entropy Model\nk Nearest Neighbor\nNaive Bayes.",
      "definition": "Artificial Intelligence"
    },
    {
      "term": "524 :\nLexical semantics deals with_________\nMeaning of word\ninternal structure of words\nrelationship between the words\nAll a,b,c",
      "definition": "Maximum Entropy Model"
    },
    {
      "term": "525 :\n_____________ is the process of understanding if a given text is talking positively or negatively about a given subject (e.g. for brand monitoring purposes).\nSyntactical analysis\nHybrid analysis\nSentiment Analysis\nLexical analysis",
      "definition": "Meaning of word"
    },
    {
      "term": "526 :\nFor automated complaint handling ______ type of NLP application can be used.\nNER\nMachine Transltion\nSentiment Analysis\nText Categorization",
      "definition": "Sentiment Analysis"
    },
    {
      "term": "527 :",
      "definition": "Mother Tongue & Commonsense Knowledge"
    },
    {
      "term": "528 :\nA ___________ is a word that resembles a preposition or an adverb, and that often combines with a verb to form a larger unit called a phrasal verb\nPreposition\nDeterminers\nParticle\nAdjectives",
      "definition": "Linguistic & Commonsense Knowledge"
    },
    {
      "term": "529 :\nWhich of the following is the example of understemming?\nData\nDate\nDatum\nDat, Datu",
      "definition": "Particle"
    },
    {
      "term": "530 :\nIn Probability Ranking Principal, Ranking documents in order of ____________ probability of relevance is optimal.\nIncreasing\nDecreasing\nAnyway\nSteady",
      "definition": "Dat, Datu"
    },
    {
      "term": "531 :\nThe words 'there' and 'their' causes which of the following type of ambiguity?\nSyntactic\nSemantic\nPhonological\nPragmatic",
      "definition": "Decreasing"
    },
    {
      "term": "532 :\nCorrect rule to write noun phrase for the sentence \"The boy gave the girl a book\"\nVP - Verb NP\nVP - Verb PP\nVP - NP PP\nVP - Verb NP NP",
      "definition": "Phonological"
    },
    {
      "term": "533 :\n\"Parrot ate the guava as it was ripe\" Identify the ambiguity\nNoun resolutionx\nAdjective resolution\nVerb resolution\nPronoun resolution",
      "definition": "VP - NP PP"
    },
    {
      "term": "534 :\nWhich Of The Following Is Used To Mapping Sentence Plan Into Sentence Structure?\nText Planning\nSentence Planning\nText Realization\nCosine Similarity",
      "definition": "Pronoun resolution"
    },
    {
      "term": "535 :\n\"Monkey ate the banana as it was ripe\" Identify the dependency checking to resolve the ambiguity of 'it'\nMonkey, banana\nBanana, ripe\nMonkey, ripe\nAte, banana",
      "definition": "Text Realization"
    },
    {
      "term": "536 :\nUses unidirectional language model for producing word embedding\nBERT\nGPT\nELMo\nWord2Vec",
      "definition": "Banana, ripe"
    },
    {
      "term": "537 : Polysemy Is Defined As The Coexistence Of Multiple Meanings For A Word Or Phrase In A Text Object. Which Of The Following Models Is Likely The Best Choice To Correct This Problem?",
      "definition": "ERROR: Cannot find option GPT"
    },
    {
      "term": "538 :\nIn NLP, computer has to understand natural language in which format\nText and/or speech\nStructured format\nUnstructured format\nXML format",
      "definition": "Convolutional Neural Networks"
    },
    {
      "term": "539 :\n_____________ is not a module in question answering system",
      "definition": "Text and/or speech"
    },
    {
      "term": "Analysis\nAnswer Selection\nSentiment Analysis\nInformation Retrieval",
      "definition": "Sentiment Analysis"
    },
    {
      "term": "540 : Which of the following belongs to the open class group?",
      "definition": "Noun"
    },
    {
      "term": "541 :\nWhich approach is used for spelling error detection and correction\nScript Validation\nTokenization\nN-gram\nFilteration",
      "definition": "N-gram"
    },
    {
      "term": "542 :\nHow given sentence represented using Bigram model? \"I want to eat Indian food\"\n{(I, want), (want, to), (to, eat), (eat, Indian),(Indian, food)}\n{(I ), (want, to), (to, eat), (eat, Indian),(Indian, food),(food, I)}\n{(I, want, to), (want, to, eat), (to, eat, Indian), (eat, Indian, food)}\n{(I), (want), (to), (eat), (Indian), (food)}",
      "definition": "{(I, want), (want, to), (to, eat), (eat, Indian),(Indian, food)}"
    },
    {
      "term": "543 :\nAssume that there are 10000 documents in a collection. Out of these, 50 documents contain the terms \"difficult task\". If \"difficult task\" appears 3 times in a particular document, what is the TFIDF value of the terms for that document?\n8.11\n15.87\n0\n81.1",
      "definition": "87"
    },
    {
      "term": "544 :\nIn NLP, word \"natural\" indicates\nTo distinguish human languages from computer languages\nIt is subfield of AI\nIt is more close to English language\nIt is closed to all languages except English language",
      "definition": "To distinguish human languages from computer languages"
    },
    {
      "term": "545 : What is the single morpheme of word \"Boxes\"?",
      "definition": "Box"
    },
    {
      "term": "546 : Which of the following techniques can be used to compute the distance between two words?",
      "definition": "Dekang Lin"
    },
    {
      "term": "547 :\nFollowing property is of - .This POS tagging is based on the probability of tag occurring\nRule based Tagging\nStochastic Tagging\nRule based Tagging and Stochastic Tagging\nNeither Rule based Tagging nor Stochastic Tagging",
      "definition": "Stochastic Tagging"
    },
    {
      "term": "548 : Which are the consonants in a given string? \"SYZYGEO\"",
      "definition": "ERROR: Cannot find option S, Z, G"
    },
    {
      "term": "549 :\nIn the sentence, \"They bought a blue house \", the underlined part is an example of _____.\nNoun phrase\nVerb phrase\nPrepositional phrase\nAdverbial phrase",
      "definition": "Noun phrase"
    },
    {
      "term": "550 :\nFor e.g. \"Before she purchased it, Mary checked warranty card of the product\". In the context of pronoun, this is the example of\nCataphora\nBound\nFree\nRandom",
      "definition": "---------\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 12 ---"
    },
    {
      "term": "551 :\nWhich instruments are used for perceiving and acting upon the environment?\nSensors and Actuators\nSensors\nPerceiver\neffector",
      "definition": "---------"
    },
    {
      "term": "552 : \"Ram's bike is new\" is _____________ type of presupposition",
      "definition": "Existential"
    },
    {
      "term": "553 :\n\"Sagar loved watching movies. He likes comedy movies.\" Given sentence does not hold ______type of ambiguity\nSyntax Level ambiguity\nReferential ambiguity\nLexical Ambiguity\nSyntax Level & Referential ambiguity",
      "definition": "---------"
    },
    {
      "term": "554 :\nHMM graphs consist of a Hidden Space and Observed Space, where the hidden space consists of the _______ and the observed space is the ______\nInput, Categories\nValues, Variables\nLabels, Input\nVariables, Values",
      "definition": "Labels, Input"
    },
    {
      "term": "555 :\nAn optimizer Compiler\nIs optimized to occupy less space\nBoth of the mentioned\nOptimize the code\nNone of the mentioned",
      "definition": "None of the mentioned"
    },
    {
      "term": "556 :\nA DFA is a tuple A = (Q, ∑, δ, qo, F) ,what does δ indicates?\nFinite set of state\nA finite set of input symbols\nTransition function\nA set of final states",
      "definition": "Transition function"
    },
    {
      "term": "557 :\nWords 'happy', 'talk', 'use' are examples of which morpheme\nPrefix\nBound\nFree\nSuffix",
      "definition": "Free"
    },
    {
      "term": "558 :\nProbabilistic context- free grammar (PCFG) is also known as the __________\nStochastic context-free grammar\nContext sensitive context-free grammar\nRegular grammar\nUnrestricted context free grammar",
      "definition": "Stochastic context-free grammar"
    },
    {
      "term": "559 :\nA model of information retrieval in which we can pose any query in which search terms are combined with the operators AND, OR, and NOT:\nAd Hoc Retrieval\nRanked Retrieval Model\nBoolean Information Model\nProximity Query Model",
      "definition": "Boolean Information Model"
    },
    {
      "term": "560 :\n______________ deals with analyzing emotions, feelings and attitude of speaker or writer from given piece of text\nSemantic Analysis\nSentiment Analysis\nInformation Retrival\nText classification",
      "definition": "Sentiment Analysis"
    },
    {
      "term": "561 :\nWhat is not the field of Natural Language Processing (NLP)?\nComputer Science\nArtificial Intelligence\nLinguistics\nEconomics",
      "definition": "Economics"
    },
    {
      "term": "562 :\nWhen Training A Language Model, If We Use An Overly Narrow Corpus, The Probabilities\nDon'T Reflect The Task\nReflect All Possible Wordings\nReflect Intuition\nDon'T Generalize",
      "definition": "Don'T Generalize"
    },
    {
      "term": "563 :\nThe word \"Tree\" is an example of\nComplex words\nCompound words\nSimple words\nJoint Words",
      "definition": "Simple words"
    },
    {
      "term": "564 :\nWhat is Morphological Segmentation?\nDoes Discourse Analysis\nSeparate words into individual morphemes and identify the class of the morphemes\nIs an extension of propositional logic\ngenerate language",
      "definition": "Separate words into individual morphemes and identify the class of the morphemes"
    },
    {
      "term": "565 :\nWhich of these is NOT a feature of pragmatics?\ncultural references\nassumptions about audiences\nimplication and inference\ncohesion",
      "definition": "cohesion"
    },
    {
      "term": "566 : Which is most common algorithm used in English language for Stemming?",
      "definition": "Porter stemmer"
    },
    {
      "term": "567 :\nIn which type of morphology, grammatical changes like number, tense, case gender takes place. e.g. walk, walks, walked, walking\nDerivational\nInflectional\nBoth derivation and inflectional\nSemantic",
      "definition": "Inflectional"
    },
    {
      "term": "568 :\nCohesion Bounds Text Together. Consider The Following Piece Of Text \"Yesterday, My Friend Invited Me To Her House. When I Reached, My Friend Was Preparing Coffee. Her Father Was Cleaning Dishes. Her Mother Was Busy Writing A Book.\" Each Occurance In The Above Text Refers To Which Noun Phrase?\nMe\nFriend'S Father\nFriend'S Mother\nMy Friend'S",
      "definition": "My Friend'S"
    },
    {
      "term": "569 :\nWhat is a lemma?\nA type of phoneme\nA phonological representation of a word\nThe abstract form of a word containing information relating to the meaning of a word\nA type of semantic",
      "definition": "The abstract form of a word containing information relating to the meaning of a word"
    },
    {
      "term": "570 :\nIn Semantic Analysis word embedding is used to _______\nClassify ambiguity in sentence\nConvert text data to numeric vector\nFeature Selection\nFeature Reduction",
      "definition": "---------"
    },
    {
      "term": "571 :\nIn the sentence \" I made her duck.\" Here the word \"her\" is\nsemantically ambiguous\nsyntactically ambiguous\nmorphologically ambiguous\nnot ambiguous",
      "definition": "syntactically ambiguous"
    },
    {
      "term": "572 : Context -free grammars also known as .............",
      "definition": "Phrase structure grammars"
    },
    {
      "term": "573 :\nThe steps of preprocessing in Natural Language Processing does not include..\nStemming\nTokenization\nStop Word Removal\nSegmantation",
      "definition": "Segmantation"
    },
    {
      "term": "574 :\nWhich Of The Following Is Used To Mapping Sentence Plan Into Sentence Structure?\nText Planning\nSentence Planning\nText Realization\nStemming",
      "definition": "Text Realization"
    },
    {
      "term": "575 :\nWhat is not the field of Natural Language Processing (NLP)?\nComputer Science\nArtificial Intelligence\nLinguistics\nbuilding robot",
      "definition": "building robot"
    },
    {
      "term": "576 :\nWhat could possibly be the environment of a Satellite Image Analysis System?\nComputers in space and earth\nImage categorization techniques\nStatistical data on image pixel intensity value and histograms\nAll of the mentioned",
      "definition": "All of the mentioned"
    },
    {
      "term": "577 :\nIn test summarisation an ___________ is formed by selecting phrases or sentences from the document to be summarized\nAbstract\nExtract\nInformation\nProse",
      "definition": "Extract"
    },
    {
      "term": "578 :\nMain reason for tokenization\nIt is simplest process\nProcessing on word can be easily performed\nAlmost all algorithms of tokenization executes in polynomial time\nReadymade program are available in various programming language",
      "definition": "Processing on word can be easily performed"
    },
    {
      "term": "579 :\nCorrect machine translation from English to Hindi for sentence: \"House temperature \"\nGhar tapman\nGhar ka tapman\nGhar ka temperature\nHouse ka tapman",
      "definition": "Ghar ka tapman"
    },
    {
      "term": "580 :\n____________ interpretation is done by adding context-dependant information\nSemantic\nPragmatic\nSyntactic\nWord level Analysis",
      "definition": "Pragmatic"
    },
    {
      "term": "581 :\nWord segmentation is mostly used when\nHyphens are present\nMultiple alphabets intermingled\nLong sentences\nNo space between words",
      "definition": "Long sentences"
    },
    {
      "term": "582 :\nHow many DFA's exits with two states over input alphabet {0,1} ?\n16\n26\n32\n64",
      "definition": "64"
    },
    {
      "term": "583 :\nSentiment analysis is the interpretation and classification of ______ emotions within text data using text analysis techniques\npositive\nnegative\nneutral\nAll positive,negative and neutral",
      "definition": "All positive,negative and neutral"
    },
    {
      "term": "584 : Which type of ambiguity is present in the sentence \"Old men and women were taken to safe locations\"?",
      "definition": "Scope Ambiguity"
    },
    {
      "term": "585 :\nWhich Of The Following Statement Is(Are) True For Word2Vec Model?\nThe Architecture Of Word2Vec Consists Of Only Two Layers - Continuous Bag Of Words And Skip-Gram Model\nContinuous Bag Of Word (Cbow) Is A Recurrent Neural Network Model\nCbow And Skip-Gram Are Shallow Neural Network Models\nConvolutional Neural Networks",
      "definition": "Cbow And Skip-Gram Are Shallow Neural Network Models"
    },
    {
      "term": "586 :\nIn POS, using generative approach, direction of flow is from class to words\nYes\nNo\nDepends on sentence\nRandomly",
      "definition": "No"
    },
    {
      "term": "587 :\nIn which method parts of the documents are labeled and other parts are not labeled during text categorization\nSupervised learning method\nUnsupervised learning method\nSemi-supervised learning method\nSub-supervised learning method",
      "definition": "Semi-supervised learning method"
    },
    {
      "term": "588 :\nWhat Is The Number Of Trigrams In A Normalized Sentence Of Length N Words?\nN\nN-1\nN-2\nN-3",
      "definition": "N-2"
    },
    {
      "term": "589 :\nSuppose we want to calculate a probability for the sequence of observations {'Dry','Rain'}. If the following are the possible hidden state sequences, then P('Dry','Rain') = ---------. Transition probabilities: P('Low'|'Low')=0.3 , P('High'|'Low')=0.7 P('Low'|'High')=0.2, P('High'|'High')=0.8 • Observation probabilities : P('Rain'|'Low')=0.6 , P('Dry'|'Low')=0.4 P('Rain'|'High')=0.4 , P('Dry'|'High')=0.3 • Initial probabilities: P('Low')=0.4 , P('High')=0.6\n0.1748\n0.2004\n0.1208\n0.2438",
      "definition": "---------"
    },
    {
      "term": "590 :\nThe main aim of Natural Language Processing is to ____________ the human language.\nCipher\nIndex\nUnderstand\nComplicate",
      "definition": "Understand"
    },
    {
      "term": "591 :\nParts of speech can be divided into two broad supercategories, one supercategories is\nSub Class\nOpen Class\nJoin Class\nEmpty Class",
      "definition": "Open Class"
    },
    {
      "term": "592 :\nIn HMMs, spaces are connected via __________ matrices {T,A} to represent the probability of ____________ from one state to another following their _____\nTransitions, Transitioning, Connections\nAttribute, Changing, groups\nLabel, moving, sets\nTransitions, Chaning, Sets",
      "definition": "Transitions, Chaning, Sets"
    },
    {
      "term": "593 :\nUnder-stemming can be interpreted as __________.\nFalse-Positives\nFalse-Negative\nTrue-Positive\nTrue-Negative",
      "definition": "---------"
    },
    {
      "term": "594 :\nWhich is not method of WSD?\nSupervised learning\nDictionary method\nUnsupervised learning\nSem-supervised learning",
      "definition": "Sem-supervised learning"
    },
    {
      "term": "595 :\nNLP Stands for.\nNatural Language Protocol\nNatural Lingual Protocol\nNatural Lingual Processing\nNatural Language Processing",
      "definition": "Natural Language Processing"
    },
    {
      "term": "596 :\nWhat is the term frequency of a term which is used a maximum number of times in that document?\nt4 - 2/6\nt1 - 2/6\nt3 - 3/6\nt6 - 2/5",
      "definition": "t3 - 3/6"
    },
    {
      "term": "597 :\nIn maximum entropy model, generally features are -------- in nature.\nBinary\nUnary\nTernary\nRandom",
      "definition": "Binary"
    },
    {
      "term": "598 : \"The German authorities said a 'Colombian' who had lived for a long time in the Ukraine flew in from Kiev. 'He' had 300 grams of plutonium 239 in his baggage.\" is an example of which type of reference?",
      "definition": "Nominative Pronoun"
    },
    {
      "term": "599 :\nA grammar that produces more than one parse tree for some sentence is called\nAmbiguous\nUnambiguous\nRegular\nNone of the mentioned",
      "definition": "Ambiguous"
    },
    {
      "term": "600 :\nWhich of the following algorithms is widely used for text classification?\nDecision tree\nSupport vector machine\nNaive Bayes\nAll of the mentioned",
      "definition": "All of the mentioned\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 13 ---"
    },
    {
      "term": "601 : Which will be suitable NLP method For COVID 19 News Analysis from the online newspaers ?",
      "definition": "Text Summarization"
    },
    {
      "term": "602 :\nWhat is significance of caret ^ in regular expression?\nIf [ab ^ cd] means \" a or b ^ c and d\".\nIf [^A-Z] means all uppercase nothing negated.\nIf caret is first symbol after the open square brace \"[\" then resulting pattern is negated.\nIf [^a-b] means all lowercase nothing negated.",
      "definition": "If caret is first symbol after the open square brace \"[\" then resulting pattern is negated."
    },
    {
      "term": "603 :\nWhich Mt Systems Involve Low Computational Costs And Can Be Extended Easily?\nRetrival-Based Mt\nExample-Based Mt\nSpeech-Based Mt\nInterlingua-Based Mt",
      "definition": "Example-Based Mt"
    },
    {
      "term": "604 :\nKnowledge of the relationship of meaning to the goals and intentions of the speaker is\nMorphology\nSemantics\nPragmatics\nDiscourse",
      "definition": "Pragmatics"
    },
    {
      "term": "605 :\nWhich of the following is TRUE about CRF (Conditional Random Field) and HMM (Hidden Markov Model)?\nCRF is generative model and HMM is discriminative model\nBoth CRF and HMM are generative model\nCRF is discriminative model and HMM is generative model\nBoth CRF and HMM are discriminative model",
      "definition": "CRF is discriminative model and HMM is generative model"
    },
    {
      "term": "606 :\nIn NLG ______includes retrieving the relevant content from knowledge base.\nText planning\nSentence planning\nText Realization\nText Mapping",
      "definition": "Text planning"
    },
    {
      "term": "607 :\nSingular: knife, Plural : Knives Which rules are applied\nMorphological Rule\nOrthographic rule\nMechanical Rule\nDynamic Rule",
      "definition": "Orthographic rule"
    },
    {
      "term": "608 :\nA group of related documents against which information retrieval is employed is called:\nCorpus\nText Database\nIndex Collection\nRepository",
      "definition": "Corpus"
    },
    {
      "term": "609 :\nWhat changes the letters from one alphabet or language into the corresponding, similar-sounding characters of another alphabet\nSummarization\nTranslation\nTransliteration\nTransformation",
      "definition": "Translation"
    },
    {
      "term": "610 :\nWhat Is The Knowledge About Physical Situations Existing In The Surroundings At The Time Of Utterance?\nSituational Context\nBackground Knowledge\nCo-Textual Context\nOperational Knowledge",
      "definition": "Situational Context"
    },
    {
      "term": "611 :\nPronouns usually refer to entities that were introduced no further than one or two sentences back in the ongoing discourse, whereas ________________ can often refer further back.\ndemonstratives\nindefinite noun phrase\none anaphora\ndefinite noun phrases",
      "definition": "---------"
    },
    {
      "term": "612 :\nHow Many Steps Of Nlp Is There?\nThree\nFour\nFive\nSix",
      "definition": "Five"
    },
    {
      "term": "613 : To identify the category of each word in a sentence",
      "definition": "ERROR: Cannot find option POS"
    },
    {
      "term": "614 :\nMercedes is a ___ of luxury.\nHomonym\nAntonyms\nSynonyms\nTaxonomy",
      "definition": "Synonyms"
    },
    {
      "term": "615 :\nIdea behind maximum entropy is\nTo build a distribution by continuously separating features.\nTo build a distribution by continuously adding features.\nIgnore words feature and build a model\nBuild a model from class to word.",
      "definition": "To build a distribution by continuously adding features."
    },
    {
      "term": "616 :\nWhich Mt Systems Produce An Abstract Represenation Using Which, The Target Language Text Can Be Generated?\nRetrieval-Based Mt\nExample-Based Mt\nSpeech-Based Mt\nInterlingua-Based Mt",
      "definition": "Interlingua-Based Mt"
    },
    {
      "term": "617 : Which of the following is the major problem in Machine Translation?",
      "definition": "Referential Ambiguity"
    },
    {
      "term": "618 :\nGoogle Translate is one of the ________________ application.\nMachine translation\nInformation Retrieval\nInformation Extraction\nInformation Generation",
      "definition": "Machine translation"
    },
    {
      "term": "619 :\nIn the English language derivational morphemes can be...\nPrefixes and Suffixes\nSuffixes only\nInfixes Only\nPrefixes, Suffixes and Infixes",
      "definition": "Prefixes and Suffixes"
    },
    {
      "term": "620 :\nAssume a corpus with 350 tokens in it. We have 20 word types in that corpus (V = 20). The frequency (unigram count) of word types \"short\" and \"fork\" are 25 and 15 respectively. Which of the following is the probability of \"short\" (PMLE(\"short\"))?\n25/350\n26/370\n26/350\n25/370",
      "definition": "25/350"
    },
    {
      "term": "621 : Which is the most suitable tecnhiqe for finding \" Trendning Topic on Twitter\"?",
      "definition": "Term Frequncy"
    },
    {
      "term": "622 :\nWhat is the main challenge/s of NLP?\nHandling Ambiguity of Sentences\nHandling Tokenization\nHandling POS-Tagging\nparsing",
      "definition": "Handling Ambiguity of Sentences"
    },
    {
      "term": "623 :\nA list of place names, often providing millions of entries for locations with detailed geographical and political information is called as:\nEncyclopaedia\nDictionary\nCorpora\nGazetteer",
      "definition": "Gazetteer"
    },
    {
      "term": "624 :\nWhich of the following will be POS Tagger output when the input sentence is \"They refuse to permit\"\n[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB')]\n[('They', 'NN'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB')]\n[('They', 'PRP'), ('refuse', 'NN'), ('to', 'TO'), ('permit', 'VB')]\n[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'PRP'), ('permit', 'VB')]",
      "definition": "ERROR: No options for answer a"
    },
    {
      "term": "625 :\nHMMs are limited to only ________ states and only take into account the last known _____.\nComplete, Value\nUnobserved, Variable\nHidden, Attribute\nDiscrete, State",
      "definition": "Discrete, State"
    },
    {
      "term": "626 :\nWhich Application Of Nlp Deals With Mapping Of Acoustic Speech Signal To A Set Of Words\nSpeech Recognition\nMachine Translation\nSpeech Synthesis\nInformation Retrieval",
      "definition": "Speech Recognition"
    },
    {
      "term": "627 :\nEconomy is called a ___, a \"higher level\" term for hero and tata\nPrototype\nExperiencer\nSuperordinate terms\nSuperordinate",
      "definition": "---------"
    },
    {
      "term": "628 :",
      "definition": "ERROR: Cannot find option IP"
    },
    {
      "term": "629 :\nIn filtration process\nSpecial characters are removed from Devanagari script\nStop word are removed\nStemming is performed\nBottom up parser is applied",
      "definition": "Stop word are removed"
    },
    {
      "term": "630 :\nWhich of the following features can be used for accuracy improvement of a classification model?\nPart of Speech Tag\nDependency Grammar\nVector Notation of sentence\nPart of Speech Tag & Dependency Grammar & Vector Notation of sentence",
      "definition": "---------"
    },
    {
      "term": "631 : How many trigrams phrases can be generated from the following sentence, after performing following text cleaning steps: Stopword Removal, Replacing punctuations by a single space? \"#Coursera is a great platform to learn @Machine Learning.\"?",
      "definition": "4"
    },
    {
      "term": "632 :\nWhich Historical event is related to NLP\nFirst World War\nSecond World War\nAmerican Revolution\nFrench Revolution",
      "definition": "Second World War"
    },
    {
      "term": "633 : Which of the following is an example of free morphene?",
      "definition": "town"
    },
    {
      "term": "634 :\nWhat Can Be Used To Disambiguate Word Senses\nSelectional Restrictions\nIndependent Restrictions\nNo Restrictions\nAll Restrictions",
      "definition": "Selectional Restrictions"
    },
    {
      "term": "635 :\nWhich Application Of Nlp Deals With Creation Of Summaries Of Documents\nText Summarization",
      "definition": "Answering\nInformation Extraction\nInformation Retrieval"
    },
    {
      "term": "636 :\nOur interpretation of the \"meaning\" of the sign is not based solely on the ___, but on what we think the writer intended to communicate.\nAnaphora\nWords\nFace\nContext",
      "definition": "Text Summarization"
    },
    {
      "term": "637 :\n____ principle states that the meaning of the whole sentence is comprised of the meaning of its parts that is the meaning of the sentence can be composed from the meaning of its constituent words\nhobs\nporter\nfreg's\nmarkov",
      "definition": "Words"
    },
    {
      "term": "638 :\nWhich is the correct order for preprocessing in Natural Language Processing?\ntokenization->stemming->lemmatization\nlemmatization->tokenization->stemming\nstemming->tokenization->lemmatization\ntokenization->lemmatization->stemming",
      "definition": "---------"
    },
    {
      "term": "639 :\nIn the sentence, \"They bought a blue house\", the underlined part is an example of _____.\nNoun phrase\nVerb phrase\nPrepositional phrase\nAdverbial phrase",
      "definition": "tokenization->stemming->lemmatization"
    },
    {
      "term": "640 :\nPorter Stemmer has ______ rules\n3\n5\n7\n4",
      "definition": "Noun phrase"
    },
    {
      "term": "641 :\nWhat does Fr[ea]nc[eh]$ does not match?\nFrance\nSino-French\nFrence\nFranc",
      "definition": "5"
    },
    {
      "term": "642 :\nHyponym is\nParent node\nChild node\nRoot node\nPart of centre node",
      "definition": "Franc"
    },
    {
      "term": "643 :\nWhen training a language model, if we use an overly narrow corpus, the probabilities\nDon't reflect the task\nReflect all possible wordings\nReflect intuition\nDon't generalize",
      "definition": "Root node"
    },
    {
      "term": "644 :\nIn text summarisation an ___________ uses different words to describe the contents of the document.\nAbstract\nExtract\nInformation\nProse",
      "definition": "Don't generalize"
    },
    {
      "term": "645 :\nWhich derivational prefixes does not change the category of word to which they are attached?\nRe- & -Un\n-er\n-ize\n-ing",
      "definition": "Abstract"
    },
    {
      "term": "646 :\n\"Innocent peacefully children sleep little\" vs \"Innocent little children sleep peacefully\". Which stage of NLP helps to find proper ordering of sentences\nMorphology Analysis\nPhonology Analysis\nSemantics Analysis\nSyntax Analysis",
      "definition": "-ing"
    },
    {
      "term": "647 :\nWhich type of semantics is concerned with how words combine to form larger meanings\nCompund Semantics\nCompositional semantics\nLexical semantics\nWord Semantics",
      "definition": "Syntax Analysis"
    },
    {
      "term": "648 :\nX is a ........ of Y if it denotes a part of Y\nMeronym\nHyponym\nHynonyms\nHypernyms",
      "definition": "---------"
    },
    {
      "term": "649 :",
      "definition": "Performance metric for classifier doesn't include"
    },
    {
      "term": "650 :\nNlp Is Concerned With The Interactions Between\nComputers And Human (Natural) Languages.\nMachine And Machine\nHuman And Machine\nBoth A) And B)",
      "definition": "---------"
    },
    {
      "term": "Computers And Human (Natural) Languages.\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 14 ---",
      "definition": "651 :\nAccording to Austin, speech acts are direct when\nthe locutionary and perlocutionary acts coincide\nthe locutionary and illocutionary acts coincide\nWhen no act coincide\nthe illocutionary and perlocutionary acts coincide"
    },
    {
      "term": "652 :\nWhich of the following NLP tasks use sequential labeling technique?\nPOS tagging\nNamed Entity Recognition\nSpeech recognition\nAll of the above",
      "definition": "the locutionary and illocutionary acts coincide"
    },
    {
      "term": "653 :\nComputer Vs Computational Is An Example Of ______ Morphology.\nInflectional\nDerivational\nCliticization\nInformation Retrieval",
      "definition": "All of the above"
    },
    {
      "term": "654 :\nWhich of the following is merits of Context-Free Grammar?\nsimplest style of grammar\nThey are highly precise.\nHigh speed\nefficiency",
      "definition": "Derivational"
    },
    {
      "term": "655 :\nThe dish is displayed on the screen. Here the type of ambiguity is\nPhonetic\nLexical\nStructural\nSemantic",
      "definition": "simplest style of grammar"
    },
    {
      "term": "656 :\nIn which type of morphology, new words get created by changing part-of-speech. e.g. organise, organization, organizational\nInflectional\nBoth derivation and inflectional\nSemantic\nDerivational",
      "definition": "Lexical"
    },
    {
      "term": "657 :\nChoose areas where NLP can not be useful.\nAutomatic Text Summarization\nAutomatic Question-Answering Systems\nInformation Retrieval\nX-Ray Analysis",
      "definition": "Derivational"
    },
    {
      "term": "658 :\nWhen did first patent's for transating machine were applied for\nIn the mid of 1930\nat the end of 1930\nIn the begining of 1930\nIn the mid of 1931",
      "definition": "X-Ray Analysis"
    },
    {
      "term": "659 :\nWhen gmail extracts only the data from the email recived for you to add in your Google Calendar. This example denotes\nInformation extraction\nInformation retrieval\nInformation Handling\nInformation Transformation",
      "definition": "In the mid of 1930"
    },
    {
      "term": "660 :\nWhich Nlp Based System Can Read Out Your Mails On Telephone Or Even Read Out A Story Book For You\nSpeech Recognition\nMachine Translation\nSpeech Synthesis\nInformation Retrieval",
      "definition": "Information extraction"
    },
    {
      "term": "661 :\nWhich Data Structure Is Used To Give Better Heuristic Estimates?\nForwards State-Space\nBackward State-Space\nPlanning Graph\nPlanning Graph Algorithm",
      "definition": "Speech Synthesis"
    },
    {
      "term": "662 :\n\"The Cat flys\" after applying which ngram gives the output as \"The Cat\",\"Cat flys\"\nUnigram\nBigram\nTrigram\nQuadrigrams",
      "definition": "Planning Graph Algorithm"
    },
    {
      "term": "663 :\n____ use hand-written rules to identify the correct tag\nStochastic POS tagging\nRule based POS tagging\nTransformation based Tagging\nFuzzy logic based Tagging",
      "definition": "Bigram"
    },
    {
      "term": "664 :\nWhat is the role of NLP in recommendation engines like Collaborative Filtering?\nExtracting features from text\nMeasuring semantic similarity\nConstructing feature vector\nAll of the mentioned",
      "definition": "Rule based POS tagging"
    },
    {
      "term": "665 :\n_________ can specify the results of processes described by utterances in a discourse.\ngenerics\none-anaphora\nInferrables\ndiscontinuous sets",
      "definition": "---------"
    },
    {
      "term": "666 :\nGoogle Translate is one of the ________________ application.\nMachine translation\nInformation Retrieval\nInformation Extraction\nSummarisation",
      "definition": "---------"
    },
    {
      "term": "667 :\n\" Bat is flying in the sky\" Identify the dependency checking to perform sense disambiguation of 'Bat'\nBatà sky\nSkyà fly\nBatà fly\nBatà sky, fly",
      "definition": "Machine translation"
    },
    {
      "term": "668 :\nFrom a verb to a specific manner elaboration of that web\nHomonymy\nTroponym\nPolysemy\nMetonymy",
      "definition": "---------"
    },
    {
      "term": "669 :\ne.g. Original statement in speech is 'I saw a van' During speech to text conversion statement becomes \"eye awe of an\" Such type of error can be removed by\nParser\nTagger\nN-gram\nFST",
      "definition": "---------"
    },
    {
      "term": "670 :\nConsider the CFG as defined: X--> XY, X--> ax / bx / a, Y --> Ya / Yb / b Any string of terminals, which can be generated by the CFG\nHas at least one b\nEnds with a\nHas no consecutive a's and b's\nHas at least 2 a's.",
      "definition": "N-gram"
    },
    {
      "term": "671 :\nWhat is the main challenge/s of NLP?\nHandling Ambiguity of Sentences\nHandling Tokenization\nHandling POS-Tagging\nStemming",
      "definition": "Has at least 2 a's."
    },
    {
      "term": "672 :\nWhich semantic relation exists between the words\"piece\" and \"peace?\nHomophony\nHomonymy\nHypernymy\nMeronymy",
      "definition": "Handling Ambiguity of Sentences"
    },
    {
      "term": "673 :\nHow to use WordNet to measure semantic relatedness between words:\nMeasure the shortest path between two words on WordNet\nCount the number of shared parent nodes\nMeasure the difference between their depths in WordNet\nMeasure the difference between the size of child nodes they have.",
      "definition": "ERROR: No options for answer a"
    },
    {
      "term": "674 :\nThis is not feature of binary machine learning classifier\nLength of the keyphrase\nFrequency of the keyphrase\nThe most recurring word in keyphrase\nStemming",
      "definition": "Measure the difference between their depths in WordNet"
    },
    {
      "term": "675 :\nTo find relevance of word in a document technique used\nTF-IDF\nLemma\nTokenizer\nPos tagging",
      "definition": "Stemming"
    },
    {
      "term": "676 :\nWhich Of The Following Will Be A Better Choice To Address Nlp Use Cases Such As Semantic Similarity, Reading Comprehension, And Common Sense Reasoning\nElmo\nOpen Ai'S Gpt\nUlmfit\nGpt-2",
      "definition": "TF-IDF"
    },
    {
      "term": "677 :\nIn Nlp, The Process Of Identifying People, An Organization From A Given Sentence, Paragraph Is Called\nStemming\nLemmatization\nStop Word Removal\nNamed Entity Recognition",
      "definition": "Open Ai'S Gpt"
    },
    {
      "term": "678 :\nClock = digital - analog - alarm\nPolysemy\nMeronymy\nHyponymy\nCline",
      "definition": "Named Entity Recognition"
    },
    {
      "term": "679 :\nNatural language processing is divided in _____feilds.\n5\n6\n3\n2",
      "definition": "Hyponymy"
    },
    {
      "term": "680 :\nWhich of the following techniques can be used to compute similarity between two sentences in NLP?\nLemmatization\nPart of Speech Tagging\nCosine Similarity\nN-grams",
      "definition": "5"
    },
    {
      "term": "681 : In linguistic morphology _____________ is the process for reducing inflected words to their root form.",
      "definition": "Text-Proofing"
    },
    {
      "term": "682 :\nHow conditional probability rewrite in language model? P(B | A) =P(A, B) / P(A)\nP(A, B) = P(A) P(B | A)\nP(A, B) = P(A) P(A | B)\nP(A, B) = P(B) P(B | A)\nP(A) = P(A) P(B | A)",
      "definition": "Stemming"
    },
    {
      "term": "683 :\nGiven a sentence S=\"w1 w2 w3 ... wn\", to compute the likelihood of S using a bigram model. How would you compute the likelihood of S?\nCalculate the conditional probability of each word in the sentence given the preceding word and add the resulting numbers\nCalculate the conditional probability of each word in the sentence given the preceding word and multiply the resulting numbers\nCalculate the conditional probability of each word given all preceding words in a sentence and add the resulting numbers\nCalculate the conditional probability of each word given all preceding words in a sentence and multiply the resulting numbers",
      "definition": "P(A, B) = P(A) P(B | A)"
    },
    {
      "term": "684 :\nWhat Is Most Commonly Described As The Language Above The Sentence Level Or As 'Language In Use\nDiscourse\nWord Level Analysis\nSemantic Analysis\nSyntax Analysis",
      "definition": "Calculate the conditional probability of each word in the sentence given the preceding word and multiply the resulting numbers"
    },
    {
      "term": "685 :\nConsider the following sentences. \"The horse ran up the hill. It was very steep. It soon got tired.\" What type of ambiguity is introduced due to the word \"it\"?\nSyntactic\nPragmatics\nCataphoric\nAnaphoric",
      "definition": "Discourse"
    },
    {
      "term": "686 :",
      "definition": "ERROR: Cannot find option d"
    },
    {
      "term": "687 :\nIn the sentence, \"He ate the pizza\", the BOLD part is an example of _____.\nNoun phrase\nVerb phrase\nPrepositional phrase\nAdverbial phrase",
      "definition": "Using language to signal attitude other than what has been literally said."
    },
    {
      "term": "688 : The study of how knowledge about the world and language conventions interact with literal meaning is called as ____________.",
      "definition": "Discourse analysis"
    },
    {
      "term": "689 :\n....................are the entities that have been previously introduced into the discourse.\nAnaphoras\nCataphoras\nPronouns\nderminers",
      "definition": "---------"
    },
    {
      "term": "690 : Any question and answering system is classified into _________ and ___________ types",
      "definition": "Locked domain QAS, Unlocked Domain QAS"
    },
    {
      "term": "691 :\nReason for stop word removal\nStop word slow down processing\nStop word enhance speed of searching\nStop word removal programs are easily available\nThis is routine pre processing without any benefit",
      "definition": "---------"
    },
    {
      "term": "692 :\nWhat Is Full Form Of Nlp?\nNatural Language Processing\nNature Language Processing\nNatural Language Process\nNatural Language Pages The Stage Of Nlp Were \"Processing Of Sequence Of Sentences Is Done\" Is Called As M",
      "definition": "Stop word slow down processing"
    },
    {
      "term": "693 :\nCo-reference Resolution is -\nAnaphora Resolution\nGiven a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\")\nCounting frequency of define terms.\nNotation of vector for every sentence.",
      "definition": "Natural Language Processing"
    },
    {
      "term": "Given a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\")",
      "definition": "694 :\nSelect one from following which is not a rule of language?\nLexicalization\nMorphology\nSemantics\nPhonology"
    },
    {
      "term": "695 :\nFST is used in _____ Analysis.\nLexical\nMorphological\nSemantic\nSyntactic",
      "definition": "---------"
    },
    {
      "term": "696 : Discourse analysis is a part of ____________.",
      "definition": "Syntax Analysis"
    },
    {
      "term": "697 :\nAutomatic text Summarization is not useful for\nCreate short summary\nReducing reading time\nAccelerate the research\nImproves redundancy",
      "definition": "---------"
    },
    {
      "term": "698 :\nThe process of assigning tags or categories to text according to its content is called\nSentiment Analysis\nText Summarization\nInformation Retrival\nText classification",
      "definition": "Accelerate the research"
    },
    {
      "term": "699 :\nIn 1969 Roger schank introduced ________________ dependency theory for NL understanding\nConceptual\nBilateral\nTrilateral\nTextual",
      "definition": "Text classification"
    },
    {
      "term": "700 :\n\"Buy books for children\" which type of ambiguity exists in the above sentence?\nSemantic\nSyntactic\nLexical\nPragmatic",
      "definition": "Conceptual"
    },
    {
      "term": "b\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 15 ---",
      "definition": "701 :\nThe words that pronouns refer back to are called as __________.\nAntecedent\nContext\nReference\nSpeech act"
    },
    {
      "term": "702 : A scheme where a weight is assigned to a term based upon the number of occurrences of the term within a document is called:",
      "definition": "Bag of Words"
    },
    {
      "term": "703 :\nWhich of the following is efficient representation of text data?\nBag of Word\nTF-IDF\nWord Vector\nBERT",
      "definition": "Term Frequency"
    },
    {
      "term": "704 : Which token of the following is lemmatized correctly by the rule given? (X) -sses ® -ss (X) -ies ® -i (X) -ss ® -ss (X) -s ® ϵ",
      "definition": "Courses"
    },
    {
      "term": "705 :\nWhich of the below are NLP use cases?\nDetecting objects from an image\nFacial Recognition\nText Summarization\nSpeech Biometric",
      "definition": "Dogs"
    },
    {
      "term": "706 :\nIn the word \"desirability\" how many morpheme is present\nOne\nTwo\nThree\nFour",
      "definition": "Text Summarization"
    },
    {
      "term": "707 :\nStemming for the word cries is _____\ncry\ncries\ncri\nies",
      "definition": "Three"
    },
    {
      "term": "708 :\nThe joint probability can be calculated using the ________\nconditional probability\nprobability\nsentence\nword",
      "definition": "cri"
    },
    {
      "term": "709 :\nClassifying email as a spam, labelling WebPages based on their content, voice recognition are the example of _____.\nSupervised learning\nUnsupervised learning\nMachine learning\nDeep learning",
      "definition": "probability"
    },
    {
      "term": "710 :\n___________ can also specify the results of processes described by utterances in a discourse.\nPronouns\ndemonstratives\ngenerics\ninferrables",
      "definition": "Supervised learning"
    },
    {
      "term": "711 :\nQuora is an example of which type of question answering system\nClose\nOpen\nSub\nAspect",
      "definition": "---------"
    },
    {
      "term": "712 :\nClass of methods that induces a classifier from manually sense-tagged text using machine learning techniques.\nSupervised WSD\nunsupervised WSD\nSemi-supervised WSD\nNormal WSD",
      "definition": "---------"
    },
    {
      "term": "713 :\nWhat is morpheme?\nSet of words with grammar.\nSmallest linguistic unit with grammatical function.\nSet of rules.\nSmallest sentence with syntax.",
      "definition": "---------"
    },
    {
      "term": "714 :\nSame Word Can Have Multiple Word Embeddings Possible With ____________?\nGlove\nWord2Vec\nElmo\nNltk",
      "definition": "Smallest linguistic unit with grammatical function."
    },
    {
      "term": "715 :\nThe statement \"Which mobiles can you show me in your shop?\" can be represented as\nN->Wh-NP Aux NP VP\nS->Wh-NP Aux NP NP\nS->Wh-VP Aux NP VP\nS->Wh-NP Aux NP VP",
      "definition": "Elmo"
    },
    {
      "term": "716 :\n_____ is a process of assigning corresponding part of speech like noun, verb, adverb, adjective, verb to each word in a sentence.\nPart of speech tagging\nName entity tagging\nParsing\nDisambiguation",
      "definition": "S->Wh-VP Aux NP VP"
    },
    {
      "term": "717 :\nHas the coexistence of many possible related meanings for a word or phrase\nHyponymy\nPolysemy\nClines\nContranyms",
      "definition": "Part of speech tagging"
    },
    {
      "term": "718 :\nIn Reference Resolution the entity that is referred is called as _________ .\ncorefer\nreferent\nanaphora\nsubject",
      "definition": "Polysemy"
    },
    {
      "term": "719 :\nPush down automata accepts which language?\nContext sensitive language\nContext free language\nRecursive language\nContext Recursive language",
      "definition": "---------"
    },
    {
      "term": "720 :\nDeciding Insurance premium of a car based on online customers reviews is an application of ______________________.\nInformation Retrival\nInformation Extraction\nSentiment Analysis\nText Summarization",
      "definition": "Context free language"
    },
    {
      "term": "721 : which one of the following is not Tools/Techniques that can be used with sentiment analysis",
      "definition": "Latent semantic analysis"
    },
    {
      "term": "722 :\nCFG consist of\nSet of rules\nSet of productions\nOrder of elements\nrules ,productions,order of element",
      "definition": "Abstractive analysis"
    },
    {
      "term": "723 :\nAssume That There Are0000 Documents In A Collection. Out Of These, 50 Documents Contain The Terms \"Difficult Task\". If \"Difficult Task\" Appears Times In A Particular Document, What Is The Tfidf Value Of The Terms For That Document?\n8.11\n15.87\nZero\n81.1",
      "definition": "rules ,productions,order of element"
    },
    {
      "term": "724 :\nIt is not part of text summarization on the basis of purpose\nGeneric\nDomain-specific\nQuery based\nSingle document",
      "definition": "87"
    },
    {
      "term": "725 :\nDefine pragmatics\nA subfield of linguistics and semiotics that studies the ways in which context contributes to meaning.\nFeatures that appear when we put sounds together in connected speech.\nSome definitions limit this to verbal communication that is not words.\nThe process of syntax checking",
      "definition": "Single document"
    },
    {
      "term": "726 :\n\"Linear sequnces of words are transformed into structure that show how the words are related to each other \" is the part of _____ Analysis.\nSemantic\nSyntactic\nLexical\nPragmatic",
      "definition": "---------"
    },
    {
      "term": "727 : Which of these does not belong to CFG?",
      "definition": "Non terminal Symbol"
    },
    {
      "term": "728 :\nWords 's', 'ly', 'er', 'ed' are examples of which morpheme\nPrefix\nBound\nFree\nSuffix(eg- clears, clearly, clearer, cleared)",
      "definition": "End Symbol"
    },
    {
      "term": "729 :\nWhich Of The Following Best Describes Grammar Induction?\nSupervised Learning Problem\nConditional Random Field Problem\nMaximum-A-Posteriori (Map) Estimation Problem\nUnsupervised Learning Problem",
      "definition": "Suffix(eg- clears, clearly, clearer, cleared)"
    },
    {
      "term": "730 :\nMany words have more than one meaning; we have to select the meaning which makes the most sense in context. This can be resolved by ____________\nFuzzy Logic\nWord Sense Disambiguation\nShallow Semantic Analysis\nAll of the mentioned",
      "definition": "Unsupervised Learning Problem"
    },
    {
      "term": "731 :\nWhich phrases are examples of anaphora in the following passage?Now let us fight to fulfil that promise! Let us fight to free the world - to do away with national barriers - to do away with greed, with hate and intolerance. Let us fight for a world of reason, a world where science and progress will lead to all men's happiness.\nlet us fight\nto do away with\nall men's happiness\nboth let us fight and to do away with",
      "definition": "Word Sense Disambiguation"
    },
    {
      "term": "732 :\n______ System consists of collection of grammar rules, dictionary, and software programs to process the rules.\nDirect translation\nKnowledge based Machine Translation\nRule based translation\nExample Based translation",
      "definition": "both let us fight and to do away with"
    },
    {
      "term": "733 :\nWhich Technique Can Modify Root To A Word Of A Different Class\nDerivational Morphology\nWord Sense Disambiguity\nEntropy\nSemantics",
      "definition": "---------"
    },
    {
      "term": "734 :\nThe effectiveness of an SVM depends upon:\nSelection of Kernel\nKernel Parameters\nSoft Margin Parameter C\nSelection of Kernel & Kernel Parameters & Soft Margin Parameter C",
      "definition": "Derivational Morphology"
    },
    {
      "term": "735 :\nHow is the term \"prototype\" used in semantics?\nThe prototype is the characteristic instance of a category, as in the case of \"robin\" being the clearest example, or prototype, of the category \"bird\" for many American English speakers.\nsyntax; semantics; pragmatics\nantonyms; gradable and non-gradable\na) The verb drink requires a subject with the feature [+animate] and the noun television has the feature [-animate]. b) The verb write requires a subject with the feature [+human] and the noun dog has the feature [-human].",
      "definition": "Selection of Kernel & Kernel Parameters & Soft Margin Parameter C"
    },
    {
      "term": "The prototype is the characteristic instance of a category, as in the case of \"robin\" being the clearest example, or prototype, of the category \"bird\" for many American English speakers.",
      "definition": "736 :\nIn linguistic morphology _____________ is the process for reducing inflected words to their root form.\nRooting\nStemming\nText-Proofing\nBoth Rooting & Stemming"
    },
    {
      "term": "737 :\nS → NP VP {DCL(NP.sem(VP.sem))}\nImperative statement\nDeclarative statement\nYes or No Question\nWh questions like who which etc",
      "definition": "Stemming"
    },
    {
      "term": "738 :\nMost tagging algorithms fall into one of two classes _________ & __________\nRule based tagger, Stochastic tagger\nGraph based tagger, Stochastic tagger\nRule based tagger, semantic tagger\nPragmatic tagger, Stochastic tagger",
      "definition": "Declarative statement"
    },
    {
      "term": "739 :\nNatural Language Processing can be divided into two su.bfields of\nsyntax and semantics\ngeneration and understanding\nderivation and inflection\ntext and speech",
      "definition": "Rule based tagger, Stochastic tagger"
    },
    {
      "term": "740 :\nHow many different lexemes are there in the following list?man, men, girls, girl, mouse\n1\n2\n3\n4",
      "definition": "generation and understanding"
    },
    {
      "term": "741 :\nThe ratio of observed frequency of a particular sequence to the observed frequency of a prefix is:\nNormalized Frequency\nRelative Frequency\nMaximum Likelihood Estimation\nMarkov Frequency",
      "definition": "3"
    },
    {
      "term": "742 :\nKnowledge of the relationship of meaning to the goals and intentions of the speaker is ________\nMorphology\nSemantics\nPragmatics\nDiscourse",
      "definition": "Relative Frequency"
    },
    {
      "term": "743 :\nWhile Working With Text Data Obtained From News Sentences, Which Are Structured In Nature, Which Of The Grammar-Based Text Parsing Techniques Can Be Used For Noun Phrase Detection, Verb Phrase Detection, Subject Detection And Object Detection.\nPart Of Speech Tagging\nDependency Parsing And Constituency Parsing\nSkip Gram And N-Gram Extraction\nContinuous Bag Of Words",
      "definition": "Pragmatics"
    },
    {
      "term": "744 :\nIn the case of Search Engine Optimization, ................. NLP technique can be used\nMachine Transltion",
      "definition": "Dependency Parsing And Constituency Parsing"
    },
    {
      "term": "Ansering System\nText summarization\nSentiment Analysis",
      "definition": "ERROR: No options for answer c"
    },
    {
      "term": "745 : Which is not an example of stop word?",
      "definition": "ERROR: Cannot find option d"
    },
    {
      "term": "746 :\nIt uses statistical methods to resolve some of the difficulties in symbolic approach. It does this by harnessing various mathematical techniques and often using large text corpora to develop approximately generalized models of linguistic phenomena based on actual examples.\nConvolutional Neural Networks\nRule based Approach\nCorpus based.\nStatistical Approach",
      "definition": "Statistical Approach"
    },
    {
      "term": "747 :\nIn the sentence \" I made her duck.\" Here the word \"make\" is\nsemantically ambiguous\nsyntactically ambiguous\nmorphologically ambiguous\nnot ambiguous",
      "definition": "syntactically ambiguous"
    },
    {
      "term": "748 :\nWhat do you by Sequence Learning?\nSequence learning is a method of only teaching in a logical manner\nSequence learning is a method of teaching and learning in a logical manner.\nAll of the mentioned\nNone of the mentioned",
      "definition": "---------"
    },
    {
      "term": "749 :\nWho is the father of NLP?\nEnjamin Bandler\nRichard Bandler\nElijah Bandler\nJon Bandler",
      "definition": "Richard Bandler"
    },
    {
      "term": "750 :\nA web server communicates with a client (browser) using which protocol:\nHTML\nHTTP\nFTP\nTelnet",
      "definition": "---------\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------\n\n--- Page 16 ---"
    },
    {
      "term": "751 :\nThe bigram model approximates the probability of a word given all the previous words by using:\nThe conditional probability of all the previous words\nThe maximum likelihood estimation of the given word\nOnly the conditional probability of the preceding word\nThe maximum likelihood estimation of the preceding word",
      "definition": "Only the conditional probability of the preceding word"
    },
    {
      "term": "752 : Consider the following corpus of 3 sentences. 1) I am here 2) who am I. 3) I would like to go. Calculate​ P(here|am) ​assuming a bi-gram language model.",
      "definition": "01-02-2020 12:00:00 AM"
    },
    {
      "term": "753 :\n\"I went to the school, and they told me come on next day\". What type of ambiguity present in the given sentence?\nSyntactic ambiguity\nAnaphoric ambiguity\nSemantic ambiguity\nLexical ambiguity",
      "definition": "Anaphoric ambiguity"
    },
    {
      "term": "754 :\nWhich of the following is/are the input(s) to k-means algorithm?\nNumber of clusters\nClass labels\nDistance metric\nNumber of centroids",
      "definition": "Number of centroids"
    },
    {
      "term": "755 :\n_________Reverses the antecedent-anaphora relationship by beginning with a pronoun, then later revealing more specific information\nAnaphora\nContextual\nContext\nCataphora",
      "definition": "Cataphora"
    },
    {
      "term": "756 :\nWhat are the possible input of an NLP system?\nSpeech and noise\nSpeech ,scan document and Written Text\nNoise and Written Text\nNoise and value",
      "definition": "Speech ,scan document and Written Text"
    },
    {
      "term": "757 : Capability vs Capabilities is an example of ______ morphology.",
      "definition": "Derivational"
    },
    {
      "term": "758 :\nIt is a process of generating a concise and meaningful summary of text from multiple text resources such as books, news articles,blog posts, research papers, emails, and tweets.\nAutomatic Summerization\nInsertion\nUpdation\nExtraction",
      "definition": "Automatic Summerization"
    },
    {
      "term": "759 : Spam email detection comes under which domain?",
      "definition": "Text Classification"
    },
    {
      "term": "760 :\nFor e.g. \"Before she purchased it, Mary checked warranty card of the product\". In the context of pronoun, this is the example of\nCataphora\nBound\nFree\nRandom",
      "definition": "---------"
    },
    {
      "term": "761 :\n\"The tour includes three Asian countries.\" Which is a noun phrase?\nThe tour includes\nthree Asian countries\nThree asian\nTour includes",
      "definition": "three Asian countries"
    },
    {
      "term": "762 :\nThe Context Of A Word Provides Useful Information About Word Sense. Which Algorithms Can Be Braodly Classified Into Knowledge-Based And Corpus-Based Approaches\nContext-Based Disambiguation\nContext-Free Grammar\nRegular Expressions\nContext-Based Ambiguation",
      "definition": "Context-Based Disambiguation"
    },
    {
      "term": "763 : What type of relation exist between the words \"meet\" and \"meat\"?",
      "definition": "Homophones"
    },
    {
      "term": "764 :\nWhat is Morphological Segmentation?\nDoes Discourse Analysis\nSeparate words into individual morphemes and identify the class of the morphemes\nIs an extension of propositional logic\nSeparate sentences into individual morphemes and identify the class of the morphemes",
      "definition": "Separate words into individual morphemes and identify the class of the morphemes"
    },
    {
      "term": "765 :\nSemantic model is not used for\nThe meaning of words\nKnowledge about structure of discourse\nCommon sense knowledge about the topic\nPOS tag of word",
      "definition": "POS tag of word"
    },
    {
      "term": "766 :\nIn A Corpus Of N Documents, One Randomly Chosen Document Contains A Total Of T Terms And The Term \"Hello\" Appears K Times. What Is The Correct Value For The Product Of Tf (Term Frequency) And Idf (Inverse-Document-Frequency), If The Term \"Hello\" Appears In Approximately One-Third Of The Total Documents?\nKt * Log(3)\nT * Log(3) / K\nK * Log(3) / T\nLog(3) / Kt",
      "definition": "K * Log(3) / T"
    },
    {
      "term": "767 :\nWhich type of semantics is concerned with the linguistic study of systematic, meaning related structure of words or lexemes\nCompund Semantics\nLexical semantics\nCompositional semantics\nWord Semantics",
      "definition": "Lexical semantics"
    },
    {
      "term": "768 :\nWhat is a difference between Finite State Automata (FSA) and Finite State Transducers (FST)?\nFSA contain single tape and FST also contain single tape.\nFSA contain single input tape and FST contain single output tape.\nFSA contain single input tape and FST contain input: output pair tapes.\nBoth FSA and FST contains output tapes only.",
      "definition": "FSA contain single input tape and FST contain input: output pair tapes."
    },
    {
      "term": "769 : Anita has got the transcripts for the Minster's press meet on NEP. She wants to summarize the Minister's opinion on NEP strengths and weakness. Which of the following sumamrization methods should she apply?",
      "definition": "Abstractive query focussed"
    },
    {
      "term": "770 :\nMaximum Entropy Markov Model (MEMM) used to handle______\nUnkonwn word\nKnown word\nMultpile tag\nSingle tag word",
      "definition": "Multpile tag"
    },
    {
      "term": "771 :\nWhat is tokenization?\nBreaking sentences into words\nCreating a set of dictonories\nRemoving repetation\nprinting words",
      "definition": "Breaking sentences into words"
    },
    {
      "term": "772 :\nHumhe khaanna khaanna hai. Here the type of ambiguity is\nPhonetic\nLexical\nStructural\nSemantic",
      "definition": "Semantic"
    },
    {
      "term": "773 :\nMaximum Entropy Markov Models use a maximum entropy _______for _______ and local __________.\nFramework, Features, Normalization\nRules, Variables, Classification\nSets, Values, Distribution\nRules, features, classification",
      "definition": "Framework, Features, Normalization"
    },
    {
      "term": "774 :\nHow is the word \"consultants\" stemmed?\nconsultant\nconsult\nconsul\nconsultants",
      "definition": "b\nchevron_left\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nchevron_right\n--------------------"
    }
  ]
}